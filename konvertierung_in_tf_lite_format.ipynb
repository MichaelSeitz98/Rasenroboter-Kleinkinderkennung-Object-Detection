{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hxwSyAOwLNEX"
      ],
      "authorship_tag": "ABX9TyM5fhrWR/Anl4+gUH1lamdR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelSeitz98/Seminararbeit_Kleinkinderkennung/blob/main/konvertierung_in_tf_lite_format.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w2tc4yQ8KdZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e10400e-b241-4db3-c759-969480999243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxwSyAOwLNEX"
      },
      "source": [
        "# Tensorflow Object Detection API installieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiQs7KXJKjev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d865015-799b-4061-ada2-56d3763c0c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.6.0\n",
            "  Downloading tensorflow-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 458.4 MB 30 kB/s \n",
            "\u001b[?25hCollecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (0.2.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (1.15.0)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (3.19.6)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (3.1.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (0.38.4)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (1.51.1)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (0.4.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (2.9.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (2.9.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.6.0) (2.9.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (3.2.2)\n",
            "Building wheels for collected packages: clang, termcolor, wrapt\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=5d1a40768b3ef55ec4353d641c0c20e4a18be71376f9934086d0b92297f23c29\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=a8b5d62ad2a8cdbee65ac29407a3698336cdb6c502a5404f36fc717da66632a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=72341 sha256=93019a9d980e94099c61a8860c6f7deca220f9d745dd3f822b4d84e941ceea49\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
            "Successfully built clang termcolor wrapt\n",
            "Installing collected packages: numpy, absl-py, wrapt, typing-extensions, termcolor, clang, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.4.0\n",
            "    Uninstalling typing-extensions-4.4.0:\n",
            "      Successfully uninstalled typing-extensions-4.4.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.1.1\n",
            "    Uninstalling termcolor-2.1.1:\n",
            "      Successfully uninstalled termcolor-2.1.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow installieren\n",
        "\n",
        "!pip install tensorflow==\"2.6.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpha2-F_SGBj"
      },
      "outputs": [],
      "source": [
        "# Tensorflow Models klonen, wenn es noch nicht vorhanden ist\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "1sqMO9kGk9h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmr2UdV_SHuc"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzXxTBXHSNqA"
      },
      "outputs": [],
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exportieren in TF-Lite Inference Graph (Frozen Model) --> nur SSD MobileNet verwendbar"
      ],
      "metadata": {
        "id": "67b-eJAXf_hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = '/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/ssd_efficientdet_d1_640x640_coco17_tpu-8.config'\n",
        "training_folder = '/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100'"
      ],
      "metadata": {
        "id": "1RB-H-Tjf_DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kann auch komplett weggelassen werden \n",
        "\n",
        "\n",
        "output_directory = training_folder+'/inference_graph_tfLite'\n",
        "#%mkdir {output_directory}\n",
        "\n",
        "!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
        "    --pipeline_config_path {config_path} --trained_checkpoint_dir {training_folder} --output_directory {output_directory}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRLzGGsTfBrd",
        "outputId": "f11c2fe5-eb30-4b2b-c15c-b6e3b0135098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-18 15:13:38.650713: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-18 15:13:40.478498: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-18 15:13:40.478802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-18 15:13:40.478848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-18 15:13:45.014818: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "I1118 15:13:45.084689 140108206606208 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1118 15:13:45.085107 140108206606208 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1118 15:13:45.085250 140108206606208 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1118 15:13:45.095725 140108206606208 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 15:13:45.176436 140108206606208 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1118 15:13:45.176704 140108206606208 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 15:13:45.570574 140108206606208 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1118 15:13:45.570948 140108206606208 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 15:13:46.463803 140108206606208 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1118 15:13:46.464139 140108206606208 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 15:13:47.172545 140108206606208 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1118 15:13:47.172896 140108206606208 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 15:13:48.064653 140108206606208 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1118 15:13:48.064956 140108206606208 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 15:13:48.781989 140108206606208 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1118 15:13:48.782228 140108206606208 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 15:13:49.585243 140108206606208 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1118 15:13:49.585479 140108206606208 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1118 15:13:49.961947 140108206606208 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1118 15:13:50.083632 140108206606208 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/export_tflite_graph_tf2.py\", line 160, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/export_tflite_graph_tf2.py\", line 156, in main\n",
            "    FLAGS.centernet_include_keypoints, FLAGS.keypoint_label_map_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/export_tflite_graph_lib_tf2.py\", line 347, in export_tflite_model\n",
            "    max_detections, use_regular_nms)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/export_tflite_graph_lib_tf2.py\", line 70, in __init__\n",
            "    self._process_config(pipeline_config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/export_tflite_graph_lib_tf2.py\", line 103, in _process_config\n",
            "    image_resizer_config.WhichOneof('image_resizer_oneof')))\n",
            "ValueError: Only fixed_shape_resizeris supported with tflite. Found keep_aspect_ratio_resizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converter = tf.lite.TFLiteConverter.from_saved_model('/content/drive/My Drive/efficientdet_d0_coco17_tpu-32/saved_model/',signature_keys=['serving_default'])\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.experimental_new_converter = True\n",
        "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "# tflite_model = converter.convert()\n",
        "\n",
        "# with tf.io.gfile.GFile('model.tflite', 'wb') as f:\n",
        "#   f.write(tflite_model)"
      ],
      "metadata": {
        "id": "6BfyDROcQ1EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite_support_nightly"
      ],
      "metadata": {
        "id": "a2CuOt4XseBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "%cd {training_folder}\n",
        "%pwd"
      ],
      "metadata": {
        "id": "vAtzJODotccV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "saved_model_dir = '/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/inference_graph/saved_model'\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel director\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.experimental_new_converter = True\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('effdetD1.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "wSKtdn6ooA3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tflite_support.metadata_writers import object_detector\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "from tflite_support import metadata\n",
        "import flatbuffers\n",
        "import os\n",
        "from tensorflow_lite_support.metadata import metadata_schema_py_generated as _metadata_fb\n",
        "from tensorflow_lite_support.metadata.python import metadata as _metadata\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import metadata_info\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import metadata_writer\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import writer_utils\n",
        " \n",
        "ObjectDetectorWriter = object_detector.MetadataWriter\n",
        " \n",
        "_MODEL_PATH = \"/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/inference_graph/effdetD1.tflite\"\n",
        "_LABEL_FILE = \"/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/inference_graph/labelmap.txt\"\n",
        "_SAVE_TO_PATH = \"/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/inference_graph/effdetD1_meta.tflite\"\n",
        " \n",
        "writer = ObjectDetectorWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [127.5], [127.5], [_LABEL_FILE])\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)\n",
        " \n",
        "# Verify the populated metadata and associated files.\n",
        "displayer = metadata.MetadataDisplayer.with_model_file(_SAVE_TO_PATH)\n",
        "print(\"Metadata populated:\")\n",
        "print(displayer.get_metadata_json())\n",
        "print(\"Associated file(s) populated:\")\n",
        "print(displayer.get_packed_associated_file_list())\n",
        " \n",
        "model_meta = _metadata_fb.ModelMetadataT()\n",
        "model_meta.name = \"SSD_Detector\"\n",
        "model_meta.description = (\n",
        "    \"Identify which of a known set of objects might be present and provide \"\n",
        "    \"information about their positions within the given image or a video \"\n",
        "    \"stream.\")\n",
        " \n",
        "# Creates input info.\n",
        "input_meta = _metadata_fb.TensorMetadataT()\n",
        "input_meta.name = \"image\"\n",
        "input_meta.content = _metadata_fb.ContentT()\n",
        "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
        "input_meta.content.contentProperties.colorSpace = (\n",
        "    _metadata_fb.ColorSpaceType.RGB)\n",
        "input_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.ImageProperties)\n",
        "input_normalization = _metadata_fb.ProcessUnitT()\n",
        "input_normalization.optionsType = (\n",
        "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
        "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
        "input_normalization.options.mean = [127.5]\n",
        "input_normalization.options.std = [127.5]\n",
        "input_meta.processUnits = [input_normalization]\n",
        "input_stats = _metadata_fb.StatsT()\n",
        "input_stats.max = [255]\n",
        "input_stats.min = [0]\n",
        "input_meta.stats = input_stats\n",
        " \n",
        "# Creates outputs info.\n",
        "output_location_meta = _metadata_fb.TensorMetadataT()\n",
        "output_location_meta.name = \"location\"\n",
        "output_location_meta.description = \"The locations of the detected boxes.\"\n",
        "output_location_meta.content = _metadata_fb.ContentT()\n",
        "output_location_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.BoundingBoxProperties)\n",
        "output_location_meta.content.contentProperties = (\n",
        "    _metadata_fb.BoundingBoxPropertiesT())\n",
        "output_location_meta.content.contentProperties.index = [1, 0, 3, 2]\n",
        "output_location_meta.content.contentProperties.type = (\n",
        "    _metadata_fb.BoundingBoxType.BOUNDARIES)\n",
        "output_location_meta.content.contentProperties.coordinateType = (\n",
        "    _metadata_fb.CoordinateType.RATIO)\n",
        "output_location_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_location_meta.content.range.min = 2\n",
        "output_location_meta.content.range.max = 2\n",
        " \n",
        "output_class_meta = _metadata_fb.TensorMetadataT()\n",
        "output_class_meta.name = \"category\"\n",
        "output_class_meta.description = \"The categories of the detected boxes.\"\n",
        "output_class_meta.content = _metadata_fb.ContentT()\n",
        "output_class_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_class_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        "output_class_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_class_meta.content.range.min = 2\n",
        "output_class_meta.content.range.max = 2\n",
        "label_file = _metadata_fb.AssociatedFileT()\n",
        "label_file.name = os.path.basename(\"labelmap.txt\")\n",
        "label_file.description = \"Label of objects that this model can recognize.\"\n",
        "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_VALUE_LABELS\n",
        "output_class_meta.associatedFiles = [label_file]\n",
        " \n",
        "output_score_meta = _metadata_fb.TensorMetadataT()\n",
        "output_score_meta.name = \"score\"\n",
        "output_score_meta.description = \"The scores of the detected boxes.\"\n",
        "output_score_meta.content = _metadata_fb.ContentT()\n",
        "output_score_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_score_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        "output_score_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_score_meta.content.range.min = 2\n",
        "output_score_meta.content.range.max = 2\n",
        " \n",
        "output_number_meta = _metadata_fb.TensorMetadataT()\n",
        "output_number_meta.name = \"number of detections\"\n",
        "output_number_meta.description = \"The number of the detected boxes.\"\n",
        "output_number_meta.content = _metadata_fb.ContentT()\n",
        "output_number_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_number_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        " \n",
        "# Creates subgraph info.\n",
        "group = _metadata_fb.TensorGroupT()\n",
        "group.name = \"detection result\"\n",
        "group.tensorNames = [\n",
        "    output_location_meta.name, output_class_meta.name,\n",
        "    output_score_meta.name\n",
        "]\n",
        "subgraph = _metadata_fb.SubGraphMetadataT()\n",
        "subgraph.inputTensorMetadata = [input_meta]\n",
        "subgraph.outputTensorMetadata = [\n",
        "    output_location_meta, output_class_meta, output_score_meta,\n",
        "    output_number_meta\n",
        "]\n",
        "subgraph.outputTensorGroups = [group]\n",
        "model_meta.subgraphMetadata = [subgraph]\n",
        " \n",
        "b = flatbuffers.Builder(0)\n",
        "b.Finish(\n",
        "    model_meta.Pack(b),\n",
        "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
        "metadata_buf = b.Output()"
      ],
      "metadata": {
        "id": "u7J_0Pwyuly1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}