{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelSeitz98/Seminararbeit/blob/main/Schwellenwertanalyse_Inferenzanwendung_Bild_mit_Einteilung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2tc4yQ8KdZX",
        "outputId": "29a8b116-e41c-47f6-cb87-d61c5e446e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxwSyAOwLNEX"
      },
      "source": [
        "# Tensorflow OD API installieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LiQs7KXJKjev",
        "outputId": "83579601-0d9d-444b-8c3b-442b9237d26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.6.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.6.0%2Bzzzcolab20220506153740-cp37-cp37m-linux_x86_64.whl (564.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 564.4 MB 2.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.50.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.19.6)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.38.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.0)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.4.0)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.2.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.1)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.1.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.0) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (3.2.2)\n",
            "Building wheels for collected packages: clang, termcolor, wrapt\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=3d340dba9fcb9f6a33e588ae3079980b394628654dcc12797f7eb0000386f0b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/91/04/971b4c587cf47ae952b108949b46926f426c02832d120a082a\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=5f025ca676996e1d4b06015937d3d6922a733340307aa53bfcca0d1030e65a75\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68721 sha256=5ff2d21b6cbc57f92b17c152dfd1f0d2e352d4093dc5a1b717354493c2611afb\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built clang termcolor wrapt\n",
            "Installing collected packages: typing-extensions, numpy, absl-py, wrapt, termcolor, clang, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.1.0\n",
            "    Uninstalling termcolor-2.1.0:\n",
            "      Successfully uninstalled termcolor-2.1.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "pydantic 1.10.2 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.23 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 clang-5.0 numpy-1.19.5 tensorflow-2.6.0+zzzcolab20220506153740 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Tensorflow installieren\n",
        "\n",
        "!pip install tensorflow==\"2.6.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpha2-F_SGBj",
        "outputId": "f8bb4862-09d0-4a96-aec5-9e18bbe2ed92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3529, done.\u001b[K\n",
            "remote: Counting objects: 100% (3529/3529), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2941/2941), done.\u001b[K\n",
            "remote: Total 3529 (delta 928), reused 1437 (delta 534), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3529/3529), 47.00 MiB | 27.90 MiB/s, done.\n",
            "Resolving deltas: 100% (928/928), done.\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow Models klonen, wenn es noch nicht vorhanden ist\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmr2UdV_SHuc",
        "outputId": "c9510aeb-3451-47d3-c047-4402c9bbab7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.42.0-cp37-cp37m-manylinux2010_x86_64.whl (11.0 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Collecting tensorflow-text~=2.10.0\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Collecting tensorflow~=2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "Collecting numpy>=1.17\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.14.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2022.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Collecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.27.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.50.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.22.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (506 kB)\n",
            "Collecting cloudpickle~=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n",
            "Building wheels for collected packages: object-detection, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696454 sha256=02ddfa5d0c4615e41a6b617161b73642fce796ae62bd07727c9bcb63d0545604\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2hi6jmb2/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=e2666c70ff5cd1969170bd962de0242d82730dc1adf0f594154fb421b3f6abf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=3db8f61ed8b5b05dbbd1ee76cee192297c08b95ec18d5596318618432f49c17f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=6ec39903138b4d85593f9f77a5efffedafcef06363337c7a70120d2b19589fc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16182 sha256=4891f5b31746648734821dac9f9bda089e99e9b7e55ce75f59bc53971623ebb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, numpy, absl-py, tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, portalocker, docopt, dill, colorama, zstandard, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, orjson, opencv-python-headless, immutabledict, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.15.0\n",
            "    Uninstalling absl-py-0.15.0:\n",
            "      Successfully uninstalled absl-py-0.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0+zzzcolab20220506153740\n",
            "    Uninstalling tensorflow-2.6.0+zzzcolab20220506153740:\n",
            "      Successfully uninstalled tensorflow-2.6.0+zzzcolab20220506153740\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.2\n",
            "    Uninstalling pymongo-4.3.2:\n",
            "      Successfully uninstalled pymongo-4.3.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed absl-py-1.3.0 apache-beam-2.42.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 flatbuffers-22.10.26 hdfs-2.7.0 immutabledict-2.2.3 keras-2.10.0 lvis-0.5.3 numpy-1.21.6 object-detection-0.1 opencv-python-headless-4.5.2.52 orjson-3.8.1 portalocker-2.6.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.10.0 tensorflow-io-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.0 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
          ]
        }
      ],
      "source": [
        "# Installieren der Object Detection API \n",
        "\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzXxTBXHSNqA",
        "outputId": "1f4da1b0-056f-4e64-9edd-0ce22ed4f36e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-14 13:14:32.228841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-14 13:14:32.442500: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-14 13:14:33.776006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-14 13:14:33.776253: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-14 13:14:33.776291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-14 13:14:39.874047: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-11-14 13:14:39.874134: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e8f09b5f1e17): /proc/driver/nvidia/version does not exist\n",
            "Running tests under Python 3.7.15: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-11-14 13:14:39.887258: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "W1114 13:14:40.662707 140415045298048 model_builder.py:1109] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.35s\n",
            "I1114 13:14:41.231339 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.35s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.96s\n",
            "I1114 13:14:43.194782 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.96s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.73s\n",
            "I1114 13:14:43.925112 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.73s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.2s\n",
            "I1114 13:14:45.122018 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.2s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 8.68s\n",
            "I1114 13:14:53.805805 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 8.68s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1114 13:14:53.826581 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.12s\n",
            "I1114 13:14:53.949971 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.07s\n",
            "I1114 13:14:54.023724 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.07s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.1s\n",
            "I1114 13:14:54.124804 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.61s\n",
            "I1114 13:14:54.741253 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.61s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.44s\n",
            "I1114 13:14:55.194269 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.44s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.46s\n",
            "I1114 13:14:55.657215 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.46s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.41s\n",
            "I1114 13:14:56.070961 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.41s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.49s\n",
            "I1114 13:14:56.569640 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.49s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n",
            "I1114 13:14:56.644296 140415045298048 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1114 13:14:57.748253 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1114 13:14:57.748668 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I1114 13:14:57.748902 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 3\n",
            "I1114 13:14:57.790620 140415045298048 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1114 13:14:57.971956 140415045298048 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1114 13:14:57.972220 140415045298048 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1114 13:14:58.421961 140415045298048 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1114 13:14:58.422228 140415045298048 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1114 13:14:59.170186 140415045298048 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1114 13:14:59.170468 140415045298048 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1114 13:15:00.221532 140415045298048 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1114 13:15:00.221779 140415045298048 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1114 13:15:01.783380 140415045298048 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1114 13:15:01.783649 140415045298048 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1114 13:15:02.430927 140415045298048 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1114 13:15:02.431134 140415045298048 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1114 13:15:02.947690 140415045298048 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1114 13:15:02.947914 140415045298048 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1114 13:15:03.077116 140415045298048 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1114 13:15:03.150010 140415045298048 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1114 13:15:03.212352 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1114 13:15:03.212552 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1114 13:15:03.212631 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1114 13:15:03.214448 140415045298048 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1114 13:15:03.240247 140415045298048 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1114 13:15:03.240443 140415045298048 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1114 13:15:03.416092 140415045298048 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1114 13:15:03.416290 140415045298048 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1114 13:15:03.734385 140415045298048 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1114 13:15:03.734580 140415045298048 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1114 13:15:04.058834 140415045298048 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1114 13:15:04.059037 140415045298048 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1114 13:15:04.502191 140415045298048 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1114 13:15:04.502377 140415045298048 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1114 13:15:04.964033 140415045298048 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1114 13:15:04.964273 140415045298048 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1114 13:15:05.611725 140415045298048 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1114 13:15:05.611941 140415045298048 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1114 13:15:05.982907 140415045298048 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1114 13:15:06.152216 140415045298048 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1114 13:15:06.381212 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1114 13:15:06.381476 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I1114 13:15:06.381584 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 5\n",
            "I1114 13:15:06.384598 140415045298048 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1114 13:15:06.420703 140415045298048 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1114 13:15:06.420971 140415045298048 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1114 13:15:06.707894 140415045298048 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1114 13:15:06.708101 140415045298048 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1114 13:15:07.336360 140415045298048 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1114 13:15:07.336678 140415045298048 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1114 13:15:08.730687 140415045298048 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1114 13:15:08.730998 140415045298048 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1114 13:15:10.169218 140415045298048 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1114 13:15:10.169497 140415045298048 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1114 13:15:10.691106 140415045298048 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1114 13:15:10.691311 140415045298048 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1114 13:15:11.408156 140415045298048 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1114 13:15:11.408369 140415045298048 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1114 13:15:11.730611 140415045298048 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1114 13:15:11.816789 140415045298048 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1114 13:15:11.894950 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1114 13:15:11.895164 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I1114 13:15:11.895260 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 6\n",
            "I1114 13:15:11.897232 140415045298048 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1114 13:15:11.920663 140415045298048 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1114 13:15:11.920876 140415045298048 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1114 13:15:12.116026 140415045298048 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1114 13:15:12.116228 140415045298048 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1114 13:15:12.449725 140415045298048 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1114 13:15:12.449949 140415045298048 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1114 13:15:12.974023 140415045298048 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1114 13:15:12.974220 140415045298048 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1114 13:15:13.538861 140415045298048 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1114 13:15:13.539062 140415045298048 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1114 13:15:14.169399 140415045298048 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1114 13:15:14.169619 140415045298048 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1114 13:15:15.022609 140415045298048 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1114 13:15:15.022828 140415045298048 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1114 13:15:15.371783 140415045298048 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1114 13:15:15.455745 140415045298048 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1114 13:15:15.534907 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1114 13:15:15.535106 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I1114 13:15:15.535166 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1114 13:15:15.537092 140415045298048 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1114 13:15:15.565753 140415045298048 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1114 13:15:15.565965 140415045298048 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1114 13:15:15.759462 140415045298048 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1114 13:15:15.759712 140415045298048 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1114 13:15:16.219569 140415045298048 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1114 13:15:16.219805 140415045298048 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1114 13:15:16.696672 140415045298048 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1114 13:15:16.696880 140415045298048 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1114 13:15:17.426133 140415045298048 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1114 13:15:17.426347 140415045298048 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1114 13:15:18.176434 140415045298048 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1114 13:15:18.176652 140415045298048 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1114 13:15:19.313683 140415045298048 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1114 13:15:19.313900 140415045298048 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1114 13:15:19.670665 140415045298048 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1114 13:15:19.757869 140415045298048 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1114 13:15:19.852065 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1114 13:15:19.852271 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I1114 13:15:19.852364 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1114 13:15:19.854273 140415045298048 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1114 13:15:19.875454 140415045298048 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1114 13:15:19.875654 140415045298048 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1114 13:15:20.148357 140415045298048 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1114 13:15:20.148573 140415045298048 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1114 13:15:20.710289 140415045298048 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1114 13:15:20.710482 140415045298048 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1114 13:15:21.310004 140415045298048 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1114 13:15:21.310213 140415045298048 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1114 13:15:22.474117 140415045298048 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1114 13:15:22.474336 140415045298048 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1114 13:15:23.410223 140415045298048 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1114 13:15:23.410435 140415045298048 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1114 13:15:24.804967 140415045298048 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1114 13:15:24.805184 140415045298048 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1114 13:15:25.379383 140415045298048 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1114 13:15:25.479077 140415045298048 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1114 13:15:25.593644 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1114 13:15:25.593984 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1114 13:15:25.594116 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1114 13:15:25.596361 140415045298048 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1114 13:15:25.634645 140415045298048 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1114 13:15:25.634876 140415045298048 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1114 13:15:25.916423 140415045298048 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1114 13:15:25.916656 140415045298048 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1114 13:15:26.619619 140415045298048 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1114 13:15:26.619854 140415045298048 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1114 13:15:27.298124 140415045298048 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1114 13:15:27.298333 140415045298048 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1114 13:15:28.312691 140415045298048 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1114 13:15:28.312934 140415045298048 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1114 13:15:29.427911 140415045298048 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1114 13:15:29.428304 140415045298048 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1114 13:15:31.226284 140415045298048 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1114 13:15:31.226517 140415045298048 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1114 13:15:31.886368 140415045298048 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1114 13:15:31.990203 140415045298048 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1114 13:15:32.111062 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1114 13:15:32.111293 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1114 13:15:32.111389 140415045298048 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1114 13:15:32.113369 140415045298048 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1114 13:15:32.137320 140415045298048 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1114 13:15:32.137522 140415045298048 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1114 13:15:32.491318 140415045298048 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1114 13:15:32.491525 140415045298048 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1114 13:15:33.637953 140415045298048 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1114 13:15:33.638163 140415045298048 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1114 13:15:34.447359 140415045298048 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1114 13:15:34.447573 140415045298048 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1114 13:15:35.675586 140415045298048 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1114 13:15:35.675821 140415045298048 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1114 13:15:37.033361 140415045298048 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1114 13:15:37.033575 140415045298048 efficientnet_model.py:143] round_filter input=192 output=384\n"
          ]
        }
      ],
      "source": [
        "# Installation testen \n",
        "\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QypNOHDULJsk"
      },
      "source": [
        "# Modell & Labelmap laden\n",
        "\n",
        "Modell und LabelMap von meinem GitHub-Account laden, dass auch auch ohne Google Drive Zugriff ausführbar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyaHmSmyMEqt"
      },
      "outputs": [],
      "source": [
        "# LabelMap von meinem GitHub-Account laden\n",
        "\n",
        "%cd /content/\n",
        "!wget https://raw.githubusercontent.com/MichaelSeitz98/Seminararbeit/main/labelmap.pbtxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSTJU78pLJfd"
      },
      "outputs": [],
      "source": [
        "labelmap_path = '/content/labelmap.pbtxt'\n",
        "\n",
        "saved_model_dir = '/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/inference_graph/saved_model'\n",
        "speicherPfadEvalBilder = '/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/angewendeteBilder_train'\n",
        "schwellenwertanaye_speicherPfadEvalBilder = '/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/schwellenwertanalyse_val/'\n",
        "\n",
        "OUTPUT_PATH_DANGER = f'{speicherPfadEvalBilder}/Danger'\n",
        "OUTPUT_PATH_NO_DANGER = f'{speicherPfadEvalBilder}/No_Danger'\n",
        "\n",
        "print (OUTPUT_PATH_DANGER)\n",
        "\n",
        "if (not os.path.isdir(schwellenwertanaye_speicherPfadEvalBilder)): \n",
        "    %mkdir {speicherPfadEvalBilder}\n",
        "    print(f'Ordner erzeugt: {schwellenwertanaye_speicherPfadEvalBilder}')\n",
        "else:\n",
        "    print(f'Ordner: {schwellenwertanaye_speicherPfadEvalBilder} existiert schon')\n",
        "\n",
        "%mkdir {OUTPUT_PATH_DANGER}\n",
        "%mkdir {OUTPUT_PATH_NO_DANGER}\n",
        "\n",
        "input_bilder_pfad_train = '/content/drive/MyDrive/DS2_POOLG_80_20_20/train'\n",
        "input_bilder_pfad_val ='/content/drive/MyDrive/DS2_POOLG_80_20_20/validation'\n",
        "input_bilder_pfad_test ='/content/drive/MyDrive/DS2_POOLG_80_20_20/test'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp4wlWrhxyJL"
      },
      "outputs": [],
      "source": [
        "# Alle benötigte packages für die Inferenz importiert\n",
        "\n",
        "import io\n",
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import six\n",
        "import time\n",
        "import glob\n",
        "from IPython.display import display\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEaYWo8WyLS2"
      },
      "outputs": [],
      "source": [
        "# Methode um aus Image ein Numpy_array zu machen \n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path (this can be local or on colossus)\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxWU7K_oyVwq"
      },
      "outputs": [],
      "source": [
        "# Label map Category Index erzeugen\n",
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)\n",
        "\n",
        "print(f'Catergory Index erzeugt aus LabelMap: {labelmap_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkMddTneyesG"
      },
      "outputs": [],
      "source": [
        "# TODO: noch saved_model_dir zuerst über wget aus meinem GitHub-Account laden\n",
        "# Das Modell wird hier reingeladen. Kann bis zu 2 Minuten dauern. \n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(saved_model_dir)\n",
        "\n",
        "print(f'Trainiertes Model erfolgreich geladen von: {saved_model_dir}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxAf3XJBzLHq"
      },
      "outputs": [],
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEX-m3P1yp4y"
      },
      "outputs": [],
      "source": [
        "# Ab hier geht dann die Erkennung los\n",
        "# Jedes Bild aus Test-Eval-Ordner wird untersucht\n",
        "# und in den SpeicherPfadEvalBilder abgespeichert. \n",
        "\n",
        "bilderCounter = 0\n",
        "danger = False\n",
        "CONFIDENT_SCORE_THRESHOLD_CHILD = 0.50\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for image_path in glob.glob(f'{input_bilder_pfad_test}/*.jpg'):\n",
        "  danger = False\n",
        "  print(f'aktueller image_path:{image_path}')\n",
        "  start_time_pro_bild = time.time()\n",
        "  bilderCounter+=1\n",
        "  image_name = os.path.basename(image_path).replace(\".jpg\", \"\")\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "\n",
        "  # Postprocessing\n",
        "\n",
        "  classes_child = output_dict['detection_classes']\n",
        "  scores_child = output_dict['detection_scores']\n",
        "  boxes_child = output_dict[\"detection_boxes\"]\n",
        "\n",
        "  for i in range(0, len(classes_child)):\n",
        "      if classes_child[i] == 1 and scores_child[i] >= CONFIDENT_SCORE_THRESHOLD_CHILD:\n",
        "              danger = True\n",
        "              print (\"Dangerous! Child detected!\")\n",
        "\n",
        "  outImg = vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=CONFIDENT_SCORE_THRESHOLD_CHILD,\n",
        "      max_boxes_to_draw=15,\n",
        "      line_thickness=3)\n",
        "  \n",
        "  im = Image.fromarray(outImg)\n",
        "  #display(Image.fromarray(image_np))\n",
        "    \n",
        "  if (danger):\n",
        "        im.save(f'{OUTPUT_PATH_DANGER}/{image_name}_boxed_danger.jpg')\n",
        "        print ('Hier gespeichert: ' + OUTPUT_PATH_DANGER + \"/\" + image_name + \"_boxed.jpg\")\n",
        "  else:\n",
        "        print('Keine Gefahr. Kein Kind entdeckt')\n",
        "        im.save(f'{OUTPUT_PATH_NO_DANGER}/{image_name}_boxed_no_danger.jpg')\n",
        "        print(image_name + \" gespeichert: No Danger.\\n\")\n",
        "\n",
        "print(f'Fertig! Modell auf {bilderCounter} Bilder angewendet und unter {speicherPfadEvalBilder} gespeichert.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPpGqpJ9z+J/+E2DWYgvSqv",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "1Y8_6tT61QY1ZdS2x3IFJvZNpaZdUGCAu",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "684e43cc1e83511fd33211d8d27c6e3a5e512c908c18c12e90a79baa740b01c0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
