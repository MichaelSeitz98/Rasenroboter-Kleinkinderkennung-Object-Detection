{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelSeitz98/Seminararbeit/blob/main/Inferenzanwendung_Bild_mit_Einteilung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxwSyAOwLNEX"
      },
      "source": [
        "# Tensorflow OD API installieren\n",
        "\n",
        "Beschreibung einfügen\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2tc4yQ8KdZX",
        "outputId": "82066d38-20ac-4d59-f77e-6d2da3e5ee6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Meine GoogleDrive mounten\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LiQs7KXJKjev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "575049fe-4eb6-47e0-e277-11fce0826dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.6.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.6.0%2Bzzzcolab20220506153740-cp37-cp37m-linux_x86_64.whl (564.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 564.4 MB 2.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.19.6)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.50.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.1)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 16.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.38.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.1.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.3.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.0) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (3.2.2)\n",
            "Building wheels for collected packages: clang, termcolor, wrapt\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=50e78078596831697d2a852555ca19239fa2233f34cf87bab842b560924cc578\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/91/04/971b4c587cf47ae952b108949b46926f426c02832d120a082a\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=72383dc5af97976e211638fcb0b3d5a3dfdb695711b4431225ce9ca11118890b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68723 sha256=1430400d6e25a0563e2819eee4ff614bb3bf8d471129e9b2a98cc281f8c2fcc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built clang termcolor wrapt\n",
            "Installing collected packages: typing-extensions, numpy, absl-py, wrapt, termcolor, clang, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.1.0\n",
            "    Uninstalling termcolor-2.1.0:\n",
            "      Successfully uninstalled termcolor-2.1.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "pydantic 1.10.2 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.23 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 clang-5.0 numpy-1.19.5 tensorflow-2.6.0+zzzcolab20220506153740 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "absl",
                  "numpy",
                  "tensorflow",
                  "termcolor",
                  "typing_extensions",
                  "wrapt"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Tensorflow installieren -> Dauer: circa 1 min\n",
        "!pip install tensorflow==\"2.6.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Kpha2-F_SGBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9fba47-0229-437e-bb6e-a1e14b16c974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3529, done.\u001b[K\n",
            "remote: Counting objects: 100% (3529/3529), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2939/2939), done.\u001b[K\n",
            "remote: Total 3529 (delta 933), reused 1514 (delta 536), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3529/3529), 47.00 MiB | 25.40 MiB/s, done.\n",
            "Resolving deltas: 100% (933/933), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Tensorflow models repository klonen, wenn es noch nicht vorhanden ist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rmr2UdV_SHuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0887534-5d4a-4cb9-e27f-a37dcb54e6a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.42.0-cp37-cp37m-manylinux2010_x86_64.whl (11.0 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting numpy>=1.17\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting tensorflow~=2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting tensorflow-text~=2.10.0\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.14.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2022.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.27.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.50.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Collecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting cloudpickle~=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (506 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.22.1)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.9.0)\n",
            "Building wheels for collected packages: object-detection, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696454 sha256=bddb3114f69206b29cd84de31cb6e57ba0ec44a834b7f16b2832a4b56f21bbd7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_gtf82pf/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=a5bfd18fb25cd8917f3d3feb854d2c9ebed605d49ff39a1356809225def886e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=5eb79e55553f92e00c9f70d01fb5851ad86eaf822df87116adbcce2e2b37455a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=54883a34c0b9605151fd1144d782c49c58fbe592d7021766ca4bd08d76f5bc31\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16182 sha256=ccf0db8c273f88a080853d9af54485128d15006badf9147a9e193088e66b44ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, numpy, absl-py, tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, portalocker, docopt, dill, colorama, zstandard, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, orjson, opencv-python-headless, immutabledict, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.15.0\n",
            "    Uninstalling absl-py-0.15.0:\n",
            "      Successfully uninstalled absl-py-0.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0+zzzcolab20220506153740\n",
            "    Uninstalling tensorflow-2.6.0+zzzcolab20220506153740:\n",
            "      Successfully uninstalled tensorflow-2.6.0+zzzcolab20220506153740\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.2\n",
            "    Uninstalling pymongo-4.3.2:\n",
            "      Successfully uninstalled pymongo-4.3.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed absl-py-1.3.0 apache-beam-2.42.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 flatbuffers-22.10.26 hdfs-2.7.0 immutabledict-2.2.3 keras-2.10.0 lvis-0.5.3 numpy-1.21.6 object-detection-0.1 opencv-python-headless-4.5.2.52 orjson-3.8.1 portalocker-2.6.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.10.0 tensorflow-io-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.0 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
          ]
        }
      ],
      "source": [
        "# Installieren der Object Detection API \n",
        "# Kann bis zu 5 min dauern. \n",
        "\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XzXxTBXHSNqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98aab066-a74d-4947-a757-5f9acba9b96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-12 15:11:47.409695: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-12 15:11:48.580105: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-12 15:11:48.580331: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-12 15:11:48.580361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-12 15:11:52.145458: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Running tests under Python 3.7.15: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "W1112 15:11:53.014981 139917727238016 model_builder.py:1109] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.07s\n",
            "I1112 15:11:54.221467 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.07s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 2.54s\n",
            "I1112 15:11:56.761901 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 2.54s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 1.33s\n",
            "I1112 15:11:58.097327 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 1.33s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.52s\n",
            "I1112 15:11:59.618592 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 1.52s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 8.9s\n",
            "I1112 15:12:08.523555 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 8.9s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1112 15:12:08.530854 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.06s\n",
            "I1112 15:12:08.590739 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "I1112 15:12:08.630546 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I1112 15:12:08.666568 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.35s\n",
            "I1112 15:12:09.022046 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.35s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.29s\n",
            "I1112 15:12:09.308345 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.25s\n",
            "I1112 15:12:09.568266 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.26s\n",
            "I1112 15:12:09.833910 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.24s\n",
            "I1112 15:12:10.071638 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n",
            "I1112 15:12:10.139664 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1112 15:12:10.604278 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1112 15:12:10.612933 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I1112 15:12:10.613140 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 3\n",
            "I1112 15:12:10.625319 139917727238016 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 15:12:10.712047 139917727238016 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 15:12:10.712316 139917727238016 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 15:12:10.929909 139917727238016 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 15:12:10.930119 139917727238016 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 15:12:11.362084 139917727238016 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 15:12:11.362367 139917727238016 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 15:12:11.866177 139917727238016 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 15:12:11.866421 139917727238016 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 15:12:12.918348 139917727238016 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 15:12:12.918625 139917727238016 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 15:12:14.033613 139917727238016 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 15:12:14.033935 139917727238016 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 15:12:14.827586 139917727238016 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 15:12:14.827817 139917727238016 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1112 15:12:14.964906 139917727238016 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1112 15:12:15.052190 139917727238016 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 15:12:15.120820 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1112 15:12:15.121047 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1112 15:12:15.121113 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1112 15:12:15.123073 139917727238016 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 15:12:15.145874 139917727238016 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 15:12:15.146067 139917727238016 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 15:12:15.333010 139917727238016 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 15:12:15.333216 139917727238016 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 15:12:15.684746 139917727238016 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 15:12:15.684985 139917727238016 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 15:12:16.034417 139917727238016 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 15:12:16.034624 139917727238016 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 15:12:16.522298 139917727238016 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 15:12:16.522521 139917727238016 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 15:12:17.007020 139917727238016 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 15:12:17.007230 139917727238016 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 15:12:17.675875 139917727238016 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 15:12:17.676080 139917727238016 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1112 15:12:17.977407 139917727238016 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1112 15:12:18.050496 139917727238016 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 15:12:18.133933 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1112 15:12:18.134146 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I1112 15:12:18.134240 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 5\n",
            "I1112 15:12:18.136227 139917727238016 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 15:12:18.159096 139917727238016 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 15:12:18.159306 139917727238016 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 15:12:18.341979 139917727238016 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 15:12:18.342189 139917727238016 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 15:12:18.707898 139917727238016 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 15:12:18.708109 139917727238016 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1112 15:12:19.072042 139917727238016 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1112 15:12:19.072254 139917727238016 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1112 15:12:19.580497 139917727238016 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1112 15:12:19.580723 139917727238016 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1112 15:12:20.089481 139917727238016 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1112 15:12:20.089701 139917727238016 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1112 15:12:20.780240 139917727238016 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1112 15:12:20.780455 139917727238016 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1112 15:12:21.099745 139917727238016 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1112 15:12:21.188519 139917727238016 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 15:12:21.260466 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1112 15:12:21.260677 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I1112 15:12:21.260788 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 6\n",
            "I1112 15:12:21.262727 139917727238016 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1112 15:12:21.286875 139917727238016 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1112 15:12:21.287231 139917727238016 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 15:12:21.498227 139917727238016 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 15:12:21.498428 139917727238016 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1112 15:12:21.850561 139917727238016 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1112 15:12:21.850784 139917727238016 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1112 15:12:22.439039 139917727238016 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1112 15:12:22.439250 139917727238016 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1112 15:12:23.070832 139917727238016 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1112 15:12:23.071046 139917727238016 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1112 15:12:23.725293 139917727238016 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1112 15:12:23.725543 139917727238016 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1112 15:12:24.579695 139917727238016 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1112 15:12:24.579935 139917727238016 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1112 15:12:24.913025 139917727238016 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1112 15:12:24.996532 139917727238016 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 15:12:25.075716 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1112 15:12:25.075962 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I1112 15:12:25.076057 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1112 15:12:25.078086 139917727238016 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1112 15:12:25.103084 139917727238016 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1112 15:12:25.103301 139917727238016 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 15:12:25.308626 139917727238016 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 15:12:25.308877 139917727238016 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1112 15:12:25.771098 139917727238016 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1112 15:12:25.771314 139917727238016 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1112 15:12:26.257071 139917727238016 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1112 15:12:26.257294 139917727238016 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1112 15:12:27.001699 139917727238016 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1112 15:12:27.001916 139917727238016 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1112 15:12:27.770225 139917727238016 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1112 15:12:27.770438 139917727238016 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1112 15:12:28.963297 139917727238016 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1112 15:12:28.963516 139917727238016 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1112 15:12:29.326495 139917727238016 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1112 15:12:29.427826 139917727238016 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 15:12:29.531003 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1112 15:12:29.531208 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I1112 15:12:29.531274 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1112 15:12:29.533261 139917727238016 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1112 15:12:29.557097 139917727238016 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1112 15:12:29.557285 139917727238016 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 15:12:29.828259 139917727238016 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 15:12:29.828456 139917727238016 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1112 15:12:30.405210 139917727238016 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1112 15:12:30.405436 139917727238016 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1112 15:12:31.021927 139917727238016 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1112 15:12:31.022140 139917727238016 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1112 15:12:32.175752 139917727238016 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1112 15:12:32.175992 139917727238016 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1112 15:12:33.116513 139917727238016 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1112 15:12:33.116721 139917727238016 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1112 15:12:34.499279 139917727238016 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1112 15:12:34.499509 139917727238016 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1112 15:12:35.108842 139917727238016 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1112 15:12:35.208718 139917727238016 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 15:12:35.316307 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1112 15:12:35.316521 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1112 15:12:35.316586 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1112 15:12:35.318531 139917727238016 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1112 15:12:35.343952 139917727238016 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1112 15:12:35.344163 139917727238016 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1112 15:12:35.644395 139917727238016 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1112 15:12:35.644596 139917727238016 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1112 15:12:36.344973 139917727238016 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1112 15:12:36.345197 139917727238016 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1112 15:12:37.100478 139917727238016 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1112 15:12:37.100674 139917727238016 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1112 15:12:38.140166 139917727238016 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1112 15:12:38.140393 139917727238016 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1112 15:12:39.223934 139917727238016 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1112 15:12:39.224153 139917727238016 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1112 15:12:41.025807 139917727238016 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1112 15:12:41.026023 139917727238016 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1112 15:12:41.697972 139917727238016 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1112 15:12:41.800518 139917727238016 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 15:12:41.921127 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1112 15:12:41.921378 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1112 15:12:41.921493 139917727238016 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1112 15:12:41.924601 139917727238016 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1112 15:12:41.951547 139917727238016 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1112 15:12:41.951740 139917727238016 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1112 15:12:42.329399 139917727238016 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1112 15:12:42.329633 139917727238016 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1112 15:12:43.456463 139917727238016 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1112 15:12:43.456681 139917727238016 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1112 15:12:44.298649 139917727238016 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1112 15:12:44.298883 139917727238016 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1112 15:12:45.616709 139917727238016 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1112 15:12:45.616956 139917727238016 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1112 15:12:47.049347 139917727238016 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1112 15:12:47.049584 139917727238016 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1112 15:12:49.301397 139917727238016 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1112 15:12:49.301603 139917727238016 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1112 15:12:50.591974 139917727238016 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1112 15:12:50.783020 139917727238016 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 40.91s\n",
            "I1112 15:12:51.048401 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 40.91s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1112 15:12:51.097599 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1112 15:12:51.100832 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1112 15:12:51.101857 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1112 15:12:51.104876 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1112 15:12:51.107300 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1112 15:12:51.108016 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1112 15:12:51.109844 139917727238016 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 58.959s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "#Tests durchlaufen lassen \n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QypNOHDULJsk"
      },
      "source": [
        "# Modell & Labelmap laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZyaHmSmyMEqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f217cf5-dbb9-438c-dab3-e20d8b2c79e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-11-12 15:12:52--  https://raw.githubusercontent.com/MichaelSeitz98/Seminararbeit/main/labelmap.pbtxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37 [text/plain]\n",
            "Saving to: ‘labelmap.pbtxt’\n",
            "\n",
            "labelmap.pbtxt      100%[===================>]      37  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-12 15:12:52 (1.86 MB/s) - ‘labelmap.pbtxt’ saved [37/37]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LabelMap von meinem GitHub-Account laden #TODO: Checken, ob schon vorhanden\n",
        "# Drauf achten, ob 2-Klassige oder 1-Klassige\n",
        "%cd /content/\n",
        "\n",
        "!wget https://raw.githubusercontent.com/MichaelSeitz98/Seminararbeit/main/labelmap.pbtxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JSTJU78pLJfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af280b7d-268f-4422-a9c6-94f442166083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/angewendeteBilder_train/Danger\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/angewendeteBilder_train/Danger’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/angewendeteBilder_train/No_Danger’: File exists\n"
          ]
        }
      ],
      "source": [
        "labelmap_path = '/content/labelmap.pbtxt'\n",
        "\n",
        "saved_model_dir = '/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/inference_graph/saved_model'\n",
        "speicherPfadEvalBilder = '/content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/angewendeteBilder_train'\n",
        "\n",
        "\n",
        "OUTPUT_PATH_DANGER = f'{speicherPfadEvalBilder}/Danger'\n",
        "OUTPUT_PATH_NO_DANGER = f'{speicherPfadEvalBilder}/No_Danger'\n",
        "\n",
        "print (OUTPUT_PATH_DANGER)\n",
        "%mkdir {OUTPUT_PATH_DANGER}\n",
        "%mkdir {OUTPUT_PATH_NO_DANGER}\n",
        "\n",
        "\n",
        "input_bilder_pfad_train = '/content/drive/MyDrive/DS2_POOLG_80_20_20/train'\n",
        "input_bilder_pfad_val ='/content/drive/MyDrive/DS2_POOLG_80_20_20/validation'\n",
        "input_bilder_pfad_test ='/content/drive/MyDrive/DS2_POOLG_80_20_20/test'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hp4wlWrhxyJL"
      },
      "outputs": [],
      "source": [
        "# Alle benötigte packages für die Inferenz importiert\n",
        "\n",
        "import io\n",
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import six\n",
        "import time\n",
        "import glob\n",
        "from IPython.display import display\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NEaYWo8WyLS2"
      },
      "outputs": [],
      "source": [
        "# Methode um aus Image ein Numpy_array zu machen \n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path (this can be local or on colossus)\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxWU7K_oyVwq",
        "outputId": "999cace3-1279-40e3-8400-fed0481f3343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Catergory Index erzeugt aus LabelMap: /content/labelmap.pbtxt\n"
          ]
        }
      ],
      "source": [
        "# Label map Category Index erzeugen\n",
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)\n",
        "\n",
        "print(f'Catergory Index erzeugt aus LabelMap: {labelmap_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkMddTneyesG",
        "outputId": "61441cf7-c253-479b-95dd-3804731ced92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainiertes Model erfolgreich geladen von: /content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/inference_graph/saved_model\n"
          ]
        }
      ],
      "source": [
        "# Das Modell wird hier reingeladen. Kann bis zu 2 Minuten dauern. \n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(saved_model_dir)\n",
        "\n",
        "print(f'Trainiertes Model erfolgreich geladen von: {saved_model_dir}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kxAf3XJBzLHq"
      },
      "outputs": [],
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7hreAk_rcdvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a934ce-763e-4553-edd6-b75ce6690357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ordner: /content/drive/MyDrive/training_effdetd1_ds2_8_20000_100/angewendeteBilder_train existiert schon\n"
          ]
        }
      ],
      "source": [
        "# Erzeugen eines neuen Ordners: Bilder mit Boxen dort abgespeichert\n",
        "\n",
        "# prüfen, ob schon ein Output-Folder für die Bilder vorhanden. Wenn nein, Ordner erzeugen\n",
        "if (not os.path.isdir(speicherPfadEvalBilder)): \n",
        "    %mkdir {speicherPfadEvalBilder}\n",
        "    print(f'Ordner erzeugt: {speicherPfadEvalBilder}')\n",
        "else:    print(f'Ordner: {speicherPfadEvalBilder} existiert schon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEX-m3P1yp4y"
      },
      "outputs": [],
      "source": [
        "# Ab hier geht dann die Erkennung los\n",
        "# Jedes Bild aus Test-Eval-Ordner wird untersucht\n",
        "# und in den SpeicherPfadEvalBilder abgespeichert. \n",
        "\n",
        "bilderCounter = 0\n",
        "danger = False\n",
        "CONFIDENT_SCORE_THRESHOLD_CHILD = 0.60\n",
        "\n",
        "%mkdir {OUTPUT_PATH_DANGER}\n",
        "%mkdir {OUTPUT_PATH_NO_DANGER}\n",
        "\n",
        "for image_path in glob.glob(f'{input_bilder_pfad_train}/*.jpg'):\n",
        "  danger = False\n",
        "  print(f'aktueller image_path:{image_path}')\n",
        "  start_time_pro_bild = time.time()\n",
        "  bilderCounter+=1\n",
        "  image_name = os.path.basename(image_path).replace(\".jpg\", \"\")\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "\n",
        "  # Postprocessing\n",
        "\n",
        "  classes_child = output_dict['detection_classes']\n",
        "  scores_child = output_dict['detection_scores']\n",
        "  boxes_child = output_dict[\"detection_boxes\"]\n",
        "\n",
        "  for i in range(0, len(classes_child)):\n",
        "      if classes_child[i] == 1 and scores_child[i] >= CONFIDENT_SCORE_THRESHOLD_CHILD:\n",
        "              danger = True\n",
        "              print (\"Kind detektiert, Dangerous!\")\n",
        "\n",
        "  outImg = vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=CONFIDENT_SCORE_THRESHOLD_CHILD,\n",
        "      max_boxes_to_draw=15,\n",
        "      line_thickness=3)\n",
        "  \n",
        "  im = Image.fromarray(outImg)\n",
        "  #display(Image.fromarray(image_np))\n",
        "    \n",
        "  if (danger):\n",
        "        im.save(f'{OUTPUT_PATH_DANGER}/{image_name}_boxed_danger.jpg')\n",
        "        print ('Hier gespeichert: ' + OUTPUT_PATH_DANGER + \"/\" + image_name + \"_boxed.jpg\")\n",
        "  else:\n",
        "        im.save(f'{OUTPUT_PATH_NO_DANGER}/{image_name}_boxed_no_danger.jpg')\n",
        "        print(image_name + \" gespeichert: No Danger.\\n\")\n",
        "\n",
        "print(f'Fertig! Modell auf {bilderCounter} Bilder angewendet und unter {speicherPfadEvalBilder} gespeichert.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Versuch für Val die Metriken zu ziehen mit dem letzten Checkpoint \n",
        "\n",
        "# # alternativ eine test.record am ende erzeugen und damit auch die Test metric bekommen\n",
        "# !python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "#     --model_dir={saved_model_dir} \\\n",
        "#     --pipeline_config_path={pipeline_config_path} \\\n",
        "#     --num_eval_steps={num_eval_steps} \\ #bringt das was für den Verlauf?\n",
        "#     --checkpoint_dir={model_dir}"
      ],
      "metadata": {
        "id": "X62aJUkFVEOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1Y8_6tT61QY1ZdS2x3IFJvZNpaZdUGCAu",
      "authorship_tag": "ABX9TyNq9jwsn7ZEKtjl9Rt8kYwj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}