{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelSeitz98/Seminararbeit/blob/main/KindDetektion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPpk7TJDYKQ"
      },
      "source": [
        "##Google Drive mounten für Zugriff auf Datensatz und zum Speichern der trainierten Modelle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyqQx6KXZeYn",
        "outputId": "5229dd3c-4000-4460-ccf5-12aebcdec537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Verknüpfung mit meiner Google Drive herstellen\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iWJSS7DwGi3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ao4ZGNbbWzYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a12e35d-f2d9-42e2-a89d-237048a60fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100’: File exists\n"
          ]
        }
      ],
      "source": [
        "#Unbedingt vor jedem Trainingslauf ANPASSEN! SONST GANZES TRAININNG ÜBERSCHRIEBEN!\n",
        "\n",
        "training_folder = '/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100'\n",
        "\n",
        "%mkdir {training_folder}\n",
        "# Anpassen!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-xxNMX1Hbg0c"
      },
      "outputs": [],
      "source": [
        "# Sicherstellen, dass train_labels.csv dort vorhanden sind (in keinem Unterornder)\n",
        "\n",
        "datensatz_folder = '/content/drive/MyDrive/DS2_POOLG_80_20_20'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmtTY8_-blOm"
      },
      "source": [
        "##Vor jedem neuen Trainingslauf bearbeiten!\n",
        "\n",
        "Alle für Training benötigten Dateien werden in diesen Ordner auf der Drive abgespeichert.\n",
        " 1.) train.record\n",
        " 2.) test.record \n",
        " 3.) test_labels.csv\n",
        " 4.) train_labels.csv\n",
        " 5.) .config File\n",
        " 6.) labelMap (optional) \n",
        " 7.) dann noch das generateTF_Record_Script  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNT9cI_ZSCla"
      },
      "source": [
        "## Installation der Tensorflow OD API\n",
        "\n",
        "Muss bei jeder neuen Laufzeit neu installiert werden - auch für die Inferenzanwendung."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fTBYWlnKSD78",
        "outputId": "4465bdf5-7d33-4e06-82bd-9f6e2c39e583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.6.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.6.0%2Bzzzcolab20220506153740-cp37-cp37m-linux_x86_64.whl (564.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 564.4 MB 2.4 kB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.19.6)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.3.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.38.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (1.50.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (2.9.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 15.1 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0) (0.4.0)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 119 kB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.0) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (2.14.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6.0) (3.2.2)\n",
            "Building wheels for collected packages: clang, termcolor, wrapt\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=f1760ebed61a896994ed1357a09b3368266e6757f6b2c68203830fc8101b8350\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/91/04/971b4c587cf47ae952b108949b46926f426c02832d120a082a\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=135d73f6cc756f196f5116e62e0c193609b003c02d35040f745bfa3d15ab6025\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68706 sha256=23ad88c8bdf74cf0d1eebba6867635556c24e50c15c7e4d76adcf2461e5edbb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built clang termcolor wrapt\n",
            "Installing collected packages: typing-extensions, numpy, absl-py, wrapt, termcolor, clang, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.1.0\n",
            "    Uninstalling termcolor-2.1.0:\n",
            "      Successfully uninstalled termcolor-2.1.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "pydantic 1.10.2 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.23 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 clang-5.0 numpy-1.19.5 tensorflow-2.6.0+zzzcolab20220506153740 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Allgemeines Tensorflow installieren \n",
        "!pip install tensorflow==\"2.6.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpha2-F_SGBj",
        "outputId": "30bd547e-1d3b-433a-9b46-09221983935b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3529, done.\u001b[K\n",
            "remote: Counting objects: 100% (3529/3529), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2942/2942), done.\u001b[K\n",
            "remote: Total 3529 (delta 931), reused 1524 (delta 533), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3529/3529), 47.00 MiB | 28.87 MiB/s, done.\n",
            "Resolving deltas: 100% (931/931), done.\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow Modelle laden (wenn noch nicht vorhanden)\n",
        "import pathlib\n",
        "import os\n",
        " \n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1OaomtgSeMU",
        "outputId": "da6115fa-956a-4e70-b780-23365373309a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmr2UdV_SHuc",
        "outputId": "edfadb2d-3338-4cb3-c48d-ba5804883390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.42.0-cp37-cp37m-manylinux2010_x86_64.whl (11.0 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.19.5)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting tensorflow-text~=2.10.0\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "Collecting numpy>=1.17\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting tensorflow~=2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.14.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2022.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.27.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Collecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.50.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (506 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.22.1)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting cloudpickle~=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.9.0)\n",
            "Building wheels for collected packages: object-detection, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696454 sha256=bff860b1c9549370d3c51cc13c52858d94809f666a96ba53cc9647bcedda51e0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a67xd729/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=2092c4bea820a82b1416389971661d580d00565eeaa8a3fb424c723b51900f2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=f093d2ccf9454433abc1de62531914e0d4c0f88ef224be045b4578de0bd58503\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=5c2c377e6a12d791288eeb3274cc1a6d18bce99d88ec1531771f7267da480ca8\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16182 sha256=0ccb1749807e64affe387a2a9444ad65946a7d36e63e23f5b0ad3483b08431d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, numpy, absl-py, tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, portalocker, docopt, dill, colorama, zstandard, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, orjson, opencv-python-headless, immutabledict, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.15.0\n",
            "    Uninstalling absl-py-0.15.0:\n",
            "      Successfully uninstalled absl-py-0.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0+zzzcolab20220506153740\n",
            "    Uninstalling tensorflow-2.6.0+zzzcolab20220506153740:\n",
            "      Successfully uninstalled tensorflow-2.6.0+zzzcolab20220506153740\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.2\n",
            "    Uninstalling pymongo-4.3.2:\n",
            "      Successfully uninstalled pymongo-4.3.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed absl-py-1.3.0 apache-beam-2.42.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 flatbuffers-22.10.26 hdfs-2.7.0 immutabledict-2.2.3 keras-2.10.0 lvis-0.5.3 numpy-1.21.6 object-detection-0.1 opencv-python-headless-4.5.2.52 orjson-3.8.1 portalocker-2.6.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.10.0 tensorflow-io-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.0 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
          ]
        }
      ],
      "source": [
        "# Installation der Tensorflow Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzXxTBXHSNqA",
        "outputId": "05c43ddf-70cd-4de6-d6ca-ff116f83c536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-12 13:54:34.928135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 13:54:35.088158: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2022-11-12 13:54:35.117942: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-12 13:54:35.932412: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-12 13:54:35.932558: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-12 13:54:35.932577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Running tests under Python 3.7.15: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-11-12 13:54:38.345195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 13:54:39.246021: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-11-12 13:54:39.246096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38354 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "W1112 13:54:39.616635 139976399730560 model_builder.py:1109] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.54s\n",
            "I1112 13:54:39.878379 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.54s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n",
            "I1112 13:54:40.438092 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.27s\n",
            "I1112 13:54:40.706852 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.27s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.37s\n",
            "I1112 13:54:41.078080 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.37s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.46s\n",
            "I1112 13:54:43.533733 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.46s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1112 13:54:43.539754 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I1112 13:54:43.569369 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I1112 13:54:43.586602 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1112 13:54:43.605159 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "I1112 13:54:43.731829 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "I1112 13:54:43.849065 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "I1112 13:54:43.968096 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "I1112 13:54:44.081301 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "I1112 13:54:44.203485 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I1112 13:54:44.236861 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1112 13:54:44.430016 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1112 13:54:44.430195 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I1112 13:54:44.430269 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 3\n",
            "I1112 13:54:44.432849 139976399730560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 13:54:44.465505 139976399730560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 13:54:44.465675 139976399730560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 13:54:44.554764 139976399730560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 13:54:44.554938 139976399730560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 13:54:44.821780 139976399730560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 13:54:44.821966 139976399730560 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 13:54:45.046691 139976399730560 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 13:54:45.046920 139976399730560 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 13:54:45.383869 139976399730560 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 13:54:45.384041 139976399730560 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 13:54:45.888819 139976399730560 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 13:54:45.889059 139976399730560 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 13:54:46.309659 139976399730560 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 13:54:46.309839 139976399730560 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1112 13:54:46.410641 139976399730560 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1112 13:54:46.458366 139976399730560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 13:54:46.516174 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1112 13:54:46.516386 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1112 13:54:46.516450 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1112 13:54:46.518248 139976399730560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 13:54:46.540298 139976399730560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 13:54:46.540540 139976399730560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 13:54:46.717171 139976399730560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 13:54:46.717366 139976399730560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 13:54:47.005873 139976399730560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 13:54:47.006046 139976399730560 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 13:54:47.291018 139976399730560 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 13:54:47.291209 139976399730560 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 13:54:47.676613 139976399730560 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 13:54:47.676804 139976399730560 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 13:54:48.068699 139976399730560 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 13:54:48.068894 139976399730560 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 13:54:48.552145 139976399730560 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 13:54:48.552335 139976399730560 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1112 13:54:48.757275 139976399730560 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1112 13:54:48.795708 139976399730560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 13:54:48.860955 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1112 13:54:48.861128 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I1112 13:54:48.861200 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 5\n",
            "I1112 13:54:48.862863 139976399730560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 13:54:48.882527 139976399730560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 13:54:48.882681 139976399730560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 13:54:49.038247 139976399730560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 13:54:49.038423 139976399730560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 13:54:49.329056 139976399730560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 13:54:49.329247 139976399730560 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1112 13:54:49.636331 139976399730560 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1112 13:54:49.636503 139976399730560 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1112 13:54:50.046659 139976399730560 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1112 13:54:50.046848 139976399730560 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1112 13:54:50.453699 139976399730560 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1112 13:54:50.453889 139976399730560 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1112 13:54:50.960608 139976399730560 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1112 13:54:50.960801 139976399730560 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1112 13:54:51.170868 139976399730560 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1112 13:54:51.215076 139976399730560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 13:54:51.278335 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1112 13:54:51.278502 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I1112 13:54:51.278560 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 6\n",
            "I1112 13:54:51.280218 139976399730560 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1112 13:54:51.301698 139976399730560 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1112 13:54:51.301857 139976399730560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 13:54:51.465666 139976399730560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 13:54:51.465848 139976399730560 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1112 13:54:51.761106 139976399730560 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1112 13:54:51.761293 139976399730560 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1112 13:54:52.249968 139976399730560 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1112 13:54:52.250148 139976399730560 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1112 13:54:52.743747 139976399730560 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1112 13:54:52.743926 139976399730560 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1112 13:54:53.256906 139976399730560 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1112 13:54:53.257079 139976399730560 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1112 13:54:53.854813 139976399730560 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1112 13:54:53.855010 139976399730560 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1112 13:54:54.066988 139976399730560 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1112 13:54:54.112936 139976399730560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 13:54:54.183017 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1112 13:54:54.183204 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I1112 13:54:54.183267 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1112 13:54:54.184937 139976399730560 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1112 13:54:54.206933 139976399730560 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1112 13:54:54.207094 139976399730560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 13:54:54.360654 139976399730560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 13:54:54.360822 139976399730560 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1112 13:54:54.716435 139976399730560 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1112 13:54:54.716601 139976399730560 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1112 13:54:55.087965 139976399730560 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1112 13:54:55.088137 139976399730560 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1112 13:54:55.626463 139976399730560 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1112 13:54:55.626624 139976399730560 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1112 13:54:56.172266 139976399730560 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1112 13:54:56.172423 139976399730560 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1112 13:54:56.901447 139976399730560 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1112 13:54:56.901617 139976399730560 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1112 13:54:57.094235 139976399730560 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1112 13:54:57.134624 139976399730560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 13:54:57.213424 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1112 13:54:57.213586 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I1112 13:54:57.213644 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1112 13:54:57.215269 139976399730560 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1112 13:54:57.234022 139976399730560 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1112 13:54:57.234158 139976399730560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 13:54:57.453139 139976399730560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1112 13:54:57.453334 139976399730560 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1112 13:54:57.928688 139976399730560 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1112 13:54:57.928870 139976399730560 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1112 13:54:58.430707 139976399730560 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1112 13:54:58.430883 139976399730560 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1112 13:54:59.379832 139976399730560 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1112 13:54:59.380014 139976399730560 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1112 13:55:00.092844 139976399730560 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1112 13:55:00.093021 139976399730560 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1112 13:55:00.987863 139976399730560 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1112 13:55:00.988034 139976399730560 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1112 13:55:01.301262 139976399730560 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1112 13:55:01.343260 139976399730560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 13:55:01.438385 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1112 13:55:01.438561 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1112 13:55:01.438637 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1112 13:55:01.440436 139976399730560 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1112 13:55:01.462874 139976399730560 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1112 13:55:01.463045 139976399730560 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1112 13:55:01.708361 139976399730560 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1112 13:55:01.708527 139976399730560 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1112 13:55:02.329729 139976399730560 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1112 13:55:02.329899 139976399730560 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1112 13:55:02.950568 139976399730560 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1112 13:55:02.950739 139976399730560 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1112 13:55:03.775381 139976399730560 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1112 13:55:03.775553 139976399730560 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1112 13:55:04.589694 139976399730560 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1112 13:55:04.589868 139976399730560 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1112 13:55:05.708093 139976399730560 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1112 13:55:05.708285 139976399730560 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1112 13:55:06.013136 139976399730560 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1112 13:55:06.054732 139976399730560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1112 13:55:06.169869 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1112 13:55:06.170044 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1112 13:55:06.170105 139976399730560 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1112 13:55:06.171936 139976399730560 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1112 13:55:06.193967 139976399730560 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1112 13:55:06.194133 139976399730560 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1112 13:55:06.517612 139976399730560 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1112 13:55:06.517791 139976399730560 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1112 13:55:07.493637 139976399730560 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1112 13:55:07.493824 139976399730560 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1112 13:55:08.173221 139976399730560 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1112 13:55:08.173398 139976399730560 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1112 13:55:09.143277 139976399730560 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1112 13:55:09.143452 139976399730560 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1112 13:55:10.130328 139976399730560 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1112 13:55:10.130503 139976399730560 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1112 13:55:11.392908 139976399730560 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1112 13:55:11.393082 139976399730560 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1112 13:55:11.802391 139976399730560 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1112 13:55:11.852426 139976399730560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.74s\n",
            "I1112 13:55:11.980771 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.74s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1112 13:55:12.007808 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1112 13:55:12.009634 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1112 13:55:12.010165 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1112 13:55:12.011615 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1112 13:55:12.012934 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1112 13:55:12.013342 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1112 13:55:12.014270 139976399730560 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 33.672s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "# Test, ob initiales Set-up erfolgreich\n",
        "\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz1sd2reSTxg"
      },
      "source": [
        "## Datenvorbereitung für Training \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5PPOdRLZOq7",
        "outputId": "7dcf8fec-4759-40b2-8640-78294295141c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100\n"
          ]
        }
      ],
      "source": [
        "# In den Traingsornder springen\n",
        "%cd {training_folder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KHDdTY_cm5G",
        "outputId": "2838a3a1-513a-4b63-d272-67864201168e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 13:11:07--  https://raw.githubusercontent.com/MichaelSeitz98/Seminararbeit/44688230a2a4692e06b2ab927ab7abca0eb163ec/generate_tfrecord.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3394 (3.3K) [text/plain]\n",
            "Saving to: ‘generate_tfrecord.py’\n",
            "\n",
            "generate_tfrecord.p 100%[===================>]   3.31K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-11-12 13:11:07 (169 KB/s) - ‘generate_tfrecord.py’ saved [3394/3394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate TF-Record-Skript von meinem GitHub-Account laden, alternativ einfach Generate TF-Record in die Drive hochladen\n",
        "\n",
        "!wget https://raw.githubusercontent.com/MichaelSeitz98/Seminararbeit/44688230a2a4692e06b2ab927ab7abca0eb163ec/generate_tfrecord.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IRZfTu6di4R",
        "outputId": "c083dd99-441e-4f0c-e3d2-e9e2d4b2e6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-12 13:11:07--  https://raw.githubusercontent.com/MichaelSeitz98/Seminararbeit/main/labelmap.pbtxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37 [text/plain]\n",
            "Saving to: ‘labelmap.pbtxt’\n",
            "\n",
            "\rlabelmap.pbtxt        0%[                    ]       0  --.-KB/s               \rlabelmap.pbtxt      100%[===================>]      37  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-12 13:11:08 (681 KB/s) - ‘labelmap.pbtxt’ saved [37/37]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LabelMap von meinem GitHub-Accountin den Trainingsordner laden\n",
        "\n",
        "!wget https://raw.githubusercontent.com/MichaelSeitz98/Seminararbeit/main/labelmap.pbtxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awloU8qkaWBw",
        "outputId": "0da22a3e-d4ad-4c3f-f1fd-27f798c74a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datensatz Pfad: /content/drive/MyDrive/DS2_POOLG_80_20_20\n",
            "Training labels: /content/drive/MyDrive/DS2_POOLG_80_20_20/train_labels.csv\n",
            "Validation labels: /content/drive/MyDrive/DS2_POOLG_80_20_20/validation_labels.csv\n"
          ]
        }
      ],
      "source": [
        "# train_labels.csv und validatation_labels.csv offline erzeugen\n",
        "# Wichtig: Den Datensatzpfad anpassen in der xml_to_csv offline-Datei\n",
        "\n",
        "print(f'Datensatz Pfad: {datensatz_folder}')\n",
        "\n",
        "train_labels_path = datensatz_folder + '/train_labels.csv'\n",
        "validation_labels_path = datensatz_folder + '/validation_labels.csv'\n",
        "\n",
        "!cp {train_labels_path} {training_folder}\n",
        "!cp {validation_labels_path} {training_folder}\n",
        "\n",
        "print (f'Training labels: {train_labels_path}')\n",
        "print (f'Validation labels: {validation_labels_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEYUJvvWEMH0",
        "outputId": "9710ec4f-e619-47b1-e683-245d784574e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DS2_POOLG_80_20_20/train\n",
            "2022-11-12 13:34:17.376446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 13:34:17.623373: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-12 13:34:18.551280: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-12 13:34:18.551413: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-12 13:34:18.551437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-12 13:34:20.322396: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-11-12 13:34:20.322462: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (50a78660f2ba): /proc/driver/nvidia/version does not exist\n",
            "Successfully created the TFRecords: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/train.record\n",
            "2022-11-12 13:36:00.727522: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 13:36:01.003826: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-12 13:36:01.977910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-12 13:36:01.978033: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-12 13:36:01.978051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-12 13:36:03.744014: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-11-12 13:36:03.744083: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (50a78660f2ba): /proc/driver/nvidia/version does not exist\n",
            "Successfully created the TFRecords: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/validation.record\n"
          ]
        }
      ],
      "source": [
        "# Erstellung der TF-Record Dateien\n",
        "# Kann bis zu 5 Minuten dauern\n",
        "\n",
        "print(f'{datensatz_folder}/train')\n",
        "!python generate_tfrecord.py --csv_input={train_labels_path} --image_dir={datensatz_folder}/train --output_path=train.record\n",
        "!python generate_tfrecord.py --csv_input={validation_labels_path} --image_dir={datensatz_folder}/validation --output_path=validation.record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_W_8L24c4Sk",
        "outputId": "b7ba69db-0f01-423c-e30f-628d1167db2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diese Datein müssen vorhanden sein in: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100\n",
            "\n",
            "train_record_path: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/train.record \n",
            "validation_record_path: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/validation.record\n",
            "labelmap_path: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/labelmap.pbtxt\n"
          ]
        }
      ],
      "source": [
        "# Dateipfade aller fürs Training relevanten Dateien: train.record, test.record, labelmap.pbtxt, + dann noch: config des Modelles, Alle aus dem Trainings-Ordner ziehen\n",
        "\n",
        "train_record_path = training_folder + '/train.record'\n",
        "validation_record_path =  training_folder + '/validation.record'\n",
        "labelmap_path =  training_folder + '/labelmap.pbtxt'\n",
        "\n",
        "print (f'Diese Datein müssen vorhanden sein in: {training_folder}\\n')\n",
        "print (f'train_record_path: {train_record_path} \\nvalidation_record_path: {validation_record_path}\\nlabelmap_path: {labelmap_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK79i98YSY8a"
      },
      "source": [
        "## Modellauswahl und Trainingsparameter festlegen...\n",
        "\n",
        "Modellauswahl aus: (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Axko9Jd0hEI3"
      },
      "outputs": [],
      "source": [
        "# Hier können die entscheidenede Trainingsparamter festgelegt werde. Variablen für jedes Training neu setzen/überprüfen. \n",
        "# Modellnamen raussuchen von:  https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "\n",
        "name_model = 'efficientdet_d1_coco17_tpu-32'\n",
        "name_model_als_tar_gz = 'efficientdet_d1_coco17_tpu-32.tar.gz'\n",
        "\n",
        "batch_size = 8\n",
        "num_steps = 20000\n",
        "num_eval_steps = 100\n",
        "nr_of_classes = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RNI68K_dyzX",
        "outputId": "c594b957-2bd1-4e1b-b0eb-fa33e25142ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
            "--2022-11-12 13:18:44--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 209.85.234.128, 2607:f8b0:4001:c17::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|209.85.234.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51839363 (49M) [application/x-tar]\n",
            "Saving to: ‘efficientdet_d1_coco17_tpu-32.tar.gz’\n",
            "\n",
            "efficientdet_d1_coc 100%[===================>]  49.44M  79.4MB/s    in 0.6s    \n",
            "\n",
            "2022-11-12 13:18:45 (79.4 MB/s) - ‘efficientdet_d1_coco17_tpu-32.tar.gz’ saved [51839363/51839363]\n",
            "\n",
            "Download des Modells: http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n"
          ]
        }
      ],
      "source": [
        "# Vortrainiertes Modell aus TF Model Zoo laden. An dieser Stelle Modelle austauschen! \n",
        "#!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
        "#!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "#!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "\n",
        "\n",
        "download_link_model = f'http://download.tensorflow.org/models/object_detection/tf2/20200711/{name_model_als_tar_gz}'\n",
        "print(download_link_model)\n",
        "!wget {download_link_model}\n",
        "\n",
        "print (f'Download des Modells: {download_link_model}' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8laIypK2GZ-5",
        "outputId": "3aa5fe96-5e05-4c54-8904-07fba76725e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entpacke Datei: efficientdet_d1_coco17_tpu-32.tar.gz\n"
          ]
        }
      ],
      "source": [
        "# Das Modell unzippen. Es wird ein neuer Ordner im Trainings-Ordner erstellt \n",
        "\n",
        "!tar xf {name_model_als_tar_gz}\n",
        "print (f'Entpacke Datei: {name_model_als_tar_gz}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TRJS43kcSt5w"
      },
      "outputs": [],
      "source": [
        "# Lösche MODEL-NAME.tar.gz, da nicht mehr benötigt\n",
        "\n",
        "!rm {name_model_als_tar_gz}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKENdH3TfhGb",
        "outputId": "9ddc669e-f17d-4dc7-a163-80954e6bd959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/efficientdet_d1_coco17_tpu-32/checkpoint/ckpt-0\n"
          ]
        }
      ],
      "source": [
        "# Hier wird der Ausgangspunkt für das Training gesetzt. Ab diesem Punkt wird mit den eigenen Daten traininert (Konzept des Transfer-Learnings)\n",
        "\n",
        "fine_tune_checkpoint = f'{training_folder}/{name_model}/checkpoint/ckpt-0'\n",
        "\n",
        "print(fine_tune_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzQ84qIQelJB"
      },
      "outputs": [],
      "source": [
        "# Jetzt das Config-File für Training runterladen aus ModelZoo Configs \n",
        "# Alternativ einfach das pipeline.config aus /content/efficientdet_d0_coco17_tpu-32/pipeline.config verwenden (sind leicht unterschiedlich) \n",
        "\n",
        "#!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
        "#!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config\n",
        "\n",
        "\n",
        "#!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/{name_model}.config\n",
        "# !wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d1_640x640_coco17_tpu-8.config\n",
        "\n",
        "# und als Config_path setzen: \n",
        "\n",
        "#\n",
        "#config_path = f'{name_model}.config'    # bei allem außer EfficientDet funktionierend\n",
        "\n",
        "#print (f'Config path gesetzt auf: {config_path}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = f'{training_folder}/{name_model}/pipeline.config'\n",
        "print (f'Config Path gesetzt auf: {config_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhYJ73ptBP4-",
        "outputId": "65556359-5521-4be5-b33a-e3ef74566a75"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config Path gesetzt auf: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/efficientdet_d1_coco17_tpu-32/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "h9Sajpbsb0t8"
      },
      "outputs": [],
      "source": [
        "# config file bearbeiten mit den eigenen Daten\n",
        "# Anzahl der Klassen anpassen\n",
        "\n",
        "import re\n",
        "\n",
        "with open(config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "  config = re.sub('label_map_path: \".*?\"', \n",
        "             'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "  \n",
        "  #  fine_tune_checkpoint Pfad setzen\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
        "  \n",
        "  # train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "  \n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(validation_record_path), config)\n",
        "  \n",
        "  # Anzahl der Detektionsklassen setzen\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(nr_of_classes), config)\n",
        "  \n",
        "  # batch size \n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "  #nur bei Train die batch_size ändern. Bei eval auf 1 lassen\n",
        "  \n",
        "  # training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(num_steps), config)\n",
        "  \n",
        "  # fine-tune checkpoint & type 'detection'\n",
        "  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
        "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
        "  \n",
        "  f.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zZopEH_5uacQ",
        "outputId": "4a4ad1af-d55c-413a-98f2-c099e7342f41"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmtrS5dihpS_"
      },
      "outputs": [],
      "source": [
        "# Anzeigen, der eben geänderten Datei\n",
        "\n",
        "print(config_path)\n",
        "%cat {config_path}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv0sbQlciKWA"
      },
      "source": [
        "## Ab hier: alles vorhanden für Training. Training starten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rwlp7bljpNQ",
        "outputId": "2146e601-3d41-4c84-de70-c8d72a51b46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/efficientdet_d1_coco17_tpu-32/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "print (config_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2zxx5AXiNNK",
        "outputId": "6f52f892-0a95-49a5-8e6d-1d028ad055f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-12 13:56:47.072338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 13:56:47.234679: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2022-11-12 13:56:47.264420: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-12 13:56:48.111468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-12 13:56:48.111565: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-12 13:56:48.111582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-12 13:56:50.537075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 13:56:51.388495: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-11-12 13:56:51.388562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38354 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I1112 13:56:51.405886 139621605971840 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 20000\n",
            "I1112 13:56:51.412502 139621605971840 config_util.py:552] Maybe overwriting train_steps: 20000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1112 13:56:51.412707 139621605971840 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "I1112 13:56:51.424208 139621605971840 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1112 13:56:51.424361 139621605971840 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1112 13:56:51.424422 139621605971840 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1112 13:56:51.428428 139621605971840 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.471078 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.478134 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.481163 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.482256 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.490242 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.494628 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.501322 139621605971840 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 13:56:51.501451 139621605971840 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.521437 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.522614 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.524655 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.525656 139621605971840 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1112 13:56:51.776023 139621605971840 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 13:56:51.776219 139621605971840 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 13:56:52.283699 139621605971840 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 13:56:52.283877 139621605971840 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 13:56:52.778323 139621605971840 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 13:56:52.778500 139621605971840 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 13:56:53.456210 139621605971840 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 13:56:53.456394 139621605971840 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 13:56:54.118672 139621605971840 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 13:56:54.118850 139621605971840 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 13:56:54.943854 139621605971840 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 13:56:54.944033 139621605971840 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1112 13:56:55.274697 139621605971840 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1112 13:56:55.345720 139621605971840 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1112 13:56:55.399423 139621605971840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/train.record']\n",
            "I1112 13:56:55.669584 139621605971840 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/train.record']\n",
            "I1112 13:56:55.669934 139621605971840 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1112 13:56:55.670027 139621605971840 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1112 13:56:55.670089 139621605971840 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1112 13:56:55.677556 139621605971840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1112 13:56:55.694300 139621605971840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1112 13:57:02.985861 139621605971840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1112 13:57:07.138514 139621605971840 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
            "2022-11-12 13:57:42.369697: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
            "2022-11-12 13:57:47.711363: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1112 13:57:57.851558 139615992473344 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "W1112 13:58:08.524028 139615992473344 utils.py:88] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "W1112 13:58:23.599949 139615992473344 utils.py:88] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "W1112 13:58:37.796504 139615992473344 utils.py:88] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "W1112 13:58:52.552015 139615992473344 utils.py:88] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "tcmalloc: large alloc 1073741824 bytes == 0x132276000 @  0x7efc2ff4eb6b 0x7efc2ff6e379 0x7efc0d43c9bc 0x7efbfc1a5e20 0x7efbfc1c0859 0x7efbfc1c163a 0x7efbfc1c1b19 0x7efbfc1c1ff1 0x7efbfc1b7b83 0x7efbf6fbc4dc 0x7efbf6dacf4d 0x7efbf6bc8a4a 0x7efbf6bc963c 0x7efbf6bc9885 0x7efc02a05536 0x7efbf6fbdb8b 0x7efbf6f2ccfc 0x7efbf6f2db98 0x7efc0c324301 0x7efc0d438585 0x7efc0d4362b3 0x7efbf6d854ab 0x7efc2f9306db 0x7efc2fc6961f\n",
            "INFO:tensorflow:Step 100 per-step time 1.214s\n",
            "I1112 13:59:59.128198 139621605971840 model_lib_v2.py:707] Step 100 per-step time 1.214s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4018985,\n",
            " 'Loss/localization_loss': 0.014986164,\n",
            " 'Loss/regularization_loss': 0.030103749,\n",
            " 'Loss/total_loss': 0.4469884,\n",
            " 'learning_rate': 0.080900006}\n",
            "I1112 13:59:59.128566 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.4018985,\n",
            " 'Loss/localization_loss': 0.014986164,\n",
            " 'Loss/regularization_loss': 0.030103749,\n",
            " 'Loss/total_loss': 0.4469884,\n",
            " 'learning_rate': 0.080900006}\n",
            "INFO:tensorflow:Step 200 per-step time 0.434s\n",
            "I1112 14:00:42.321798 139621605971840 model_lib_v2.py:707] Step 200 per-step time 0.434s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.52755845,\n",
            " 'Loss/localization_loss': 0.014134872,\n",
            " 'Loss/regularization_loss': 0.032001078,\n",
            " 'Loss/total_loss': 0.5736944,\n",
            " 'learning_rate': 0.16080001}\n",
            "I1112 14:00:42.322139 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.52755845,\n",
            " 'Loss/localization_loss': 0.014134872,\n",
            " 'Loss/regularization_loss': 0.032001078,\n",
            " 'Loss/total_loss': 0.5736944,\n",
            " 'learning_rate': 0.16080001}\n",
            "INFO:tensorflow:Step 300 per-step time 0.433s\n",
            "I1112 14:01:25.579179 139621605971840 model_lib_v2.py:707] Step 300 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.67775154,\n",
            " 'Loss/localization_loss': 0.017589185,\n",
            " 'Loss/regularization_loss': 0.033360664,\n",
            " 'Loss/total_loss': 0.7287014,\n",
            " 'learning_rate': 0.2407}\n",
            "I1112 14:01:25.579510 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.67775154,\n",
            " 'Loss/localization_loss': 0.017589185,\n",
            " 'Loss/regularization_loss': 0.033360664,\n",
            " 'Loss/total_loss': 0.7287014,\n",
            " 'learning_rate': 0.2407}\n",
            "INFO:tensorflow:Step 400 per-step time 0.431s\n",
            "I1112 14:02:08.655148 139621605971840 model_lib_v2.py:707] Step 400 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.39466402,\n",
            " 'Loss/localization_loss': 0.014114755,\n",
            " 'Loss/regularization_loss': 0.034981575,\n",
            " 'Loss/total_loss': 0.44376037,\n",
            " 'learning_rate': 0.3206}\n",
            "I1112 14:02:08.655487 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.39466402,\n",
            " 'Loss/localization_loss': 0.014114755,\n",
            " 'Loss/regularization_loss': 0.034981575,\n",
            " 'Loss/total_loss': 0.44376037,\n",
            " 'learning_rate': 0.3206}\n",
            "INFO:tensorflow:Step 500 per-step time 0.431s\n",
            "I1112 14:02:51.781060 139621605971840 model_lib_v2.py:707] Step 500 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.39240158,\n",
            " 'Loss/localization_loss': 0.010590871,\n",
            " 'Loss/regularization_loss': 0.037011355,\n",
            " 'Loss/total_loss': 0.4400038,\n",
            " 'learning_rate': 0.4005}\n",
            "I1112 14:02:51.781464 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.39240158,\n",
            " 'Loss/localization_loss': 0.010590871,\n",
            " 'Loss/regularization_loss': 0.037011355,\n",
            " 'Loss/total_loss': 0.4400038,\n",
            " 'learning_rate': 0.4005}\n",
            "INFO:tensorflow:Step 600 per-step time 0.433s\n",
            "I1112 14:03:35.035934 139621605971840 model_lib_v2.py:707] Step 600 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4657415,\n",
            " 'Loss/localization_loss': 0.011856658,\n",
            " 'Loss/regularization_loss': 0.039584443,\n",
            " 'Loss/total_loss': 0.5171826,\n",
            " 'learning_rate': 0.4804}\n",
            "I1112 14:03:35.036277 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.4657415,\n",
            " 'Loss/localization_loss': 0.011856658,\n",
            " 'Loss/regularization_loss': 0.039584443,\n",
            " 'Loss/total_loss': 0.5171826,\n",
            " 'learning_rate': 0.4804}\n",
            "INFO:tensorflow:Step 700 per-step time 0.430s\n",
            "I1112 14:04:18.066217 139621605971840 model_lib_v2.py:707] Step 700 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.5707917,\n",
            " 'Loss/localization_loss': 0.014239371,\n",
            " 'Loss/regularization_loss': 0.040888123,\n",
            " 'Loss/total_loss': 0.6259192,\n",
            " 'learning_rate': 0.5603}\n",
            "I1112 14:04:18.066563 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.5707917,\n",
            " 'Loss/localization_loss': 0.014239371,\n",
            " 'Loss/regularization_loss': 0.040888123,\n",
            " 'Loss/total_loss': 0.6259192,\n",
            " 'learning_rate': 0.5603}\n",
            "INFO:tensorflow:Step 800 per-step time 0.431s\n",
            "I1112 14:05:01.180611 139621605971840 model_lib_v2.py:707] Step 800 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.42647186,\n",
            " 'Loss/localization_loss': 0.008888925,\n",
            " 'Loss/regularization_loss': 0.042419646,\n",
            " 'Loss/total_loss': 0.47778043,\n",
            " 'learning_rate': 0.6402}\n",
            "I1112 14:05:01.180949 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.42647186,\n",
            " 'Loss/localization_loss': 0.008888925,\n",
            " 'Loss/regularization_loss': 0.042419646,\n",
            " 'Loss/total_loss': 0.47778043,\n",
            " 'learning_rate': 0.6402}\n",
            "INFO:tensorflow:Step 900 per-step time 0.432s\n",
            "I1112 14:05:44.393388 139621605971840 model_lib_v2.py:707] Step 900 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.36719826,\n",
            " 'Loss/localization_loss': 0.010012029,\n",
            " 'Loss/regularization_loss': 0.046036176,\n",
            " 'Loss/total_loss': 0.42324647,\n",
            " 'learning_rate': 0.7201}\n",
            "I1112 14:05:44.393736 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.36719826,\n",
            " 'Loss/localization_loss': 0.010012029,\n",
            " 'Loss/regularization_loss': 0.046036176,\n",
            " 'Loss/total_loss': 0.42324647,\n",
            " 'learning_rate': 0.7201}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.432s\n",
            "I1112 14:06:27.556522 139621605971840 model_lib_v2.py:707] Step 1000 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.40941513,\n",
            " 'Loss/localization_loss': 0.009938563,\n",
            " 'Loss/regularization_loss': 0.04722328,\n",
            " 'Loss/total_loss': 0.46657696,\n",
            " 'learning_rate': 0.8}\n",
            "I1112 14:06:27.556864 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.40941513,\n",
            " 'Loss/localization_loss': 0.009938563,\n",
            " 'Loss/regularization_loss': 0.04722328,\n",
            " 'Loss/total_loss': 0.46657696,\n",
            " 'learning_rate': 0.8}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.455s\n",
            "I1112 14:07:13.035266 139621605971840 model_lib_v2.py:707] Step 1100 per-step time 0.455s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.37532252,\n",
            " 'Loss/localization_loss': 0.011336484,\n",
            " 'Loss/regularization_loss': 0.0488567,\n",
            " 'Loss/total_loss': 0.4355157,\n",
            " 'learning_rate': 0.7999918}\n",
            "I1112 14:07:13.035606 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.37532252,\n",
            " 'Loss/localization_loss': 0.011336484,\n",
            " 'Loss/regularization_loss': 0.0488567,\n",
            " 'Loss/total_loss': 0.4355157,\n",
            " 'learning_rate': 0.7999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.432s\n",
            "I1112 14:07:56.257156 139621605971840 model_lib_v2.py:707] Step 1200 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4381541,\n",
            " 'Loss/localization_loss': 0.008128758,\n",
            " 'Loss/regularization_loss': 0.050228164,\n",
            " 'Loss/total_loss': 0.49651104,\n",
            " 'learning_rate': 0.7999671}\n",
            "I1112 14:07:56.257545 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.4381541,\n",
            " 'Loss/localization_loss': 0.008128758,\n",
            " 'Loss/regularization_loss': 0.050228164,\n",
            " 'Loss/total_loss': 0.49651104,\n",
            " 'learning_rate': 0.7999671}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.431s\n",
            "I1112 14:08:39.381806 139621605971840 model_lib_v2.py:707] Step 1300 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.33046556,\n",
            " 'Loss/localization_loss': 0.008999073,\n",
            " 'Loss/regularization_loss': 0.052323733,\n",
            " 'Loss/total_loss': 0.39178836,\n",
            " 'learning_rate': 0.799926}\n",
            "I1112 14:08:39.382141 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.33046556,\n",
            " 'Loss/localization_loss': 0.008999073,\n",
            " 'Loss/regularization_loss': 0.052323733,\n",
            " 'Loss/total_loss': 0.39178836,\n",
            " 'learning_rate': 0.799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.432s\n",
            "I1112 14:09:22.595113 139621605971840 model_lib_v2.py:707] Step 1400 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34452164,\n",
            " 'Loss/localization_loss': 0.008771245,\n",
            " 'Loss/regularization_loss': 0.05260665,\n",
            " 'Loss/total_loss': 0.40589952,\n",
            " 'learning_rate': 0.7998685}\n",
            "I1112 14:09:22.595459 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.34452164,\n",
            " 'Loss/localization_loss': 0.008771245,\n",
            " 'Loss/regularization_loss': 0.05260665,\n",
            " 'Loss/total_loss': 0.40589952,\n",
            " 'learning_rate': 0.7998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.433s\n",
            "I1112 14:10:05.895377 139621605971840 model_lib_v2.py:707] Step 1500 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4057505,\n",
            " 'Loss/localization_loss': 0.0079386905,\n",
            " 'Loss/regularization_loss': 0.053406462,\n",
            " 'Loss/total_loss': 0.46709567,\n",
            " 'learning_rate': 0.7997945}\n",
            "I1112 14:10:05.895716 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.4057505,\n",
            " 'Loss/localization_loss': 0.0079386905,\n",
            " 'Loss/regularization_loss': 0.053406462,\n",
            " 'Loss/total_loss': 0.46709567,\n",
            " 'learning_rate': 0.7997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.432s\n",
            "I1112 14:10:49.049777 139621605971840 model_lib_v2.py:707] Step 1600 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34678248,\n",
            " 'Loss/localization_loss': 0.010951778,\n",
            " 'Loss/regularization_loss': 0.053852707,\n",
            " 'Loss/total_loss': 0.41158697,\n",
            " 'learning_rate': 0.7997041}\n",
            "I1112 14:10:49.050106 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.34678248,\n",
            " 'Loss/localization_loss': 0.010951778,\n",
            " 'Loss/regularization_loss': 0.053852707,\n",
            " 'Loss/total_loss': 0.41158697,\n",
            " 'learning_rate': 0.7997041}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.433s\n",
            "I1112 14:11:32.350744 139621605971840 model_lib_v2.py:707] Step 1700 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31290427,\n",
            " 'Loss/localization_loss': 0.0075991163,\n",
            " 'Loss/regularization_loss': 0.05410902,\n",
            " 'Loss/total_loss': 0.3746124,\n",
            " 'learning_rate': 0.7995972}\n",
            "I1112 14:11:32.351082 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.31290427,\n",
            " 'Loss/localization_loss': 0.0075991163,\n",
            " 'Loss/regularization_loss': 0.05410902,\n",
            " 'Loss/total_loss': 0.3746124,\n",
            " 'learning_rate': 0.7995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.430s\n",
            "I1112 14:12:15.342779 139621605971840 model_lib_v2.py:707] Step 1800 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.43571344,\n",
            " 'Loss/localization_loss': 0.013838888,\n",
            " 'Loss/regularization_loss': 0.054466162,\n",
            " 'Loss/total_loss': 0.5040185,\n",
            " 'learning_rate': 0.79947394}\n",
            "I1112 14:12:15.343140 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.43571344,\n",
            " 'Loss/localization_loss': 0.013838888,\n",
            " 'Loss/regularization_loss': 0.054466162,\n",
            " 'Loss/total_loss': 0.5040185,\n",
            " 'learning_rate': 0.79947394}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.432s\n",
            "I1112 14:12:58.541946 139621605971840 model_lib_v2.py:707] Step 1900 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26025298,\n",
            " 'Loss/localization_loss': 0.005666559,\n",
            " 'Loss/regularization_loss': 0.055060837,\n",
            " 'Loss/total_loss': 0.32098037,\n",
            " 'learning_rate': 0.7993342}\n",
            "I1112 14:12:58.542291 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.26025298,\n",
            " 'Loss/localization_loss': 0.005666559,\n",
            " 'Loss/regularization_loss': 0.055060837,\n",
            " 'Loss/total_loss': 0.32098037,\n",
            " 'learning_rate': 0.7993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.433s\n",
            "I1112 14:13:41.818403 139621605971840 model_lib_v2.py:707] Step 2000 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25125605,\n",
            " 'Loss/localization_loss': 0.004220864,\n",
            " 'Loss/regularization_loss': 0.05571814,\n",
            " 'Loss/total_loss': 0.31119508,\n",
            " 'learning_rate': 0.7991781}\n",
            "I1112 14:13:41.818776 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25125605,\n",
            " 'Loss/localization_loss': 0.004220864,\n",
            " 'Loss/regularization_loss': 0.05571814,\n",
            " 'Loss/total_loss': 0.31119508,\n",
            " 'learning_rate': 0.7991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.453s\n",
            "I1112 14:14:27.110297 139621605971840 model_lib_v2.py:707] Step 2100 per-step time 0.453s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3161957,\n",
            " 'Loss/localization_loss': 0.007807976,\n",
            " 'Loss/regularization_loss': 0.055947527,\n",
            " 'Loss/total_loss': 0.37995118,\n",
            " 'learning_rate': 0.7990057}\n",
            "I1112 14:14:27.110630 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.3161957,\n",
            " 'Loss/localization_loss': 0.007807976,\n",
            " 'Loss/regularization_loss': 0.055947527,\n",
            " 'Loss/total_loss': 0.37995118,\n",
            " 'learning_rate': 0.7990057}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.431s\n",
            "I1112 14:15:10.158339 139621605971840 model_lib_v2.py:707] Step 2200 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4366321,\n",
            " 'Loss/localization_loss': 0.008066984,\n",
            " 'Loss/regularization_loss': 0.05626745,\n",
            " 'Loss/total_loss': 0.50096655,\n",
            " 'learning_rate': 0.79881674}\n",
            "I1112 14:15:10.158700 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.4366321,\n",
            " 'Loss/localization_loss': 0.008066984,\n",
            " 'Loss/regularization_loss': 0.05626745,\n",
            " 'Loss/total_loss': 0.50096655,\n",
            " 'learning_rate': 0.79881674}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.432s\n",
            "I1112 14:15:53.327322 139621605971840 model_lib_v2.py:707] Step 2300 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26184782,\n",
            " 'Loss/localization_loss': 0.0045766463,\n",
            " 'Loss/regularization_loss': 0.05645869,\n",
            " 'Loss/total_loss': 0.32288316,\n",
            " 'learning_rate': 0.7986114}\n",
            "I1112 14:15:53.327651 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.26184782,\n",
            " 'Loss/localization_loss': 0.0045766463,\n",
            " 'Loss/regularization_loss': 0.05645869,\n",
            " 'Loss/total_loss': 0.32288316,\n",
            " 'learning_rate': 0.7986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.431s\n",
            "I1112 14:16:36.411314 139621605971840 model_lib_v2.py:707] Step 2400 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30165148,\n",
            " 'Loss/localization_loss': 0.0071113585,\n",
            " 'Loss/regularization_loss': 0.05672396,\n",
            " 'Loss/total_loss': 0.3654868,\n",
            " 'learning_rate': 0.79838973}\n",
            "I1112 14:16:36.411654 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.30165148,\n",
            " 'Loss/localization_loss': 0.0071113585,\n",
            " 'Loss/regularization_loss': 0.05672396,\n",
            " 'Loss/total_loss': 0.3654868,\n",
            " 'learning_rate': 0.79838973}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.432s\n",
            "I1112 14:17:19.577889 139621605971840 model_lib_v2.py:707] Step 2500 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3242175,\n",
            " 'Loss/localization_loss': 0.007825895,\n",
            " 'Loss/regularization_loss': 0.05671447,\n",
            " 'Loss/total_loss': 0.38875785,\n",
            " 'learning_rate': 0.7981517}\n",
            "I1112 14:17:19.578242 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.3242175,\n",
            " 'Loss/localization_loss': 0.007825895,\n",
            " 'Loss/regularization_loss': 0.05671447,\n",
            " 'Loss/total_loss': 0.38875785,\n",
            " 'learning_rate': 0.7981517}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.431s\n",
            "I1112 14:18:02.720384 139621605971840 model_lib_v2.py:707] Step 2600 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.289978,\n",
            " 'Loss/localization_loss': 0.005998326,\n",
            " 'Loss/regularization_loss': 0.056875553,\n",
            " 'Loss/total_loss': 0.35285187,\n",
            " 'learning_rate': 0.7978972}\n",
            "I1112 14:18:02.720713 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.289978,\n",
            " 'Loss/localization_loss': 0.005998326,\n",
            " 'Loss/regularization_loss': 0.056875553,\n",
            " 'Loss/total_loss': 0.35285187,\n",
            " 'learning_rate': 0.7978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.432s\n",
            "I1112 14:18:45.911636 139621605971840 model_lib_v2.py:707] Step 2700 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25792474,\n",
            " 'Loss/localization_loss': 0.005555243,\n",
            " 'Loss/regularization_loss': 0.0570361,\n",
            " 'Loss/total_loss': 0.32051608,\n",
            " 'learning_rate': 0.79762644}\n",
            "I1112 14:18:45.911977 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25792474,\n",
            " 'Loss/localization_loss': 0.005555243,\n",
            " 'Loss/regularization_loss': 0.0570361,\n",
            " 'Loss/total_loss': 0.32051608,\n",
            " 'learning_rate': 0.79762644}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.433s\n",
            "I1112 14:19:29.168342 139621605971840 model_lib_v2.py:707] Step 2800 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.28425497,\n",
            " 'Loss/localization_loss': 0.008853117,\n",
            " 'Loss/regularization_loss': 0.057487566,\n",
            " 'Loss/total_loss': 0.35059565,\n",
            " 'learning_rate': 0.79733926}\n",
            "I1112 14:19:29.168672 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.28425497,\n",
            " 'Loss/localization_loss': 0.008853117,\n",
            " 'Loss/regularization_loss': 0.057487566,\n",
            " 'Loss/total_loss': 0.35059565,\n",
            " 'learning_rate': 0.79733926}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.431s\n",
            "I1112 14:20:12.274309 139621605971840 model_lib_v2.py:707] Step 2900 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30928564,\n",
            " 'Loss/localization_loss': 0.006682802,\n",
            " 'Loss/regularization_loss': 0.05785893,\n",
            " 'Loss/total_loss': 0.3738274,\n",
            " 'learning_rate': 0.7970358}\n",
            "I1112 14:20:12.274636 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.30928564,\n",
            " 'Loss/localization_loss': 0.006682802,\n",
            " 'Loss/regularization_loss': 0.05785893,\n",
            " 'Loss/total_loss': 0.3738274,\n",
            " 'learning_rate': 0.7970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.432s\n",
            "I1112 14:20:55.499982 139621605971840 model_lib_v2.py:707] Step 3000 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22243254,\n",
            " 'Loss/localization_loss': 0.0030689235,\n",
            " 'Loss/regularization_loss': 0.05798023,\n",
            " 'Loss/total_loss': 0.2834817,\n",
            " 'learning_rate': 0.79671603}\n",
            "I1112 14:20:55.500311 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22243254,\n",
            " 'Loss/localization_loss': 0.0030689235,\n",
            " 'Loss/regularization_loss': 0.05798023,\n",
            " 'Loss/total_loss': 0.2834817,\n",
            " 'learning_rate': 0.79671603}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.459s\n",
            "I1112 14:21:41.385554 139621605971840 model_lib_v2.py:707] Step 3100 per-step time 0.459s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.28167006,\n",
            " 'Loss/localization_loss': 0.0064194743,\n",
            " 'Loss/regularization_loss': 0.058139883,\n",
            " 'Loss/total_loss': 0.34622943,\n",
            " 'learning_rate': 0.7963799}\n",
            "I1112 14:21:41.385883 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.28167006,\n",
            " 'Loss/localization_loss': 0.0064194743,\n",
            " 'Loss/regularization_loss': 0.058139883,\n",
            " 'Loss/total_loss': 0.34622943,\n",
            " 'learning_rate': 0.7963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.432s\n",
            "I1112 14:22:24.633527 139621605971840 model_lib_v2.py:707] Step 3200 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.29058382,\n",
            " 'Loss/localization_loss': 0.005174661,\n",
            " 'Loss/regularization_loss': 0.058431294,\n",
            " 'Loss/total_loss': 0.35418978,\n",
            " 'learning_rate': 0.79602754}\n",
            "I1112 14:22:24.633864 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.29058382,\n",
            " 'Loss/localization_loss': 0.005174661,\n",
            " 'Loss/regularization_loss': 0.058431294,\n",
            " 'Loss/total_loss': 0.35418978,\n",
            " 'learning_rate': 0.79602754}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.431s\n",
            "I1112 14:23:07.684829 139621605971840 model_lib_v2.py:707] Step 3300 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4212692,\n",
            " 'Loss/localization_loss': 0.012367441,\n",
            " 'Loss/regularization_loss': 0.059058707,\n",
            " 'Loss/total_loss': 0.49269533,\n",
            " 'learning_rate': 0.7956588}\n",
            "I1112 14:23:07.685153 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.4212692,\n",
            " 'Loss/localization_loss': 0.012367441,\n",
            " 'Loss/regularization_loss': 0.059058707,\n",
            " 'Loss/total_loss': 0.49269533,\n",
            " 'learning_rate': 0.7956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.434s\n",
            "I1112 14:23:51.088655 139621605971840 model_lib_v2.py:707] Step 3400 per-step time 0.434s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27585682,\n",
            " 'Loss/localization_loss': 0.004566695,\n",
            " 'Loss/regularization_loss': 0.05978336,\n",
            " 'Loss/total_loss': 0.3402069,\n",
            " 'learning_rate': 0.7952739}\n",
            "I1112 14:23:51.089013 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.27585682,\n",
            " 'Loss/localization_loss': 0.004566695,\n",
            " 'Loss/regularization_loss': 0.05978336,\n",
            " 'Loss/total_loss': 0.3402069,\n",
            " 'learning_rate': 0.7952739}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.431s\n",
            "I1112 14:24:34.216224 139621605971840 model_lib_v2.py:707] Step 3500 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2655468,\n",
            " 'Loss/localization_loss': 0.0045541534,\n",
            " 'Loss/regularization_loss': 0.059885763,\n",
            " 'Loss/total_loss': 0.32998672,\n",
            " 'learning_rate': 0.7948727}\n",
            "I1112 14:24:34.216560 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2655468,\n",
            " 'Loss/localization_loss': 0.0045541534,\n",
            " 'Loss/regularization_loss': 0.059885763,\n",
            " 'Loss/total_loss': 0.32998672,\n",
            " 'learning_rate': 0.7948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.434s\n",
            "I1112 14:25:17.572049 139621605971840 model_lib_v2.py:707] Step 3600 per-step time 0.434s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3235267,\n",
            " 'Loss/localization_loss': 0.005783725,\n",
            " 'Loss/regularization_loss': 0.05985191,\n",
            " 'Loss/total_loss': 0.38916236,\n",
            " 'learning_rate': 0.7944553}\n",
            "I1112 14:25:17.572416 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.3235267,\n",
            " 'Loss/localization_loss': 0.005783725,\n",
            " 'Loss/regularization_loss': 0.05985191,\n",
            " 'Loss/total_loss': 0.38916236,\n",
            " 'learning_rate': 0.7944553}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.430s\n",
            "I1112 14:26:00.602230 139621605971840 model_lib_v2.py:707] Step 3700 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.32102427,\n",
            " 'Loss/localization_loss': 0.00809612,\n",
            " 'Loss/regularization_loss': 0.060567766,\n",
            " 'Loss/total_loss': 0.38968816,\n",
            " 'learning_rate': 0.79402167}\n",
            "I1112 14:26:00.602569 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.32102427,\n",
            " 'Loss/localization_loss': 0.00809612,\n",
            " 'Loss/regularization_loss': 0.060567766,\n",
            " 'Loss/total_loss': 0.38968816,\n",
            " 'learning_rate': 0.79402167}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.432s\n",
            "I1112 14:26:43.760453 139621605971840 model_lib_v2.py:707] Step 3800 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27115828,\n",
            " 'Loss/localization_loss': 0.006161525,\n",
            " 'Loss/regularization_loss': 0.06097061,\n",
            " 'Loss/total_loss': 0.3382904,\n",
            " 'learning_rate': 0.7935719}\n",
            "I1112 14:26:43.760790 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.27115828,\n",
            " 'Loss/localization_loss': 0.006161525,\n",
            " 'Loss/regularization_loss': 0.06097061,\n",
            " 'Loss/total_loss': 0.3382904,\n",
            " 'learning_rate': 0.7935719}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.431s\n",
            "I1112 14:27:26.891699 139621605971840 model_lib_v2.py:707] Step 3900 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27393213,\n",
            " 'Loss/localization_loss': 0.0073602567,\n",
            " 'Loss/regularization_loss': 0.06109097,\n",
            " 'Loss/total_loss': 0.34238335,\n",
            " 'learning_rate': 0.7931058}\n",
            "I1112 14:27:26.892033 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.27393213,\n",
            " 'Loss/localization_loss': 0.0073602567,\n",
            " 'Loss/regularization_loss': 0.06109097,\n",
            " 'Loss/total_loss': 0.34238335,\n",
            " 'learning_rate': 0.7931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.431s\n",
            "I1112 14:28:09.955343 139621605971840 model_lib_v2.py:707] Step 4000 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22505045,\n",
            " 'Loss/localization_loss': 0.004168359,\n",
            " 'Loss/regularization_loss': 0.061243434,\n",
            " 'Loss/total_loss': 0.29046226,\n",
            " 'learning_rate': 0.7926237}\n",
            "I1112 14:28:09.955671 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22505045,\n",
            " 'Loss/localization_loss': 0.004168359,\n",
            " 'Loss/regularization_loss': 0.061243434,\n",
            " 'Loss/total_loss': 0.29046226,\n",
            " 'learning_rate': 0.7926237}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.455s\n",
            "I1112 14:28:55.404944 139621605971840 model_lib_v2.py:707] Step 4100 per-step time 0.455s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.32814962,\n",
            " 'Loss/localization_loss': 0.005394574,\n",
            " 'Loss/regularization_loss': 0.061588887,\n",
            " 'Loss/total_loss': 0.39513308,\n",
            " 'learning_rate': 0.7921254}\n",
            "I1112 14:28:55.405446 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.32814962,\n",
            " 'Loss/localization_loss': 0.005394574,\n",
            " 'Loss/regularization_loss': 0.061588887,\n",
            " 'Loss/total_loss': 0.39513308,\n",
            " 'learning_rate': 0.7921254}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.433s\n",
            "I1112 14:29:38.655642 139621605971840 model_lib_v2.py:707] Step 4200 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.29564777,\n",
            " 'Loss/localization_loss': 0.0068376074,\n",
            " 'Loss/regularization_loss': 0.061849732,\n",
            " 'Loss/total_loss': 0.36433512,\n",
            " 'learning_rate': 0.7916109}\n",
            "I1112 14:29:38.655978 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.29564777,\n",
            " 'Loss/localization_loss': 0.0068376074,\n",
            " 'Loss/regularization_loss': 0.061849732,\n",
            " 'Loss/total_loss': 0.36433512,\n",
            " 'learning_rate': 0.7916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.432s\n",
            "I1112 14:30:21.813115 139621605971840 model_lib_v2.py:707] Step 4300 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23953487,\n",
            " 'Loss/localization_loss': 0.004449901,\n",
            " 'Loss/regularization_loss': 0.06210029,\n",
            " 'Loss/total_loss': 0.30608505,\n",
            " 'learning_rate': 0.7910804}\n",
            "I1112 14:30:21.813464 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23953487,\n",
            " 'Loss/localization_loss': 0.004449901,\n",
            " 'Loss/regularization_loss': 0.06210029,\n",
            " 'Loss/total_loss': 0.30608505,\n",
            " 'learning_rate': 0.7910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.433s\n",
            "I1112 14:31:05.118472 139621605971840 model_lib_v2.py:707] Step 4400 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25714257,\n",
            " 'Loss/localization_loss': 0.0036184718,\n",
            " 'Loss/regularization_loss': 0.06219055,\n",
            " 'Loss/total_loss': 0.3229516,\n",
            " 'learning_rate': 0.79053384}\n",
            "I1112 14:31:05.118798 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25714257,\n",
            " 'Loss/localization_loss': 0.0036184718,\n",
            " 'Loss/regularization_loss': 0.06219055,\n",
            " 'Loss/total_loss': 0.3229516,\n",
            " 'learning_rate': 0.79053384}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.433s\n",
            "I1112 14:31:48.463178 139621605971840 model_lib_v2.py:707] Step 4500 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2718644,\n",
            " 'Loss/localization_loss': 0.0048834556,\n",
            " 'Loss/regularization_loss': 0.06267159,\n",
            " 'Loss/total_loss': 0.33941948,\n",
            " 'learning_rate': 0.7899712}\n",
            "I1112 14:31:48.463539 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2718644,\n",
            " 'Loss/localization_loss': 0.0048834556,\n",
            " 'Loss/regularization_loss': 0.06267159,\n",
            " 'Loss/total_loss': 0.33941948,\n",
            " 'learning_rate': 0.7899712}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.431s\n",
            "I1112 14:32:31.532553 139621605971840 model_lib_v2.py:707] Step 4600 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.29883352,\n",
            " 'Loss/localization_loss': 0.005498769,\n",
            " 'Loss/regularization_loss': 0.06275349,\n",
            " 'Loss/total_loss': 0.36708578,\n",
            " 'learning_rate': 0.7893925}\n",
            "I1112 14:32:31.532894 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.29883352,\n",
            " 'Loss/localization_loss': 0.005498769,\n",
            " 'Loss/regularization_loss': 0.06275349,\n",
            " 'Loss/total_loss': 0.36708578,\n",
            " 'learning_rate': 0.7893925}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.432s\n",
            "I1112 14:33:14.760173 139621605971840 model_lib_v2.py:707] Step 4700 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26348075,\n",
            " 'Loss/localization_loss': 0.0046474617,\n",
            " 'Loss/regularization_loss': 0.06272893,\n",
            " 'Loss/total_loss': 0.33085716,\n",
            " 'learning_rate': 0.7887978}\n",
            "I1112 14:33:14.760545 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.26348075,\n",
            " 'Loss/localization_loss': 0.0046474617,\n",
            " 'Loss/regularization_loss': 0.06272893,\n",
            " 'Loss/total_loss': 0.33085716,\n",
            " 'learning_rate': 0.7887978}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.429s\n",
            "I1112 14:33:57.707893 139621605971840 model_lib_v2.py:707] Step 4800 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22289436,\n",
            " 'Loss/localization_loss': 0.0055307224,\n",
            " 'Loss/regularization_loss': 0.06315898,\n",
            " 'Loss/total_loss': 0.29158407,\n",
            " 'learning_rate': 0.78818715}\n",
            "I1112 14:33:57.708227 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22289436,\n",
            " 'Loss/localization_loss': 0.0055307224,\n",
            " 'Loss/regularization_loss': 0.06315898,\n",
            " 'Loss/total_loss': 0.29158407,\n",
            " 'learning_rate': 0.78818715}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.433s\n",
            "I1112 14:34:40.961350 139621605971840 model_lib_v2.py:707] Step 4900 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3061503,\n",
            " 'Loss/localization_loss': 0.0057016485,\n",
            " 'Loss/regularization_loss': 0.06350927,\n",
            " 'Loss/total_loss': 0.3753612,\n",
            " 'learning_rate': 0.7875605}\n",
            "I1112 14:34:40.961683 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.3061503,\n",
            " 'Loss/localization_loss': 0.0057016485,\n",
            " 'Loss/regularization_loss': 0.06350927,\n",
            " 'Loss/total_loss': 0.3753612,\n",
            " 'learning_rate': 0.7875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.432s\n",
            "I1112 14:35:24.162384 139621605971840 model_lib_v2.py:707] Step 5000 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19072978,\n",
            " 'Loss/localization_loss': 0.0028451474,\n",
            " 'Loss/regularization_loss': 0.06345827,\n",
            " 'Loss/total_loss': 0.2570332,\n",
            " 'learning_rate': 0.786918}\n",
            "I1112 14:35:24.162797 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19072978,\n",
            " 'Loss/localization_loss': 0.0028451474,\n",
            " 'Loss/regularization_loss': 0.06345827,\n",
            " 'Loss/total_loss': 0.2570332,\n",
            " 'learning_rate': 0.786918}\n",
            "INFO:tensorflow:Step 5100 per-step time 0.453s\n",
            "I1112 14:36:09.493137 139621605971840 model_lib_v2.py:707] Step 5100 per-step time 0.453s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22288553,\n",
            " 'Loss/localization_loss': 0.004606922,\n",
            " 'Loss/regularization_loss': 0.06378088,\n",
            " 'Loss/total_loss': 0.29127333,\n",
            " 'learning_rate': 0.7862595}\n",
            "I1112 14:36:09.493502 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22288553,\n",
            " 'Loss/localization_loss': 0.004606922,\n",
            " 'Loss/regularization_loss': 0.06378088,\n",
            " 'Loss/total_loss': 0.29127333,\n",
            " 'learning_rate': 0.7862595}\n",
            "INFO:tensorflow:Step 5200 per-step time 0.434s\n",
            "I1112 14:36:52.886792 139621605971840 model_lib_v2.py:707] Step 5200 per-step time 0.434s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19391549,\n",
            " 'Loss/localization_loss': 0.0030698245,\n",
            " 'Loss/regularization_loss': 0.06369417,\n",
            " 'Loss/total_loss': 0.26067948,\n",
            " 'learning_rate': 0.7855851}\n",
            "I1112 14:36:52.887124 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19391549,\n",
            " 'Loss/localization_loss': 0.0030698245,\n",
            " 'Loss/regularization_loss': 0.06369417,\n",
            " 'Loss/total_loss': 0.26067948,\n",
            " 'learning_rate': 0.7855851}\n",
            "INFO:tensorflow:Step 5300 per-step time 0.432s\n",
            "I1112 14:37:36.086437 139621605971840 model_lib_v2.py:707] Step 5300 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.29296914,\n",
            " 'Loss/localization_loss': 0.005517851,\n",
            " 'Loss/regularization_loss': 0.0640741,\n",
            " 'Loss/total_loss': 0.36256108,\n",
            " 'learning_rate': 0.78489494}\n",
            "I1112 14:37:36.086808 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.29296914,\n",
            " 'Loss/localization_loss': 0.005517851,\n",
            " 'Loss/regularization_loss': 0.0640741,\n",
            " 'Loss/total_loss': 0.36256108,\n",
            " 'learning_rate': 0.78489494}\n",
            "INFO:tensorflow:Step 5400 per-step time 0.432s\n",
            "I1112 14:38:19.260802 139621605971840 model_lib_v2.py:707] Step 5400 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.36034817,\n",
            " 'Loss/localization_loss': 0.0066207973,\n",
            " 'Loss/regularization_loss': 0.06457075,\n",
            " 'Loss/total_loss': 0.4315397,\n",
            " 'learning_rate': 0.7841889}\n",
            "I1112 14:38:19.261130 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.36034817,\n",
            " 'Loss/localization_loss': 0.0066207973,\n",
            " 'Loss/regularization_loss': 0.06457075,\n",
            " 'Loss/total_loss': 0.4315397,\n",
            " 'learning_rate': 0.7841889}\n",
            "INFO:tensorflow:Step 5500 per-step time 0.431s\n",
            "I1112 14:39:02.311614 139621605971840 model_lib_v2.py:707] Step 5500 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23048462,\n",
            " 'Loss/localization_loss': 0.0049261297,\n",
            " 'Loss/regularization_loss': 0.06475897,\n",
            " 'Loss/total_loss': 0.3001697,\n",
            " 'learning_rate': 0.7834672}\n",
            "I1112 14:39:02.311962 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23048462,\n",
            " 'Loss/localization_loss': 0.0049261297,\n",
            " 'Loss/regularization_loss': 0.06475897,\n",
            " 'Loss/total_loss': 0.3001697,\n",
            " 'learning_rate': 0.7834672}\n",
            "INFO:tensorflow:Step 5600 per-step time 0.434s\n",
            "I1112 14:39:45.717602 139621605971840 model_lib_v2.py:707] Step 5600 per-step time 0.434s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24713647,\n",
            " 'Loss/localization_loss': 0.006021108,\n",
            " 'Loss/regularization_loss': 0.06507926,\n",
            " 'Loss/total_loss': 0.31823683,\n",
            " 'learning_rate': 0.78272957}\n",
            "I1112 14:39:45.717927 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24713647,\n",
            " 'Loss/localization_loss': 0.006021108,\n",
            " 'Loss/regularization_loss': 0.06507926,\n",
            " 'Loss/total_loss': 0.31823683,\n",
            " 'learning_rate': 0.78272957}\n",
            "INFO:tensorflow:Step 5700 per-step time 0.432s\n",
            "I1112 14:40:28.959663 139621605971840 model_lib_v2.py:707] Step 5700 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24060263,\n",
            " 'Loss/localization_loss': 0.0060149375,\n",
            " 'Loss/regularization_loss': 0.06520982,\n",
            " 'Loss/total_loss': 0.3118274,\n",
            " 'learning_rate': 0.7819763}\n",
            "I1112 14:40:28.960025 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24060263,\n",
            " 'Loss/localization_loss': 0.0060149375,\n",
            " 'Loss/regularization_loss': 0.06520982,\n",
            " 'Loss/total_loss': 0.3118274,\n",
            " 'learning_rate': 0.7819763}\n",
            "INFO:tensorflow:Step 5800 per-step time 0.432s\n",
            "I1112 14:41:12.194451 139621605971840 model_lib_v2.py:707] Step 5800 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.35349038,\n",
            " 'Loss/localization_loss': 0.0077822944,\n",
            " 'Loss/regularization_loss': 0.065398775,\n",
            " 'Loss/total_loss': 0.42667145,\n",
            " 'learning_rate': 0.78120726}\n",
            "I1112 14:41:12.194789 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.35349038,\n",
            " 'Loss/localization_loss': 0.0077822944,\n",
            " 'Loss/regularization_loss': 0.065398775,\n",
            " 'Loss/total_loss': 0.42667145,\n",
            " 'learning_rate': 0.78120726}\n",
            "INFO:tensorflow:Step 5900 per-step time 0.432s\n",
            "I1112 14:41:55.440692 139621605971840 model_lib_v2.py:707] Step 5900 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25320616,\n",
            " 'Loss/localization_loss': 0.0051436094,\n",
            " 'Loss/regularization_loss': 0.06569691,\n",
            " 'Loss/total_loss': 0.32404667,\n",
            " 'learning_rate': 0.7804226}\n",
            "I1112 14:41:55.441059 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25320616,\n",
            " 'Loss/localization_loss': 0.0051436094,\n",
            " 'Loss/regularization_loss': 0.06569691,\n",
            " 'Loss/total_loss': 0.32404667,\n",
            " 'learning_rate': 0.7804226}\n",
            "INFO:tensorflow:Step 6000 per-step time 0.432s\n",
            "I1112 14:42:38.635872 139621605971840 model_lib_v2.py:707] Step 6000 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2846496,\n",
            " 'Loss/localization_loss': 0.004659667,\n",
            " 'Loss/regularization_loss': 0.06615993,\n",
            " 'Loss/total_loss': 0.3554692,\n",
            " 'learning_rate': 0.77962226}\n",
            "I1112 14:42:38.636259 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2846496,\n",
            " 'Loss/localization_loss': 0.004659667,\n",
            " 'Loss/regularization_loss': 0.06615993,\n",
            " 'Loss/total_loss': 0.3554692,\n",
            " 'learning_rate': 0.77962226}\n",
            "INFO:tensorflow:Step 6100 per-step time 0.453s\n",
            "I1112 14:43:23.949905 139621605971840 model_lib_v2.py:707] Step 6100 per-step time 0.453s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31366274,\n",
            " 'Loss/localization_loss': 0.008165473,\n",
            " 'Loss/regularization_loss': 0.0663942,\n",
            " 'Loss/total_loss': 0.38822243,\n",
            " 'learning_rate': 0.7788064}\n",
            "I1112 14:43:23.950261 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.31366274,\n",
            " 'Loss/localization_loss': 0.008165473,\n",
            " 'Loss/regularization_loss': 0.0663942,\n",
            " 'Loss/total_loss': 0.38822243,\n",
            " 'learning_rate': 0.7788064}\n",
            "INFO:tensorflow:Step 6200 per-step time 0.431s\n",
            "I1112 14:44:07.017005 139621605971840 model_lib_v2.py:707] Step 6200 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3758839,\n",
            " 'Loss/localization_loss': 0.0073982943,\n",
            " 'Loss/regularization_loss': 0.06643274,\n",
            " 'Loss/total_loss': 0.44971496,\n",
            " 'learning_rate': 0.7779749}\n",
            "I1112 14:44:07.017331 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.3758839,\n",
            " 'Loss/localization_loss': 0.0073982943,\n",
            " 'Loss/regularization_loss': 0.06643274,\n",
            " 'Loss/total_loss': 0.44971496,\n",
            " 'learning_rate': 0.7779749}\n",
            "INFO:tensorflow:Step 6300 per-step time 0.431s\n",
            "I1112 14:44:50.142502 139621605971840 model_lib_v2.py:707] Step 6300 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20566946,\n",
            " 'Loss/localization_loss': 0.0049222936,\n",
            " 'Loss/regularization_loss': 0.06664123,\n",
            " 'Loss/total_loss': 0.277233,\n",
            " 'learning_rate': 0.7771279}\n",
            "I1112 14:44:50.142884 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20566946,\n",
            " 'Loss/localization_loss': 0.0049222936,\n",
            " 'Loss/regularization_loss': 0.06664123,\n",
            " 'Loss/total_loss': 0.277233,\n",
            " 'learning_rate': 0.7771279}\n",
            "INFO:tensorflow:Step 6400 per-step time 0.432s\n",
            "I1112 14:45:33.359462 139621605971840 model_lib_v2.py:707] Step 6400 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.37238365,\n",
            " 'Loss/localization_loss': 0.007904139,\n",
            " 'Loss/regularization_loss': 0.067102395,\n",
            " 'Loss/total_loss': 0.4473902,\n",
            " 'learning_rate': 0.7762653}\n",
            "I1112 14:45:33.359798 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.37238365,\n",
            " 'Loss/localization_loss': 0.007904139,\n",
            " 'Loss/regularization_loss': 0.067102395,\n",
            " 'Loss/total_loss': 0.4473902,\n",
            " 'learning_rate': 0.7762653}\n",
            "INFO:tensorflow:Step 6500 per-step time 0.431s\n",
            "I1112 14:46:16.473875 139621605971840 model_lib_v2.py:707] Step 6500 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15856348,\n",
            " 'Loss/localization_loss': 0.0029434413,\n",
            " 'Loss/regularization_loss': 0.06739877,\n",
            " 'Loss/total_loss': 0.2289057,\n",
            " 'learning_rate': 0.7753874}\n",
            "I1112 14:46:16.474209 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.15856348,\n",
            " 'Loss/localization_loss': 0.0029434413,\n",
            " 'Loss/regularization_loss': 0.06739877,\n",
            " 'Loss/total_loss': 0.2289057,\n",
            " 'learning_rate': 0.7753874}\n",
            "INFO:tensorflow:Step 6600 per-step time 0.430s\n",
            "I1112 14:46:59.469516 139621605971840 model_lib_v2.py:707] Step 6600 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19317028,\n",
            " 'Loss/localization_loss': 0.0036457612,\n",
            " 'Loss/regularization_loss': 0.06792417,\n",
            " 'Loss/total_loss': 0.26474023,\n",
            " 'learning_rate': 0.774494}\n",
            "I1112 14:46:59.469842 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19317028,\n",
            " 'Loss/localization_loss': 0.0036457612,\n",
            " 'Loss/regularization_loss': 0.06792417,\n",
            " 'Loss/total_loss': 0.26474023,\n",
            " 'learning_rate': 0.774494}\n",
            "INFO:tensorflow:Step 6700 per-step time 0.433s\n",
            "I1112 14:47:42.794417 139621605971840 model_lib_v2.py:707] Step 6700 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23116787,\n",
            " 'Loss/localization_loss': 0.0045207376,\n",
            " 'Loss/regularization_loss': 0.068187125,\n",
            " 'Loss/total_loss': 0.30387574,\n",
            " 'learning_rate': 0.77358514}\n",
            "I1112 14:47:42.794732 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23116787,\n",
            " 'Loss/localization_loss': 0.0045207376,\n",
            " 'Loss/regularization_loss': 0.068187125,\n",
            " 'Loss/total_loss': 0.30387574,\n",
            " 'learning_rate': 0.77358514}\n",
            "INFO:tensorflow:Step 6800 per-step time 0.427s\n",
            "I1112 14:48:25.528815 139621605971840 model_lib_v2.py:707] Step 6800 per-step time 0.427s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20224552,\n",
            " 'Loss/localization_loss': 0.0021503968,\n",
            " 'Loss/regularization_loss': 0.06869975,\n",
            " 'Loss/total_loss': 0.27309567,\n",
            " 'learning_rate': 0.772661}\n",
            "I1112 14:48:25.529126 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20224552,\n",
            " 'Loss/localization_loss': 0.0021503968,\n",
            " 'Loss/regularization_loss': 0.06869975,\n",
            " 'Loss/total_loss': 0.27309567,\n",
            " 'learning_rate': 0.772661}\n",
            "INFO:tensorflow:Step 6900 per-step time 0.432s\n",
            "I1112 14:49:08.704310 139621605971840 model_lib_v2.py:707] Step 6900 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25297904,\n",
            " 'Loss/localization_loss': 0.0028216867,\n",
            " 'Loss/regularization_loss': 0.06889555,\n",
            " 'Loss/total_loss': 0.32469627,\n",
            " 'learning_rate': 0.7717215}\n",
            "I1112 14:49:08.704638 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25297904,\n",
            " 'Loss/localization_loss': 0.0028216867,\n",
            " 'Loss/regularization_loss': 0.06889555,\n",
            " 'Loss/total_loss': 0.32469627,\n",
            " 'learning_rate': 0.7717215}\n",
            "INFO:tensorflow:Step 7000 per-step time 0.430s\n",
            "I1112 14:49:51.683450 139621605971840 model_lib_v2.py:707] Step 7000 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2177424,\n",
            " 'Loss/localization_loss': 0.0051955343,\n",
            " 'Loss/regularization_loss': 0.06894322,\n",
            " 'Loss/total_loss': 0.29188114,\n",
            " 'learning_rate': 0.77076674}\n",
            "I1112 14:49:51.683770 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2177424,\n",
            " 'Loss/localization_loss': 0.0051955343,\n",
            " 'Loss/regularization_loss': 0.06894322,\n",
            " 'Loss/total_loss': 0.29188114,\n",
            " 'learning_rate': 0.77076674}\n",
            "INFO:tensorflow:Step 7100 per-step time 0.453s\n",
            "I1112 14:50:36.938942 139621605971840 model_lib_v2.py:707] Step 7100 per-step time 0.453s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.165849,\n",
            " 'Loss/localization_loss': 0.0033087619,\n",
            " 'Loss/regularization_loss': 0.0691369,\n",
            " 'Loss/total_loss': 0.23829466,\n",
            " 'learning_rate': 0.7697967}\n",
            "I1112 14:50:36.939296 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.165849,\n",
            " 'Loss/localization_loss': 0.0033087619,\n",
            " 'Loss/regularization_loss': 0.0691369,\n",
            " 'Loss/total_loss': 0.23829466,\n",
            " 'learning_rate': 0.7697967}\n",
            "INFO:tensorflow:Step 7200 per-step time 0.430s\n",
            "I1112 14:51:19.922204 139621605971840 model_lib_v2.py:707] Step 7200 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25037742,\n",
            " 'Loss/localization_loss': 0.003945665,\n",
            " 'Loss/regularization_loss': 0.06943176,\n",
            " 'Loss/total_loss': 0.32375485,\n",
            " 'learning_rate': 0.7688115}\n",
            "I1112 14:51:19.922530 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25037742,\n",
            " 'Loss/localization_loss': 0.003945665,\n",
            " 'Loss/regularization_loss': 0.06943176,\n",
            " 'Loss/total_loss': 0.32375485,\n",
            " 'learning_rate': 0.7688115}\n",
            "INFO:tensorflow:Step 7300 per-step time 0.428s\n",
            "I1112 14:52:02.719477 139621605971840 model_lib_v2.py:707] Step 7300 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18564115,\n",
            " 'Loss/localization_loss': 0.0042292853,\n",
            " 'Loss/regularization_loss': 0.06959163,\n",
            " 'Loss/total_loss': 0.25946206,\n",
            " 'learning_rate': 0.7678111}\n",
            "I1112 14:52:02.719794 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18564115,\n",
            " 'Loss/localization_loss': 0.0042292853,\n",
            " 'Loss/regularization_loss': 0.06959163,\n",
            " 'Loss/total_loss': 0.25946206,\n",
            " 'learning_rate': 0.7678111}\n",
            "INFO:tensorflow:Step 7400 per-step time 0.431s\n",
            "I1112 14:52:45.767079 139621605971840 model_lib_v2.py:707] Step 7400 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24668024,\n",
            " 'Loss/localization_loss': 0.0033285671,\n",
            " 'Loss/regularization_loss': 0.06963869,\n",
            " 'Loss/total_loss': 0.31964752,\n",
            " 'learning_rate': 0.76679564}\n",
            "I1112 14:52:45.767405 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24668024,\n",
            " 'Loss/localization_loss': 0.0033285671,\n",
            " 'Loss/regularization_loss': 0.06963869,\n",
            " 'Loss/total_loss': 0.31964752,\n",
            " 'learning_rate': 0.76679564}\n",
            "INFO:tensorflow:Step 7500 per-step time 0.430s\n",
            "I1112 14:53:28.807174 139621605971840 model_lib_v2.py:707] Step 7500 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21429017,\n",
            " 'Loss/localization_loss': 0.0034399685,\n",
            " 'Loss/regularization_loss': 0.07010064,\n",
            " 'Loss/total_loss': 0.28783077,\n",
            " 'learning_rate': 0.7657651}\n",
            "I1112 14:53:28.807491 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.21429017,\n",
            " 'Loss/localization_loss': 0.0034399685,\n",
            " 'Loss/regularization_loss': 0.07010064,\n",
            " 'Loss/total_loss': 0.28783077,\n",
            " 'learning_rate': 0.7657651}\n",
            "INFO:tensorflow:Step 7600 per-step time 0.431s\n",
            "I1112 14:54:11.956205 139621605971840 model_lib_v2.py:707] Step 7600 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23105328,\n",
            " 'Loss/localization_loss': 0.0044781244,\n",
            " 'Loss/regularization_loss': 0.070618086,\n",
            " 'Loss/total_loss': 0.30614948,\n",
            " 'learning_rate': 0.7647194}\n",
            "I1112 14:54:11.956517 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23105328,\n",
            " 'Loss/localization_loss': 0.0044781244,\n",
            " 'Loss/regularization_loss': 0.070618086,\n",
            " 'Loss/total_loss': 0.30614948,\n",
            " 'learning_rate': 0.7647194}\n",
            "INFO:tensorflow:Step 7700 per-step time 0.431s\n",
            "I1112 14:54:55.059406 139621605971840 model_lib_v2.py:707] Step 7700 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17982377,\n",
            " 'Loss/localization_loss': 0.0021737402,\n",
            " 'Loss/regularization_loss': 0.07092194,\n",
            " 'Loss/total_loss': 0.25291944,\n",
            " 'learning_rate': 0.7636589}\n",
            "I1112 14:54:55.059721 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.17982377,\n",
            " 'Loss/localization_loss': 0.0021737402,\n",
            " 'Loss/regularization_loss': 0.07092194,\n",
            " 'Loss/total_loss': 0.25291944,\n",
            " 'learning_rate': 0.7636589}\n",
            "INFO:tensorflow:Step 7800 per-step time 0.429s\n",
            "I1112 14:55:37.973343 139621605971840 model_lib_v2.py:707] Step 7800 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.38161522,\n",
            " 'Loss/localization_loss': 0.0045804908,\n",
            " 'Loss/regularization_loss': 0.07102628,\n",
            " 'Loss/total_loss': 0.45722198,\n",
            " 'learning_rate': 0.7625833}\n",
            "I1112 14:55:37.973654 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.38161522,\n",
            " 'Loss/localization_loss': 0.0045804908,\n",
            " 'Loss/regularization_loss': 0.07102628,\n",
            " 'Loss/total_loss': 0.45722198,\n",
            " 'learning_rate': 0.7625833}\n",
            "INFO:tensorflow:Step 7900 per-step time 0.431s\n",
            "I1112 14:56:21.072422 139621605971840 model_lib_v2.py:707] Step 7900 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24673058,\n",
            " 'Loss/localization_loss': 0.004789661,\n",
            " 'Loss/regularization_loss': 0.07164564,\n",
            " 'Loss/total_loss': 0.3231659,\n",
            " 'learning_rate': 0.76149285}\n",
            "I1112 14:56:21.072739 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24673058,\n",
            " 'Loss/localization_loss': 0.004789661,\n",
            " 'Loss/regularization_loss': 0.07164564,\n",
            " 'Loss/total_loss': 0.3231659,\n",
            " 'learning_rate': 0.76149285}\n",
            "INFO:tensorflow:Step 8000 per-step time 0.432s\n",
            "I1112 14:57:04.225748 139621605971840 model_lib_v2.py:707] Step 8000 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22633646,\n",
            " 'Loss/localization_loss': 0.005993693,\n",
            " 'Loss/regularization_loss': 0.07181372,\n",
            " 'Loss/total_loss': 0.30414388,\n",
            " 'learning_rate': 0.76038754}\n",
            "I1112 14:57:04.226060 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22633646,\n",
            " 'Loss/localization_loss': 0.005993693,\n",
            " 'Loss/regularization_loss': 0.07181372,\n",
            " 'Loss/total_loss': 0.30414388,\n",
            " 'learning_rate': 0.76038754}\n",
            "INFO:tensorflow:Step 8100 per-step time 0.452s\n",
            "I1112 14:57:49.472783 139621605971840 model_lib_v2.py:707] Step 8100 per-step time 0.452s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.41537842,\n",
            " 'Loss/localization_loss': 0.0055577415,\n",
            " 'Loss/regularization_loss': 0.071745455,\n",
            " 'Loss/total_loss': 0.49268162,\n",
            " 'learning_rate': 0.75926745}\n",
            "I1112 14:57:49.473114 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.41537842,\n",
            " 'Loss/localization_loss': 0.0055577415,\n",
            " 'Loss/regularization_loss': 0.071745455,\n",
            " 'Loss/total_loss': 0.49268162,\n",
            " 'learning_rate': 0.75926745}\n",
            "INFO:tensorflow:Step 8200 per-step time 0.430s\n",
            "I1112 14:58:32.431879 139621605971840 model_lib_v2.py:707] Step 8200 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.312164,\n",
            " 'Loss/localization_loss': 0.0076653017,\n",
            " 'Loss/regularization_loss': 0.07225385,\n",
            " 'Loss/total_loss': 0.39208317,\n",
            " 'learning_rate': 0.7581326}\n",
            "I1112 14:58:32.432218 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.312164,\n",
            " 'Loss/localization_loss': 0.0076653017,\n",
            " 'Loss/regularization_loss': 0.07225385,\n",
            " 'Loss/total_loss': 0.39208317,\n",
            " 'learning_rate': 0.7581326}\n",
            "INFO:tensorflow:Step 8300 per-step time 0.432s\n",
            "I1112 14:59:15.589084 139621605971840 model_lib_v2.py:707] Step 8300 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20819463,\n",
            " 'Loss/localization_loss': 0.0035045976,\n",
            " 'Loss/regularization_loss': 0.07236759,\n",
            " 'Loss/total_loss': 0.28406683,\n",
            " 'learning_rate': 0.7569829}\n",
            "I1112 14:59:15.589414 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20819463,\n",
            " 'Loss/localization_loss': 0.0035045976,\n",
            " 'Loss/regularization_loss': 0.07236759,\n",
            " 'Loss/total_loss': 0.28406683,\n",
            " 'learning_rate': 0.7569829}\n",
            "INFO:tensorflow:Step 8400 per-step time 0.433s\n",
            "I1112 14:59:58.868819 139621605971840 model_lib_v2.py:707] Step 8400 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23350352,\n",
            " 'Loss/localization_loss': 0.004696261,\n",
            " 'Loss/regularization_loss': 0.07257619,\n",
            " 'Loss/total_loss': 0.31077597,\n",
            " 'learning_rate': 0.75581867}\n",
            "I1112 14:59:58.869142 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23350352,\n",
            " 'Loss/localization_loss': 0.004696261,\n",
            " 'Loss/regularization_loss': 0.07257619,\n",
            " 'Loss/total_loss': 0.31077597,\n",
            " 'learning_rate': 0.75581867}\n",
            "INFO:tensorflow:Step 8500 per-step time 0.432s\n",
            "I1112 15:00:42.092142 139621605971840 model_lib_v2.py:707] Step 8500 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16345906,\n",
            " 'Loss/localization_loss': 0.0026981216,\n",
            " 'Loss/regularization_loss': 0.07284802,\n",
            " 'Loss/total_loss': 0.23900521,\n",
            " 'learning_rate': 0.75463974}\n",
            "I1112 15:00:42.092483 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16345906,\n",
            " 'Loss/localization_loss': 0.0026981216,\n",
            " 'Loss/regularization_loss': 0.07284802,\n",
            " 'Loss/total_loss': 0.23900521,\n",
            " 'learning_rate': 0.75463974}\n",
            "INFO:tensorflow:Step 8600 per-step time 0.430s\n",
            "I1112 15:01:25.062655 139621605971840 model_lib_v2.py:707] Step 8600 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22776645,\n",
            " 'Loss/localization_loss': 0.0033378631,\n",
            " 'Loss/regularization_loss': 0.073238425,\n",
            " 'Loss/total_loss': 0.30434275,\n",
            " 'learning_rate': 0.7534462}\n",
            "I1112 15:01:25.062981 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22776645,\n",
            " 'Loss/localization_loss': 0.0033378631,\n",
            " 'Loss/regularization_loss': 0.073238425,\n",
            " 'Loss/total_loss': 0.30434275,\n",
            " 'learning_rate': 0.7534462}\n",
            "INFO:tensorflow:Step 8700 per-step time 0.433s\n",
            "I1112 15:02:08.399199 139621605971840 model_lib_v2.py:707] Step 8700 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18192863,\n",
            " 'Loss/localization_loss': 0.0030390483,\n",
            " 'Loss/regularization_loss': 0.07334527,\n",
            " 'Loss/total_loss': 0.25831294,\n",
            " 'learning_rate': 0.7522382}\n",
            "I1112 15:02:08.399536 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18192863,\n",
            " 'Loss/localization_loss': 0.0030390483,\n",
            " 'Loss/regularization_loss': 0.07334527,\n",
            " 'Loss/total_loss': 0.25831294,\n",
            " 'learning_rate': 0.7522382}\n",
            "INFO:tensorflow:Step 8800 per-step time 0.430s\n",
            "I1112 15:02:51.426276 139621605971840 model_lib_v2.py:707] Step 8800 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19924568,\n",
            " 'Loss/localization_loss': 0.003307049,\n",
            " 'Loss/regularization_loss': 0.07360385,\n",
            " 'Loss/total_loss': 0.27615657,\n",
            " 'learning_rate': 0.7510157}\n",
            "I1112 15:02:51.426634 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19924568,\n",
            " 'Loss/localization_loss': 0.003307049,\n",
            " 'Loss/regularization_loss': 0.07360385,\n",
            " 'Loss/total_loss': 0.27615657,\n",
            " 'learning_rate': 0.7510157}\n",
            "INFO:tensorflow:Step 8900 per-step time 0.432s\n",
            "I1112 15:03:34.607238 139621605971840 model_lib_v2.py:707] Step 8900 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3584989,\n",
            " 'Loss/localization_loss': 0.0061939517,\n",
            " 'Loss/regularization_loss': 0.073858336,\n",
            " 'Loss/total_loss': 0.4385512,\n",
            " 'learning_rate': 0.7497788}\n",
            "I1112 15:03:34.607550 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.3584989,\n",
            " 'Loss/localization_loss': 0.0061939517,\n",
            " 'Loss/regularization_loss': 0.073858336,\n",
            " 'Loss/total_loss': 0.4385512,\n",
            " 'learning_rate': 0.7497788}\n",
            "INFO:tensorflow:Step 9000 per-step time 0.431s\n",
            "I1112 15:04:17.722720 139621605971840 model_lib_v2.py:707] Step 9000 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20681807,\n",
            " 'Loss/localization_loss': 0.0048509566,\n",
            " 'Loss/regularization_loss': 0.073846936,\n",
            " 'Loss/total_loss': 0.28551596,\n",
            " 'learning_rate': 0.74852747}\n",
            "I1112 15:04:17.723038 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20681807,\n",
            " 'Loss/localization_loss': 0.0048509566,\n",
            " 'Loss/regularization_loss': 0.073846936,\n",
            " 'Loss/total_loss': 0.28551596,\n",
            " 'learning_rate': 0.74852747}\n",
            "INFO:tensorflow:Step 9100 per-step time 0.455s\n",
            "I1112 15:05:03.204403 139621605971840 model_lib_v2.py:707] Step 9100 per-step time 0.455s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18868782,\n",
            " 'Loss/localization_loss': 0.0034888806,\n",
            " 'Loss/regularization_loss': 0.073871695,\n",
            " 'Loss/total_loss': 0.2660484,\n",
            " 'learning_rate': 0.7472619}\n",
            "I1112 15:05:03.204718 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18868782,\n",
            " 'Loss/localization_loss': 0.0034888806,\n",
            " 'Loss/regularization_loss': 0.073871695,\n",
            " 'Loss/total_loss': 0.2660484,\n",
            " 'learning_rate': 0.7472619}\n",
            "INFO:tensorflow:Step 9200 per-step time 0.432s\n",
            "I1112 15:05:46.382111 139621605971840 model_lib_v2.py:707] Step 9200 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22410516,\n",
            " 'Loss/localization_loss': 0.0039660255,\n",
            " 'Loss/regularization_loss': 0.073711514,\n",
            " 'Loss/total_loss': 0.3017827,\n",
            " 'learning_rate': 0.745982}\n",
            "I1112 15:05:46.382441 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22410516,\n",
            " 'Loss/localization_loss': 0.0039660255,\n",
            " 'Loss/regularization_loss': 0.073711514,\n",
            " 'Loss/total_loss': 0.3017827,\n",
            " 'learning_rate': 0.745982}\n",
            "INFO:tensorflow:Step 9300 per-step time 0.430s\n",
            "I1112 15:06:29.405336 139621605971840 model_lib_v2.py:707] Step 9300 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27412254,\n",
            " 'Loss/localization_loss': 0.004980132,\n",
            " 'Loss/regularization_loss': 0.07373513,\n",
            " 'Loss/total_loss': 0.3528378,\n",
            " 'learning_rate': 0.74468786}\n",
            "I1112 15:06:29.405647 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.27412254,\n",
            " 'Loss/localization_loss': 0.004980132,\n",
            " 'Loss/regularization_loss': 0.07373513,\n",
            " 'Loss/total_loss': 0.3528378,\n",
            " 'learning_rate': 0.74468786}\n",
            "INFO:tensorflow:Step 9400 per-step time 0.430s\n",
            "I1112 15:07:12.426756 139621605971840 model_lib_v2.py:707] Step 9400 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18355091,\n",
            " 'Loss/localization_loss': 0.002395582,\n",
            " 'Loss/regularization_loss': 0.073828265,\n",
            " 'Loss/total_loss': 0.25977474,\n",
            " 'learning_rate': 0.74337953}\n",
            "I1112 15:07:12.427075 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18355091,\n",
            " 'Loss/localization_loss': 0.002395582,\n",
            " 'Loss/regularization_loss': 0.073828265,\n",
            " 'Loss/total_loss': 0.25977474,\n",
            " 'learning_rate': 0.74337953}\n",
            "INFO:tensorflow:Step 9500 per-step time 0.430s\n",
            "I1112 15:07:55.402739 139621605971840 model_lib_v2.py:707] Step 9500 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2985553,\n",
            " 'Loss/localization_loss': 0.0056677544,\n",
            " 'Loss/regularization_loss': 0.074185796,\n",
            " 'Loss/total_loss': 0.37840885,\n",
            " 'learning_rate': 0.7420571}\n",
            "I1112 15:07:55.403054 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2985553,\n",
            " 'Loss/localization_loss': 0.0056677544,\n",
            " 'Loss/regularization_loss': 0.074185796,\n",
            " 'Loss/total_loss': 0.37840885,\n",
            " 'learning_rate': 0.7420571}\n",
            "INFO:tensorflow:Step 9600 per-step time 0.430s\n",
            "I1112 15:08:38.405999 139621605971840 model_lib_v2.py:707] Step 9600 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19658843,\n",
            " 'Loss/localization_loss': 0.0036340351,\n",
            " 'Loss/regularization_loss': 0.07426126,\n",
            " 'Loss/total_loss': 0.27448374,\n",
            " 'learning_rate': 0.7407207}\n",
            "I1112 15:08:38.406321 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19658843,\n",
            " 'Loss/localization_loss': 0.0036340351,\n",
            " 'Loss/regularization_loss': 0.07426126,\n",
            " 'Loss/total_loss': 0.27448374,\n",
            " 'learning_rate': 0.7407207}\n",
            "INFO:tensorflow:Step 9700 per-step time 0.429s\n",
            "I1112 15:09:21.308090 139621605971840 model_lib_v2.py:707] Step 9700 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18644588,\n",
            " 'Loss/localization_loss': 0.0027473206,\n",
            " 'Loss/regularization_loss': 0.074655205,\n",
            " 'Loss/total_loss': 0.26384842,\n",
            " 'learning_rate': 0.73937017}\n",
            "I1112 15:09:21.308420 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18644588,\n",
            " 'Loss/localization_loss': 0.0027473206,\n",
            " 'Loss/regularization_loss': 0.074655205,\n",
            " 'Loss/total_loss': 0.26384842,\n",
            " 'learning_rate': 0.73937017}\n",
            "INFO:tensorflow:Step 9800 per-step time 0.428s\n",
            "I1112 15:10:04.157382 139621605971840 model_lib_v2.py:707] Step 9800 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22695954,\n",
            " 'Loss/localization_loss': 0.003469331,\n",
            " 'Loss/regularization_loss': 0.07460194,\n",
            " 'Loss/total_loss': 0.30503082,\n",
            " 'learning_rate': 0.73800576}\n",
            "I1112 15:10:04.157741 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22695954,\n",
            " 'Loss/localization_loss': 0.003469331,\n",
            " 'Loss/regularization_loss': 0.07460194,\n",
            " 'Loss/total_loss': 0.30503082,\n",
            " 'learning_rate': 0.73800576}\n",
            "INFO:tensorflow:Step 9900 per-step time 0.430s\n",
            "I1112 15:10:47.161568 139621605971840 model_lib_v2.py:707] Step 9900 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23583788,\n",
            " 'Loss/localization_loss': 0.005418875,\n",
            " 'Loss/regularization_loss': 0.074945025,\n",
            " 'Loss/total_loss': 0.31620178,\n",
            " 'learning_rate': 0.7366274}\n",
            "I1112 15:10:47.161896 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23583788,\n",
            " 'Loss/localization_loss': 0.005418875,\n",
            " 'Loss/regularization_loss': 0.074945025,\n",
            " 'Loss/total_loss': 0.31620178,\n",
            " 'learning_rate': 0.7366274}\n",
            "INFO:tensorflow:Step 10000 per-step time 0.430s\n",
            "I1112 15:11:30.173658 139621605971840 model_lib_v2.py:707] Step 10000 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15373808,\n",
            " 'Loss/localization_loss': 0.00266511,\n",
            " 'Loss/regularization_loss': 0.074627295,\n",
            " 'Loss/total_loss': 0.23103048,\n",
            " 'learning_rate': 0.7352353}\n",
            "I1112 15:11:30.173981 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.15373808,\n",
            " 'Loss/localization_loss': 0.00266511,\n",
            " 'Loss/regularization_loss': 0.074627295,\n",
            " 'Loss/total_loss': 0.23103048,\n",
            " 'learning_rate': 0.7352353}\n",
            "INFO:tensorflow:Step 10100 per-step time 0.456s\n",
            "I1112 15:12:15.811635 139621605971840 model_lib_v2.py:707] Step 10100 per-step time 0.456s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2767717,\n",
            " 'Loss/localization_loss': 0.0060852193,\n",
            " 'Loss/regularization_loss': 0.07477668,\n",
            " 'Loss/total_loss': 0.3576336,\n",
            " 'learning_rate': 0.7338293}\n",
            "I1112 15:12:15.811968 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2767717,\n",
            " 'Loss/localization_loss': 0.0060852193,\n",
            " 'Loss/regularization_loss': 0.07477668,\n",
            " 'Loss/total_loss': 0.3576336,\n",
            " 'learning_rate': 0.7338293}\n",
            "INFO:tensorflow:Step 10200 per-step time 0.431s\n",
            "I1112 15:12:58.902219 139621605971840 model_lib_v2.py:707] Step 10200 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3018959,\n",
            " 'Loss/localization_loss': 0.009268661,\n",
            " 'Loss/regularization_loss': 0.077607095,\n",
            " 'Loss/total_loss': 0.38877165,\n",
            " 'learning_rate': 0.73240966}\n",
            "I1112 15:12:58.902584 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.3018959,\n",
            " 'Loss/localization_loss': 0.009268661,\n",
            " 'Loss/regularization_loss': 0.077607095,\n",
            " 'Loss/total_loss': 0.38877165,\n",
            " 'learning_rate': 0.73240966}\n",
            "INFO:tensorflow:Step 10300 per-step time 0.430s\n",
            "I1112 15:13:41.942500 139621605971840 model_lib_v2.py:707] Step 10300 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20676489,\n",
            " 'Loss/localization_loss': 0.0032629524,\n",
            " 'Loss/regularization_loss': 0.07776372,\n",
            " 'Loss/total_loss': 0.28779155,\n",
            " 'learning_rate': 0.7309763}\n",
            "I1112 15:13:41.942831 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20676489,\n",
            " 'Loss/localization_loss': 0.0032629524,\n",
            " 'Loss/regularization_loss': 0.07776372,\n",
            " 'Loss/total_loss': 0.28779155,\n",
            " 'learning_rate': 0.7309763}\n",
            "INFO:tensorflow:Step 10400 per-step time 0.428s\n",
            "I1112 15:14:24.783216 139621605971840 model_lib_v2.py:707] Step 10400 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17801678,\n",
            " 'Loss/localization_loss': 0.0029483614,\n",
            " 'Loss/regularization_loss': 0.07770691,\n",
            " 'Loss/total_loss': 0.25867206,\n",
            " 'learning_rate': 0.7295294}\n",
            "I1112 15:14:24.783545 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.17801678,\n",
            " 'Loss/localization_loss': 0.0029483614,\n",
            " 'Loss/regularization_loss': 0.07770691,\n",
            " 'Loss/total_loss': 0.25867206,\n",
            " 'learning_rate': 0.7295294}\n",
            "INFO:tensorflow:Step 10500 per-step time 0.429s\n",
            "I1112 15:15:07.724479 139621605971840 model_lib_v2.py:707] Step 10500 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18647474,\n",
            " 'Loss/localization_loss': 0.0024587512,\n",
            " 'Loss/regularization_loss': 0.0778277,\n",
            " 'Loss/total_loss': 0.26676118,\n",
            " 'learning_rate': 0.72806895}\n",
            "I1112 15:15:07.724811 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18647474,\n",
            " 'Loss/localization_loss': 0.0024587512,\n",
            " 'Loss/regularization_loss': 0.0778277,\n",
            " 'Loss/total_loss': 0.26676118,\n",
            " 'learning_rate': 0.72806895}\n",
            "INFO:tensorflow:Step 10600 per-step time 0.430s\n",
            "I1112 15:15:50.746768 139621605971840 model_lib_v2.py:707] Step 10600 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19897954,\n",
            " 'Loss/localization_loss': 0.002539567,\n",
            " 'Loss/regularization_loss': 0.077570856,\n",
            " 'Loss/total_loss': 0.27908996,\n",
            " 'learning_rate': 0.7265949}\n",
            "I1112 15:15:50.747085 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19897954,\n",
            " 'Loss/localization_loss': 0.002539567,\n",
            " 'Loss/regularization_loss': 0.077570856,\n",
            " 'Loss/total_loss': 0.27908996,\n",
            " 'learning_rate': 0.7265949}\n",
            "INFO:tensorflow:Step 10700 per-step time 0.428s\n",
            "I1112 15:16:33.523316 139621605971840 model_lib_v2.py:707] Step 10700 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25541705,\n",
            " 'Loss/localization_loss': 0.004751583,\n",
            " 'Loss/regularization_loss': 0.07756453,\n",
            " 'Loss/total_loss': 0.33773318,\n",
            " 'learning_rate': 0.7251076}\n",
            "I1112 15:16:33.523631 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25541705,\n",
            " 'Loss/localization_loss': 0.004751583,\n",
            " 'Loss/regularization_loss': 0.07756453,\n",
            " 'Loss/total_loss': 0.33773318,\n",
            " 'learning_rate': 0.7251076}\n",
            "INFO:tensorflow:Step 10800 per-step time 0.430s\n",
            "I1112 15:17:16.513905 139621605971840 model_lib_v2.py:707] Step 10800 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19935879,\n",
            " 'Loss/localization_loss': 0.0026829722,\n",
            " 'Loss/regularization_loss': 0.07748516,\n",
            " 'Loss/total_loss': 0.27952692,\n",
            " 'learning_rate': 0.72360677}\n",
            "I1112 15:17:16.514237 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19935879,\n",
            " 'Loss/localization_loss': 0.0026829722,\n",
            " 'Loss/regularization_loss': 0.07748516,\n",
            " 'Loss/total_loss': 0.27952692,\n",
            " 'learning_rate': 0.72360677}\n",
            "INFO:tensorflow:Step 10900 per-step time 0.428s\n",
            "I1112 15:17:59.366403 139621605971840 model_lib_v2.py:707] Step 10900 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20080808,\n",
            " 'Loss/localization_loss': 0.0032880083,\n",
            " 'Loss/regularization_loss': 0.07768883,\n",
            " 'Loss/total_loss': 0.2817849,\n",
            " 'learning_rate': 0.72209275}\n",
            "I1112 15:17:59.366719 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20080808,\n",
            " 'Loss/localization_loss': 0.0032880083,\n",
            " 'Loss/regularization_loss': 0.07768883,\n",
            " 'Loss/total_loss': 0.2817849,\n",
            " 'learning_rate': 0.72209275}\n",
            "INFO:tensorflow:Step 11000 per-step time 0.431s\n",
            "I1112 15:18:42.477916 139621605971840 model_lib_v2.py:707] Step 11000 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23809525,\n",
            " 'Loss/localization_loss': 0.0054318146,\n",
            " 'Loss/regularization_loss': 0.078619346,\n",
            " 'Loss/total_loss': 0.32214642,\n",
            " 'learning_rate': 0.7205655}\n",
            "I1112 15:18:42.478248 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23809525,\n",
            " 'Loss/localization_loss': 0.0054318146,\n",
            " 'Loss/regularization_loss': 0.078619346,\n",
            " 'Loss/total_loss': 0.32214642,\n",
            " 'learning_rate': 0.7205655}\n",
            "INFO:tensorflow:Step 11100 per-step time 0.450s\n",
            "I1112 15:19:27.437994 139621605971840 model_lib_v2.py:707] Step 11100 per-step time 0.450s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25773466,\n",
            " 'Loss/localization_loss': 0.006844837,\n",
            " 'Loss/regularization_loss': 0.078648694,\n",
            " 'Loss/total_loss': 0.3432282,\n",
            " 'learning_rate': 0.71902496}\n",
            "I1112 15:19:27.438334 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25773466,\n",
            " 'Loss/localization_loss': 0.006844837,\n",
            " 'Loss/regularization_loss': 0.078648694,\n",
            " 'Loss/total_loss': 0.3432282,\n",
            " 'learning_rate': 0.71902496}\n",
            "INFO:tensorflow:Step 11200 per-step time 0.429s\n",
            "I1112 15:20:10.351848 139621605971840 model_lib_v2.py:707] Step 11200 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22656001,\n",
            " 'Loss/localization_loss': 0.0045874747,\n",
            " 'Loss/regularization_loss': 0.078748055,\n",
            " 'Loss/total_loss': 0.30989555,\n",
            " 'learning_rate': 0.7174714}\n",
            "I1112 15:20:10.352156 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22656001,\n",
            " 'Loss/localization_loss': 0.0045874747,\n",
            " 'Loss/regularization_loss': 0.078748055,\n",
            " 'Loss/total_loss': 0.30989555,\n",
            " 'learning_rate': 0.7174714}\n",
            "INFO:tensorflow:Step 11300 per-step time 0.428s\n",
            "I1112 15:20:53.157699 139621605971840 model_lib_v2.py:707] Step 11300 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22354183,\n",
            " 'Loss/localization_loss': 0.004549267,\n",
            " 'Loss/regularization_loss': 0.078555435,\n",
            " 'Loss/total_loss': 0.30664653,\n",
            " 'learning_rate': 0.7159048}\n",
            "I1112 15:20:53.158033 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22354183,\n",
            " 'Loss/localization_loss': 0.004549267,\n",
            " 'Loss/regularization_loss': 0.078555435,\n",
            " 'Loss/total_loss': 0.30664653,\n",
            " 'learning_rate': 0.7159048}\n",
            "INFO:tensorflow:Step 11400 per-step time 0.431s\n",
            "I1112 15:21:36.292066 139621605971840 model_lib_v2.py:707] Step 11400 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1667304,\n",
            " 'Loss/localization_loss': 0.0023282664,\n",
            " 'Loss/regularization_loss': 0.07841863,\n",
            " 'Loss/total_loss': 0.2474773,\n",
            " 'learning_rate': 0.71432513}\n",
            "I1112 15:21:36.292440 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1667304,\n",
            " 'Loss/localization_loss': 0.0023282664,\n",
            " 'Loss/regularization_loss': 0.07841863,\n",
            " 'Loss/total_loss': 0.2474773,\n",
            " 'learning_rate': 0.71432513}\n",
            "INFO:tensorflow:Step 11500 per-step time 0.430s\n",
            "I1112 15:22:19.242385 139621605971840 model_lib_v2.py:707] Step 11500 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21216238,\n",
            " 'Loss/localization_loss': 0.0017489147,\n",
            " 'Loss/regularization_loss': 0.07818727,\n",
            " 'Loss/total_loss': 0.29209858,\n",
            " 'learning_rate': 0.7127326}\n",
            "I1112 15:22:19.242708 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.21216238,\n",
            " 'Loss/localization_loss': 0.0017489147,\n",
            " 'Loss/regularization_loss': 0.07818727,\n",
            " 'Loss/total_loss': 0.29209858,\n",
            " 'learning_rate': 0.7127326}\n",
            "INFO:tensorflow:Step 11600 per-step time 0.431s\n",
            "I1112 15:23:02.372306 139621605971840 model_lib_v2.py:707] Step 11600 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24657573,\n",
            " 'Loss/localization_loss': 0.0049831136,\n",
            " 'Loss/regularization_loss': 0.078211226,\n",
            " 'Loss/total_loss': 0.32977006,\n",
            " 'learning_rate': 0.7111272}\n",
            "I1112 15:23:02.372616 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24657573,\n",
            " 'Loss/localization_loss': 0.0049831136,\n",
            " 'Loss/regularization_loss': 0.078211226,\n",
            " 'Loss/total_loss': 0.32977006,\n",
            " 'learning_rate': 0.7111272}\n",
            "INFO:tensorflow:Step 11700 per-step time 0.431s\n",
            "I1112 15:23:45.462127 139621605971840 model_lib_v2.py:707] Step 11700 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18528076,\n",
            " 'Loss/localization_loss': 0.0029934987,\n",
            " 'Loss/regularization_loss': 0.07845254,\n",
            " 'Loss/total_loss': 0.2667268,\n",
            " 'learning_rate': 0.709509}\n",
            "I1112 15:23:45.462476 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18528076,\n",
            " 'Loss/localization_loss': 0.0029934987,\n",
            " 'Loss/regularization_loss': 0.07845254,\n",
            " 'Loss/total_loss': 0.2667268,\n",
            " 'learning_rate': 0.709509}\n",
            "INFO:tensorflow:Step 11800 per-step time 0.431s\n",
            "I1112 15:24:28.543644 139621605971840 model_lib_v2.py:707] Step 11800 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24256107,\n",
            " 'Loss/localization_loss': 0.0067402213,\n",
            " 'Loss/regularization_loss': 0.07866768,\n",
            " 'Loss/total_loss': 0.32796898,\n",
            " 'learning_rate': 0.7078781}\n",
            "I1112 15:24:28.543977 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24256107,\n",
            " 'Loss/localization_loss': 0.0067402213,\n",
            " 'Loss/regularization_loss': 0.07866768,\n",
            " 'Loss/total_loss': 0.32796898,\n",
            " 'learning_rate': 0.7078781}\n",
            "INFO:tensorflow:Step 11900 per-step time 0.428s\n",
            "I1112 15:25:11.379370 139621605971840 model_lib_v2.py:707] Step 11900 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23394069,\n",
            " 'Loss/localization_loss': 0.0049727503,\n",
            " 'Loss/regularization_loss': 0.078946315,\n",
            " 'Loss/total_loss': 0.31785977,\n",
            " 'learning_rate': 0.7062346}\n",
            "I1112 15:25:11.379689 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23394069,\n",
            " 'Loss/localization_loss': 0.0049727503,\n",
            " 'Loss/regularization_loss': 0.078946315,\n",
            " 'Loss/total_loss': 0.31785977,\n",
            " 'learning_rate': 0.7062346}\n",
            "INFO:tensorflow:Step 12000 per-step time 0.431s\n",
            "I1112 15:25:54.512639 139621605971840 model_lib_v2.py:707] Step 12000 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20091948,\n",
            " 'Loss/localization_loss': 0.0040498516,\n",
            " 'Loss/regularization_loss': 0.078954,\n",
            " 'Loss/total_loss': 0.28392333,\n",
            " 'learning_rate': 0.7045784}\n",
            "I1112 15:25:54.512987 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20091948,\n",
            " 'Loss/localization_loss': 0.0040498516,\n",
            " 'Loss/regularization_loss': 0.078954,\n",
            " 'Loss/total_loss': 0.28392333,\n",
            " 'learning_rate': 0.7045784}\n",
            "INFO:tensorflow:Step 12100 per-step time 0.453s\n",
            "I1112 15:26:39.857079 139621605971840 model_lib_v2.py:707] Step 12100 per-step time 0.453s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2778072,\n",
            " 'Loss/localization_loss': 0.0043562837,\n",
            " 'Loss/regularization_loss': 0.07861289,\n",
            " 'Loss/total_loss': 0.3607764,\n",
            " 'learning_rate': 0.7029097}\n",
            "I1112 15:26:39.857442 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2778072,\n",
            " 'Loss/localization_loss': 0.0043562837,\n",
            " 'Loss/regularization_loss': 0.07861289,\n",
            " 'Loss/total_loss': 0.3607764,\n",
            " 'learning_rate': 0.7029097}\n",
            "INFO:tensorflow:Step 12200 per-step time 0.426s\n",
            "I1112 15:27:22.501851 139621605971840 model_lib_v2.py:707] Step 12200 per-step time 0.426s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18998541,\n",
            " 'Loss/localization_loss': 0.003330141,\n",
            " 'Loss/regularization_loss': 0.07846378,\n",
            " 'Loss/total_loss': 0.27177933,\n",
            " 'learning_rate': 0.70122856}\n",
            "I1112 15:27:22.502208 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18998541,\n",
            " 'Loss/localization_loss': 0.003330141,\n",
            " 'Loss/regularization_loss': 0.07846378,\n",
            " 'Loss/total_loss': 0.27177933,\n",
            " 'learning_rate': 0.70122856}\n",
            "INFO:tensorflow:Step 12300 per-step time 0.430s\n",
            "I1112 15:28:05.537639 139621605971840 model_lib_v2.py:707] Step 12300 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16654636,\n",
            " 'Loss/localization_loss': 0.002525301,\n",
            " 'Loss/regularization_loss': 0.078304596,\n",
            " 'Loss/total_loss': 0.24737626,\n",
            " 'learning_rate': 0.6995351}\n",
            "I1112 15:28:05.537954 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16654636,\n",
            " 'Loss/localization_loss': 0.002525301,\n",
            " 'Loss/regularization_loss': 0.078304596,\n",
            " 'Loss/total_loss': 0.24737626,\n",
            " 'learning_rate': 0.6995351}\n",
            "INFO:tensorflow:Step 12400 per-step time 0.429s\n",
            "I1112 15:28:48.443167 139621605971840 model_lib_v2.py:707] Step 12400 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17244086,\n",
            " 'Loss/localization_loss': 0.0023693177,\n",
            " 'Loss/regularization_loss': 0.07852137,\n",
            " 'Loss/total_loss': 0.25333154,\n",
            " 'learning_rate': 0.69782925}\n",
            "I1112 15:28:48.443496 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.17244086,\n",
            " 'Loss/localization_loss': 0.0023693177,\n",
            " 'Loss/regularization_loss': 0.07852137,\n",
            " 'Loss/total_loss': 0.25333154,\n",
            " 'learning_rate': 0.69782925}\n",
            "INFO:tensorflow:Step 12500 per-step time 0.429s\n",
            "I1112 15:29:31.346451 139621605971840 model_lib_v2.py:707] Step 12500 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26900974,\n",
            " 'Loss/localization_loss': 0.005877742,\n",
            " 'Loss/regularization_loss': 0.07825694,\n",
            " 'Loss/total_loss': 0.3531444,\n",
            " 'learning_rate': 0.6961112}\n",
            "I1112 15:29:31.346780 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.26900974,\n",
            " 'Loss/localization_loss': 0.005877742,\n",
            " 'Loss/regularization_loss': 0.07825694,\n",
            " 'Loss/total_loss': 0.3531444,\n",
            " 'learning_rate': 0.6961112}\n",
            "INFO:tensorflow:Step 12600 per-step time 0.429s\n",
            "I1112 15:30:14.266224 139621605971840 model_lib_v2.py:707] Step 12600 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18231541,\n",
            " 'Loss/localization_loss': 0.0023677712,\n",
            " 'Loss/regularization_loss': 0.078511685,\n",
            " 'Loss/total_loss': 0.26319486,\n",
            " 'learning_rate': 0.69438094}\n",
            "I1112 15:30:14.266537 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18231541,\n",
            " 'Loss/localization_loss': 0.0023677712,\n",
            " 'Loss/regularization_loss': 0.078511685,\n",
            " 'Loss/total_loss': 0.26319486,\n",
            " 'learning_rate': 0.69438094}\n",
            "INFO:tensorflow:Step 12700 per-step time 0.431s\n",
            "I1112 15:30:57.315316 139621605971840 model_lib_v2.py:707] Step 12700 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.28192264,\n",
            " 'Loss/localization_loss': 0.0050120912,\n",
            " 'Loss/regularization_loss': 0.07849211,\n",
            " 'Loss/total_loss': 0.36542684,\n",
            " 'learning_rate': 0.69263864}\n",
            "I1112 15:30:57.315622 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.28192264,\n",
            " 'Loss/localization_loss': 0.0050120912,\n",
            " 'Loss/regularization_loss': 0.07849211,\n",
            " 'Loss/total_loss': 0.36542684,\n",
            " 'learning_rate': 0.69263864}\n",
            "INFO:tensorflow:Step 12800 per-step time 0.431s\n",
            "I1112 15:31:40.409306 139621605971840 model_lib_v2.py:707] Step 12800 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18621749,\n",
            " 'Loss/localization_loss': 0.0021083045,\n",
            " 'Loss/regularization_loss': 0.07859131,\n",
            " 'Loss/total_loss': 0.2669171,\n",
            " 'learning_rate': 0.6908843}\n",
            "I1112 15:31:40.409624 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18621749,\n",
            " 'Loss/localization_loss': 0.0021083045,\n",
            " 'Loss/regularization_loss': 0.07859131,\n",
            " 'Loss/total_loss': 0.2669171,\n",
            " 'learning_rate': 0.6908843}\n",
            "INFO:tensorflow:Step 12900 per-step time 0.429s\n",
            "I1112 15:32:23.305071 139621605971840 model_lib_v2.py:707] Step 12900 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19881818,\n",
            " 'Loss/localization_loss': 0.0056214985,\n",
            " 'Loss/regularization_loss': 0.07877428,\n",
            " 'Loss/total_loss': 0.28321394,\n",
            " 'learning_rate': 0.68911797}\n",
            "I1112 15:32:23.305401 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19881818,\n",
            " 'Loss/localization_loss': 0.0056214985,\n",
            " 'Loss/regularization_loss': 0.07877428,\n",
            " 'Loss/total_loss': 0.28321394,\n",
            " 'learning_rate': 0.68911797}\n",
            "INFO:tensorflow:Step 13000 per-step time 0.430s\n",
            "I1112 15:33:06.291868 139621605971840 model_lib_v2.py:707] Step 13000 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21974902,\n",
            " 'Loss/localization_loss': 0.0034730867,\n",
            " 'Loss/regularization_loss': 0.07883745,\n",
            " 'Loss/total_loss': 0.30205956,\n",
            " 'learning_rate': 0.6873397}\n",
            "I1112 15:33:06.292233 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.21974902,\n",
            " 'Loss/localization_loss': 0.0034730867,\n",
            " 'Loss/regularization_loss': 0.07883745,\n",
            " 'Loss/total_loss': 0.30205956,\n",
            " 'learning_rate': 0.6873397}\n",
            "INFO:tensorflow:Step 13100 per-step time 0.453s\n",
            "I1112 15:33:51.609331 139621605971840 model_lib_v2.py:707] Step 13100 per-step time 0.453s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21189488,\n",
            " 'Loss/localization_loss': 0.004177897,\n",
            " 'Loss/regularization_loss': 0.07906469,\n",
            " 'Loss/total_loss': 0.29513747,\n",
            " 'learning_rate': 0.68554974}\n",
            "I1112 15:33:51.609683 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.21189488,\n",
            " 'Loss/localization_loss': 0.004177897,\n",
            " 'Loss/regularization_loss': 0.07906469,\n",
            " 'Loss/total_loss': 0.29513747,\n",
            " 'learning_rate': 0.68554974}\n",
            "INFO:tensorflow:Step 13200 per-step time 0.431s\n",
            "I1112 15:34:34.699198 139621605971840 model_lib_v2.py:707] Step 13200 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13952278,\n",
            " 'Loss/localization_loss': 0.0015549815,\n",
            " 'Loss/regularization_loss': 0.07882642,\n",
            " 'Loss/total_loss': 0.21990418,\n",
            " 'learning_rate': 0.68374795}\n",
            "I1112 15:34:34.699522 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13952278,\n",
            " 'Loss/localization_loss': 0.0015549815,\n",
            " 'Loss/regularization_loss': 0.07882642,\n",
            " 'Loss/total_loss': 0.21990418,\n",
            " 'learning_rate': 0.68374795}\n",
            "INFO:tensorflow:Step 13300 per-step time 0.429s\n",
            "I1112 15:35:17.550445 139621605971840 model_lib_v2.py:707] Step 13300 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25024423,\n",
            " 'Loss/localization_loss': 0.0036994284,\n",
            " 'Loss/regularization_loss': 0.07889873,\n",
            " 'Loss/total_loss': 0.33284238,\n",
            " 'learning_rate': 0.68193454}\n",
            "I1112 15:35:17.550773 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.25024423,\n",
            " 'Loss/localization_loss': 0.0036994284,\n",
            " 'Loss/regularization_loss': 0.07889873,\n",
            " 'Loss/total_loss': 0.33284238,\n",
            " 'learning_rate': 0.68193454}\n",
            "INFO:tensorflow:Step 13400 per-step time 0.430s\n",
            "I1112 15:36:00.557443 139621605971840 model_lib_v2.py:707] Step 13400 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.37672302,\n",
            " 'Loss/localization_loss': 0.004793484,\n",
            " 'Loss/regularization_loss': 0.07908376,\n",
            " 'Loss/total_loss': 0.4606003,\n",
            " 'learning_rate': 0.6801095}\n",
            "I1112 15:36:00.557769 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.37672302,\n",
            " 'Loss/localization_loss': 0.004793484,\n",
            " 'Loss/regularization_loss': 0.07908376,\n",
            " 'Loss/total_loss': 0.4606003,\n",
            " 'learning_rate': 0.6801095}\n",
            "INFO:tensorflow:Step 13500 per-step time 0.432s\n",
            "I1112 15:36:43.798932 139621605971840 model_lib_v2.py:707] Step 13500 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19961625,\n",
            " 'Loss/localization_loss': 0.00259875,\n",
            " 'Loss/regularization_loss': 0.079404466,\n",
            " 'Loss/total_loss': 0.28161946,\n",
            " 'learning_rate': 0.678273}\n",
            "I1112 15:36:43.799270 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19961625,\n",
            " 'Loss/localization_loss': 0.00259875,\n",
            " 'Loss/regularization_loss': 0.079404466,\n",
            " 'Loss/total_loss': 0.28161946,\n",
            " 'learning_rate': 0.678273}\n",
            "INFO:tensorflow:Step 13600 per-step time 0.431s\n",
            "I1112 15:37:26.912070 139621605971840 model_lib_v2.py:707] Step 13600 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2153296,\n",
            " 'Loss/localization_loss': 0.0053069075,\n",
            " 'Loss/regularization_loss': 0.07978667,\n",
            " 'Loss/total_loss': 0.3004232,\n",
            " 'learning_rate': 0.6764251}\n",
            "I1112 15:37:26.912404 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2153296,\n",
            " 'Loss/localization_loss': 0.0053069075,\n",
            " 'Loss/regularization_loss': 0.07978667,\n",
            " 'Loss/total_loss': 0.3004232,\n",
            " 'learning_rate': 0.6764251}\n",
            "INFO:tensorflow:Step 13700 per-step time 0.430s\n",
            "I1112 15:38:09.902390 139621605971840 model_lib_v2.py:707] Step 13700 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21960358,\n",
            " 'Loss/localization_loss': 0.002634088,\n",
            " 'Loss/regularization_loss': 0.079593465,\n",
            " 'Loss/total_loss': 0.30183113,\n",
            " 'learning_rate': 0.67456573}\n",
            "I1112 15:38:09.902711 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.21960358,\n",
            " 'Loss/localization_loss': 0.002634088,\n",
            " 'Loss/regularization_loss': 0.079593465,\n",
            " 'Loss/total_loss': 0.30183113,\n",
            " 'learning_rate': 0.67456573}\n",
            "INFO:tensorflow:Step 13800 per-step time 0.431s\n",
            "I1112 15:38:53.029857 139621605971840 model_lib_v2.py:707] Step 13800 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1486944,\n",
            " 'Loss/localization_loss': 0.002100345,\n",
            " 'Loss/regularization_loss': 0.0795838,\n",
            " 'Loss/total_loss': 0.23037854,\n",
            " 'learning_rate': 0.67269516}\n",
            "I1112 15:38:53.030193 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1486944,\n",
            " 'Loss/localization_loss': 0.002100345,\n",
            " 'Loss/regularization_loss': 0.0795838,\n",
            " 'Loss/total_loss': 0.23037854,\n",
            " 'learning_rate': 0.67269516}\n",
            "INFO:tensorflow:Step 13900 per-step time 0.430s\n",
            "I1112 15:39:36.043999 139621605971840 model_lib_v2.py:707] Step 13900 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18478188,\n",
            " 'Loss/localization_loss': 0.0030558526,\n",
            " 'Loss/regularization_loss': 0.07966834,\n",
            " 'Loss/total_loss': 0.26750606,\n",
            " 'learning_rate': 0.67081326}\n",
            "I1112 15:39:36.044343 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18478188,\n",
            " 'Loss/localization_loss': 0.0030558526,\n",
            " 'Loss/regularization_loss': 0.07966834,\n",
            " 'Loss/total_loss': 0.26750606,\n",
            " 'learning_rate': 0.67081326}\n",
            "INFO:tensorflow:Step 14000 per-step time 0.431s\n",
            "I1112 15:40:19.127422 139621605971840 model_lib_v2.py:707] Step 14000 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26382664,\n",
            " 'Loss/localization_loss': 0.004200845,\n",
            " 'Loss/regularization_loss': 0.07991554,\n",
            " 'Loss/total_loss': 0.347943,\n",
            " 'learning_rate': 0.66892034}\n",
            "I1112 15:40:19.127757 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.26382664,\n",
            " 'Loss/localization_loss': 0.004200845,\n",
            " 'Loss/regularization_loss': 0.07991554,\n",
            " 'Loss/total_loss': 0.347943,\n",
            " 'learning_rate': 0.66892034}\n",
            "INFO:tensorflow:Step 14100 per-step time 0.454s\n",
            "I1112 15:41:04.553072 139621605971840 model_lib_v2.py:707] Step 14100 per-step time 0.454s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20077568,\n",
            " 'Loss/localization_loss': 0.0041210465,\n",
            " 'Loss/regularization_loss': 0.07988843,\n",
            " 'Loss/total_loss': 0.28478515,\n",
            " 'learning_rate': 0.6670163}\n",
            "I1112 15:41:04.553438 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20077568,\n",
            " 'Loss/localization_loss': 0.0041210465,\n",
            " 'Loss/regularization_loss': 0.07988843,\n",
            " 'Loss/total_loss': 0.28478515,\n",
            " 'learning_rate': 0.6670163}\n",
            "INFO:tensorflow:Step 14200 per-step time 0.432s\n",
            "I1112 15:41:47.740331 139621605971840 model_lib_v2.py:707] Step 14200 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16500585,\n",
            " 'Loss/localization_loss': 0.002444888,\n",
            " 'Loss/regularization_loss': 0.079730615,\n",
            " 'Loss/total_loss': 0.24718136,\n",
            " 'learning_rate': 0.66510135}\n",
            "I1112 15:41:47.740653 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16500585,\n",
            " 'Loss/localization_loss': 0.002444888,\n",
            " 'Loss/regularization_loss': 0.079730615,\n",
            " 'Loss/total_loss': 0.24718136,\n",
            " 'learning_rate': 0.66510135}\n",
            "INFO:tensorflow:Step 14300 per-step time 0.430s\n",
            "I1112 15:42:30.776107 139621605971840 model_lib_v2.py:707] Step 14300 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20713668,\n",
            " 'Loss/localization_loss': 0.0037872312,\n",
            " 'Loss/regularization_loss': 0.07966829,\n",
            " 'Loss/total_loss': 0.2905922,\n",
            " 'learning_rate': 0.6631755}\n",
            "I1112 15:42:30.776530 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20713668,\n",
            " 'Loss/localization_loss': 0.0037872312,\n",
            " 'Loss/regularization_loss': 0.07966829,\n",
            " 'Loss/total_loss': 0.2905922,\n",
            " 'learning_rate': 0.6631755}\n",
            "INFO:tensorflow:Step 14400 per-step time 0.429s\n",
            "I1112 15:43:13.658993 139621605971840 model_lib_v2.py:707] Step 14400 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1785231,\n",
            " 'Loss/localization_loss': 0.0035752552,\n",
            " 'Loss/regularization_loss': 0.0797018,\n",
            " 'Loss/total_loss': 0.26180014,\n",
            " 'learning_rate': 0.6612388}\n",
            "I1112 15:43:13.659341 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1785231,\n",
            " 'Loss/localization_loss': 0.0035752552,\n",
            " 'Loss/regularization_loss': 0.0797018,\n",
            " 'Loss/total_loss': 0.26180014,\n",
            " 'learning_rate': 0.6612388}\n",
            "INFO:tensorflow:Step 14500 per-step time 0.433s\n",
            "I1112 15:43:56.931733 139621605971840 model_lib_v2.py:707] Step 14500 per-step time 0.433s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12490614,\n",
            " 'Loss/localization_loss': 0.0022033222,\n",
            " 'Loss/regularization_loss': 0.07962004,\n",
            " 'Loss/total_loss': 0.2067295,\n",
            " 'learning_rate': 0.6592914}\n",
            "I1112 15:43:56.932051 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12490614,\n",
            " 'Loss/localization_loss': 0.0022033222,\n",
            " 'Loss/regularization_loss': 0.07962004,\n",
            " 'Loss/total_loss': 0.2067295,\n",
            " 'learning_rate': 0.6592914}\n",
            "INFO:tensorflow:Step 14600 per-step time 0.431s\n",
            "I1112 15:44:40.002957 139621605971840 model_lib_v2.py:707] Step 14600 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12795097,\n",
            " 'Loss/localization_loss': 0.0018117956,\n",
            " 'Loss/regularization_loss': 0.07952243,\n",
            " 'Loss/total_loss': 0.2092852,\n",
            " 'learning_rate': 0.6573333}\n",
            "I1112 15:44:40.003286 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12795097,\n",
            " 'Loss/localization_loss': 0.0018117956,\n",
            " 'Loss/regularization_loss': 0.07952243,\n",
            " 'Loss/total_loss': 0.2092852,\n",
            " 'learning_rate': 0.6573333}\n",
            "INFO:tensorflow:Step 14700 per-step time 0.431s\n",
            "I1112 15:45:23.081275 139621605971840 model_lib_v2.py:707] Step 14700 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24831165,\n",
            " 'Loss/localization_loss': 0.0054798513,\n",
            " 'Loss/regularization_loss': 0.07924515,\n",
            " 'Loss/total_loss': 0.33303666,\n",
            " 'learning_rate': 0.65536463}\n",
            "I1112 15:45:23.081605 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24831165,\n",
            " 'Loss/localization_loss': 0.0054798513,\n",
            " 'Loss/regularization_loss': 0.07924515,\n",
            " 'Loss/total_loss': 0.33303666,\n",
            " 'learning_rate': 0.65536463}\n",
            "INFO:tensorflow:Step 14800 per-step time 0.432s\n",
            "I1112 15:46:06.259387 139621605971840 model_lib_v2.py:707] Step 14800 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26065302,\n",
            " 'Loss/localization_loss': 0.004202294,\n",
            " 'Loss/regularization_loss': 0.079251416,\n",
            " 'Loss/total_loss': 0.34410673,\n",
            " 'learning_rate': 0.65338546}\n",
            "I1112 15:46:06.259743 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.26065302,\n",
            " 'Loss/localization_loss': 0.004202294,\n",
            " 'Loss/regularization_loss': 0.079251416,\n",
            " 'Loss/total_loss': 0.34410673,\n",
            " 'learning_rate': 0.65338546}\n",
            "INFO:tensorflow:Step 14900 per-step time 0.430s\n",
            "I1112 15:46:49.283448 139621605971840 model_lib_v2.py:707] Step 14900 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24497914,\n",
            " 'Loss/localization_loss': 0.0037174872,\n",
            " 'Loss/regularization_loss': 0.079527564,\n",
            " 'Loss/total_loss': 0.32822418,\n",
            " 'learning_rate': 0.6513958}\n",
            "I1112 15:46:49.283810 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24497914,\n",
            " 'Loss/localization_loss': 0.0037174872,\n",
            " 'Loss/regularization_loss': 0.079527564,\n",
            " 'Loss/total_loss': 0.32822418,\n",
            " 'learning_rate': 0.6513958}\n",
            "INFO:tensorflow:Step 15000 per-step time 0.431s\n",
            "I1112 15:47:32.349223 139621605971840 model_lib_v2.py:707] Step 15000 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20899302,\n",
            " 'Loss/localization_loss': 0.0032184904,\n",
            " 'Loss/regularization_loss': 0.079547554,\n",
            " 'Loss/total_loss': 0.29175907,\n",
            " 'learning_rate': 0.64939594}\n",
            "I1112 15:47:32.349544 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20899302,\n",
            " 'Loss/localization_loss': 0.0032184904,\n",
            " 'Loss/regularization_loss': 0.079547554,\n",
            " 'Loss/total_loss': 0.29175907,\n",
            " 'learning_rate': 0.64939594}\n",
            "INFO:tensorflow:Step 15100 per-step time 0.453s\n",
            "I1112 15:48:17.646356 139621605971840 model_lib_v2.py:707] Step 15100 per-step time 0.453s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18994366,\n",
            " 'Loss/localization_loss': 0.00414437,\n",
            " 'Loss/regularization_loss': 0.07969098,\n",
            " 'Loss/total_loss': 0.273779,\n",
            " 'learning_rate': 0.6473858}\n",
            "I1112 15:48:17.646685 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18994366,\n",
            " 'Loss/localization_loss': 0.00414437,\n",
            " 'Loss/regularization_loss': 0.07969098,\n",
            " 'Loss/total_loss': 0.273779,\n",
            " 'learning_rate': 0.6473858}\n",
            "INFO:tensorflow:Step 15200 per-step time 0.430s\n",
            "I1112 15:49:00.646102 139621605971840 model_lib_v2.py:707] Step 15200 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14164032,\n",
            " 'Loss/localization_loss': 0.0022423922,\n",
            " 'Loss/regularization_loss': 0.079567686,\n",
            " 'Loss/total_loss': 0.22345039,\n",
            " 'learning_rate': 0.6453654}\n",
            "I1112 15:49:00.646451 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.14164032,\n",
            " 'Loss/localization_loss': 0.0022423922,\n",
            " 'Loss/regularization_loss': 0.079567686,\n",
            " 'Loss/total_loss': 0.22345039,\n",
            " 'learning_rate': 0.6453654}\n",
            "INFO:tensorflow:Step 15300 per-step time 0.429s\n",
            "I1112 15:49:43.518194 139621605971840 model_lib_v2.py:707] Step 15300 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20060882,\n",
            " 'Loss/localization_loss': 0.0035351724,\n",
            " 'Loss/regularization_loss': 0.080114126,\n",
            " 'Loss/total_loss': 0.28425813,\n",
            " 'learning_rate': 0.643335}\n",
            "I1112 15:49:43.518559 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.20060882,\n",
            " 'Loss/localization_loss': 0.0035351724,\n",
            " 'Loss/regularization_loss': 0.080114126,\n",
            " 'Loss/total_loss': 0.28425813,\n",
            " 'learning_rate': 0.643335}\n",
            "INFO:tensorflow:Step 15400 per-step time 0.429s\n",
            "I1112 15:50:26.435934 139621605971840 model_lib_v2.py:707] Step 15400 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14812993,\n",
            " 'Loss/localization_loss': 0.0016521505,\n",
            " 'Loss/regularization_loss': 0.08046805,\n",
            " 'Loss/total_loss': 0.23025012,\n",
            " 'learning_rate': 0.6412946}\n",
            "I1112 15:50:26.436271 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.14812993,\n",
            " 'Loss/localization_loss': 0.0016521505,\n",
            " 'Loss/regularization_loss': 0.08046805,\n",
            " 'Loss/total_loss': 0.23025012,\n",
            " 'learning_rate': 0.6412946}\n",
            "INFO:tensorflow:Step 15500 per-step time 0.427s\n",
            "I1112 15:51:09.181127 139621605971840 model_lib_v2.py:707] Step 15500 per-step time 0.427s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19719696,\n",
            " 'Loss/localization_loss': 0.0026926047,\n",
            " 'Loss/regularization_loss': 0.080061935,\n",
            " 'Loss/total_loss': 0.2799515,\n",
            " 'learning_rate': 0.63924426}\n",
            "I1112 15:51:09.181469 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19719696,\n",
            " 'Loss/localization_loss': 0.0026926047,\n",
            " 'Loss/regularization_loss': 0.080061935,\n",
            " 'Loss/total_loss': 0.2799515,\n",
            " 'learning_rate': 0.63924426}\n",
            "INFO:tensorflow:Step 15600 per-step time 0.430s\n",
            "I1112 15:51:52.221608 139621605971840 model_lib_v2.py:707] Step 15600 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21571538,\n",
            " 'Loss/localization_loss': 0.0053558876,\n",
            " 'Loss/regularization_loss': 0.080307566,\n",
            " 'Loss/total_loss': 0.30137885,\n",
            " 'learning_rate': 0.6371841}\n",
            "I1112 15:51:52.221923 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.21571538,\n",
            " 'Loss/localization_loss': 0.0053558876,\n",
            " 'Loss/regularization_loss': 0.080307566,\n",
            " 'Loss/total_loss': 0.30137885,\n",
            " 'learning_rate': 0.6371841}\n",
            "INFO:tensorflow:Step 15700 per-step time 0.430s\n",
            "I1112 15:52:35.265564 139621605971840 model_lib_v2.py:707] Step 15700 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18064159,\n",
            " 'Loss/localization_loss': 0.0034418486,\n",
            " 'Loss/regularization_loss': 0.08015387,\n",
            " 'Loss/total_loss': 0.2642373,\n",
            " 'learning_rate': 0.63511413}\n",
            "I1112 15:52:35.265890 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18064159,\n",
            " 'Loss/localization_loss': 0.0034418486,\n",
            " 'Loss/regularization_loss': 0.08015387,\n",
            " 'Loss/total_loss': 0.2642373,\n",
            " 'learning_rate': 0.63511413}\n",
            "INFO:tensorflow:Step 15800 per-step time 0.431s\n",
            "I1112 15:53:18.359663 139621605971840 model_lib_v2.py:707] Step 15800 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16714379,\n",
            " 'Loss/localization_loss': 0.0028126289,\n",
            " 'Loss/regularization_loss': 0.08009682,\n",
            " 'Loss/total_loss': 0.25005323,\n",
            " 'learning_rate': 0.6330345}\n",
            "I1112 15:53:18.359994 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16714379,\n",
            " 'Loss/localization_loss': 0.0028126289,\n",
            " 'Loss/regularization_loss': 0.08009682,\n",
            " 'Loss/total_loss': 0.25005323,\n",
            " 'learning_rate': 0.6330345}\n",
            "INFO:tensorflow:Step 15900 per-step time 0.436s\n",
            "I1112 15:54:01.971312 139621605971840 model_lib_v2.py:707] Step 15900 per-step time 0.436s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19684237,\n",
            " 'Loss/localization_loss': 0.0033536847,\n",
            " 'Loss/regularization_loss': 0.08086254,\n",
            " 'Loss/total_loss': 0.2810586,\n",
            " 'learning_rate': 0.6309453}\n",
            "I1112 15:54:01.971630 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19684237,\n",
            " 'Loss/localization_loss': 0.0033536847,\n",
            " 'Loss/regularization_loss': 0.08086254,\n",
            " 'Loss/total_loss': 0.2810586,\n",
            " 'learning_rate': 0.6309453}\n",
            "INFO:tensorflow:Step 16000 per-step time 0.431s\n",
            "I1112 15:54:45.095408 139621605971840 model_lib_v2.py:707] Step 16000 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16844583,\n",
            " 'Loss/localization_loss': 0.0031878871,\n",
            " 'Loss/regularization_loss': 0.08088915,\n",
            " 'Loss/total_loss': 0.25252286,\n",
            " 'learning_rate': 0.62884665}\n",
            "I1112 15:54:45.095734 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16844583,\n",
            " 'Loss/localization_loss': 0.0031878871,\n",
            " 'Loss/regularization_loss': 0.08088915,\n",
            " 'Loss/total_loss': 0.25252286,\n",
            " 'learning_rate': 0.62884665}\n",
            "INFO:tensorflow:Step 16100 per-step time 0.452s\n",
            "I1112 15:55:30.341918 139621605971840 model_lib_v2.py:707] Step 16100 per-step time 0.452s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18821725,\n",
            " 'Loss/localization_loss': 0.0042244396,\n",
            " 'Loss/regularization_loss': 0.080754265,\n",
            " 'Loss/total_loss': 0.27319595,\n",
            " 'learning_rate': 0.62673855}\n",
            "I1112 15:55:30.342276 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18821725,\n",
            " 'Loss/localization_loss': 0.0042244396,\n",
            " 'Loss/regularization_loss': 0.080754265,\n",
            " 'Loss/total_loss': 0.27319595,\n",
            " 'learning_rate': 0.62673855}\n",
            "INFO:tensorflow:Step 16200 per-step time 0.431s\n",
            "I1112 15:56:13.407103 139621605971840 model_lib_v2.py:707] Step 16200 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18174022,\n",
            " 'Loss/localization_loss': 0.0039719497,\n",
            " 'Loss/regularization_loss': 0.08097065,\n",
            " 'Loss/total_loss': 0.26668283,\n",
            " 'learning_rate': 0.6246212}\n",
            "I1112 15:56:13.407437 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18174022,\n",
            " 'Loss/localization_loss': 0.0039719497,\n",
            " 'Loss/regularization_loss': 0.08097065,\n",
            " 'Loss/total_loss': 0.26668283,\n",
            " 'learning_rate': 0.6246212}\n",
            "INFO:tensorflow:Step 16300 per-step time 0.432s\n",
            "I1112 15:56:56.564399 139621605971840 model_lib_v2.py:707] Step 16300 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21258612,\n",
            " 'Loss/localization_loss': 0.0029750683,\n",
            " 'Loss/regularization_loss': 0.08066023,\n",
            " 'Loss/total_loss': 0.2962214,\n",
            " 'learning_rate': 0.62249464}\n",
            "I1112 15:56:56.564726 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.21258612,\n",
            " 'Loss/localization_loss': 0.0029750683,\n",
            " 'Loss/regularization_loss': 0.08066023,\n",
            " 'Loss/total_loss': 0.2962214,\n",
            " 'learning_rate': 0.62249464}\n",
            "INFO:tensorflow:Step 16400 per-step time 0.432s\n",
            "I1112 15:57:39.748916 139621605971840 model_lib_v2.py:707] Step 16400 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11210419,\n",
            " 'Loss/localization_loss': 0.0021007038,\n",
            " 'Loss/regularization_loss': 0.080225736,\n",
            " 'Loss/total_loss': 0.19443063,\n",
            " 'learning_rate': 0.6203588}\n",
            "I1112 15:57:39.749256 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.11210419,\n",
            " 'Loss/localization_loss': 0.0021007038,\n",
            " 'Loss/regularization_loss': 0.080225736,\n",
            " 'Loss/total_loss': 0.19443063,\n",
            " 'learning_rate': 0.6203588}\n",
            "INFO:tensorflow:Step 16500 per-step time 0.430s\n",
            "I1112 15:58:22.744908 139621605971840 model_lib_v2.py:707] Step 16500 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22959846,\n",
            " 'Loss/localization_loss': 0.003720929,\n",
            " 'Loss/regularization_loss': 0.0799535,\n",
            " 'Loss/total_loss': 0.3132729,\n",
            " 'learning_rate': 0.61821395}\n",
            "I1112 15:58:22.745260 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.22959846,\n",
            " 'Loss/localization_loss': 0.003720929,\n",
            " 'Loss/regularization_loss': 0.0799535,\n",
            " 'Loss/total_loss': 0.3132729,\n",
            " 'learning_rate': 0.61821395}\n",
            "INFO:tensorflow:Step 16600 per-step time 0.429s\n",
            "I1112 15:59:05.692759 139621605971840 model_lib_v2.py:707] Step 16600 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19973283,\n",
            " 'Loss/localization_loss': 0.005176083,\n",
            " 'Loss/regularization_loss': 0.080417365,\n",
            " 'Loss/total_loss': 0.28532627,\n",
            " 'learning_rate': 0.6160602}\n",
            "I1112 15:59:05.693085 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19973283,\n",
            " 'Loss/localization_loss': 0.005176083,\n",
            " 'Loss/regularization_loss': 0.080417365,\n",
            " 'Loss/total_loss': 0.28532627,\n",
            " 'learning_rate': 0.6160602}\n",
            "INFO:tensorflow:Step 16700 per-step time 0.432s\n",
            "I1112 15:59:48.856004 139621605971840 model_lib_v2.py:707] Step 16700 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18677789,\n",
            " 'Loss/localization_loss': 0.0032720817,\n",
            " 'Loss/regularization_loss': 0.0802132,\n",
            " 'Loss/total_loss': 0.27026317,\n",
            " 'learning_rate': 0.61389744}\n",
            "I1112 15:59:48.856342 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18677789,\n",
            " 'Loss/localization_loss': 0.0032720817,\n",
            " 'Loss/regularization_loss': 0.0802132,\n",
            " 'Loss/total_loss': 0.27026317,\n",
            " 'learning_rate': 0.61389744}\n",
            "INFO:tensorflow:Step 16800 per-step time 0.428s\n",
            "I1112 16:00:31.641418 139621605971840 model_lib_v2.py:707] Step 16800 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14707354,\n",
            " 'Loss/localization_loss': 0.0020213947,\n",
            " 'Loss/regularization_loss': 0.0803026,\n",
            " 'Loss/total_loss': 0.22939754,\n",
            " 'learning_rate': 0.611726}\n",
            "I1112 16:00:31.641741 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.14707354,\n",
            " 'Loss/localization_loss': 0.0020213947,\n",
            " 'Loss/regularization_loss': 0.0803026,\n",
            " 'Loss/total_loss': 0.22939754,\n",
            " 'learning_rate': 0.611726}\n",
            "INFO:tensorflow:Step 16900 per-step time 0.431s\n",
            "I1112 16:01:14.710611 139621605971840 model_lib_v2.py:707] Step 16900 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2076958,\n",
            " 'Loss/localization_loss': 0.004305257,\n",
            " 'Loss/regularization_loss': 0.080342054,\n",
            " 'Loss/total_loss': 0.2923431,\n",
            " 'learning_rate': 0.6095458}\n",
            "I1112 16:01:14.710950 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2076958,\n",
            " 'Loss/localization_loss': 0.004305257,\n",
            " 'Loss/regularization_loss': 0.080342054,\n",
            " 'Loss/total_loss': 0.2923431,\n",
            " 'learning_rate': 0.6095458}\n",
            "INFO:tensorflow:Step 17000 per-step time 0.432s\n",
            "I1112 16:01:57.906833 139621605971840 model_lib_v2.py:707] Step 17000 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19911557,\n",
            " 'Loss/localization_loss': 0.0027182624,\n",
            " 'Loss/regularization_loss': 0.08033895,\n",
            " 'Loss/total_loss': 0.2821728,\n",
            " 'learning_rate': 0.607357}\n",
            "I1112 16:01:57.907161 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.19911557,\n",
            " 'Loss/localization_loss': 0.0027182624,\n",
            " 'Loss/regularization_loss': 0.08033895,\n",
            " 'Loss/total_loss': 0.2821728,\n",
            " 'learning_rate': 0.607357}\n",
            "INFO:tensorflow:Step 17100 per-step time 0.456s\n",
            "I1112 16:02:43.506104 139621605971840 model_lib_v2.py:707] Step 17100 per-step time 0.456s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21577397,\n",
            " 'Loss/localization_loss': 0.0031902243,\n",
            " 'Loss/regularization_loss': 0.08019775,\n",
            " 'Loss/total_loss': 0.29916194,\n",
            " 'learning_rate': 0.6051597}\n",
            "I1112 16:02:43.506447 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.21577397,\n",
            " 'Loss/localization_loss': 0.0031902243,\n",
            " 'Loss/regularization_loss': 0.08019775,\n",
            " 'Loss/total_loss': 0.29916194,\n",
            " 'learning_rate': 0.6051597}\n",
            "INFO:tensorflow:Step 17200 per-step time 0.429s\n",
            "I1112 16:03:26.436564 139621605971840 model_lib_v2.py:707] Step 17200 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12926827,\n",
            " 'Loss/localization_loss': 0.0012206682,\n",
            " 'Loss/regularization_loss': 0.07974084,\n",
            " 'Loss/total_loss': 0.21022978,\n",
            " 'learning_rate': 0.602954}\n",
            "I1112 16:03:26.436888 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12926827,\n",
            " 'Loss/localization_loss': 0.0012206682,\n",
            " 'Loss/regularization_loss': 0.07974084,\n",
            " 'Loss/total_loss': 0.21022978,\n",
            " 'learning_rate': 0.602954}\n",
            "INFO:tensorflow:Step 17300 per-step time 0.432s\n",
            "I1112 16:04:09.622476 139621605971840 model_lib_v2.py:707] Step 17300 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13672698,\n",
            " 'Loss/localization_loss': 0.0014628725,\n",
            " 'Loss/regularization_loss': 0.08007194,\n",
            " 'Loss/total_loss': 0.2182618,\n",
            " 'learning_rate': 0.6007399}\n",
            "I1112 16:04:09.622830 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.13672698,\n",
            " 'Loss/localization_loss': 0.0014628725,\n",
            " 'Loss/regularization_loss': 0.08007194,\n",
            " 'Loss/total_loss': 0.2182618,\n",
            " 'learning_rate': 0.6007399}\n",
            "INFO:tensorflow:Step 17400 per-step time 0.430s\n",
            "I1112 16:04:52.632170 139621605971840 model_lib_v2.py:707] Step 17400 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18559968,\n",
            " 'Loss/localization_loss': 0.0030832812,\n",
            " 'Loss/regularization_loss': 0.080115855,\n",
            " 'Loss/total_loss': 0.26879883,\n",
            " 'learning_rate': 0.59851754}\n",
            "I1112 16:04:52.632518 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18559968,\n",
            " 'Loss/localization_loss': 0.0030832812,\n",
            " 'Loss/regularization_loss': 0.080115855,\n",
            " 'Loss/total_loss': 0.26879883,\n",
            " 'learning_rate': 0.59851754}\n",
            "INFO:tensorflow:Step 17500 per-step time 0.429s\n",
            "I1112 16:05:35.529882 139621605971840 model_lib_v2.py:707] Step 17500 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24401693,\n",
            " 'Loss/localization_loss': 0.0052059386,\n",
            " 'Loss/regularization_loss': 0.08007839,\n",
            " 'Loss/total_loss': 0.32930127,\n",
            " 'learning_rate': 0.596287}\n",
            "I1112 16:05:35.530227 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.24401693,\n",
            " 'Loss/localization_loss': 0.0052059386,\n",
            " 'Loss/regularization_loss': 0.08007839,\n",
            " 'Loss/total_loss': 0.32930127,\n",
            " 'learning_rate': 0.596287}\n",
            "INFO:tensorflow:Step 17600 per-step time 0.432s\n",
            "I1112 16:06:18.680202 139621605971840 model_lib_v2.py:707] Step 17600 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1906711,\n",
            " 'Loss/localization_loss': 0.002633385,\n",
            " 'Loss/regularization_loss': 0.08027217,\n",
            " 'Loss/total_loss': 0.27357665,\n",
            " 'learning_rate': 0.59404844}\n",
            "I1112 16:06:18.680533 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1906711,\n",
            " 'Loss/localization_loss': 0.002633385,\n",
            " 'Loss/regularization_loss': 0.08027217,\n",
            " 'Loss/total_loss': 0.27357665,\n",
            " 'learning_rate': 0.59404844}\n",
            "INFO:tensorflow:Step 17700 per-step time 0.430s\n",
            "I1112 16:07:01.702040 139621605971840 model_lib_v2.py:707] Step 17700 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16820665,\n",
            " 'Loss/localization_loss': 0.0028591384,\n",
            " 'Loss/regularization_loss': 0.08005691,\n",
            " 'Loss/total_loss': 0.2511227,\n",
            " 'learning_rate': 0.5918019}\n",
            "I1112 16:07:01.702398 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16820665,\n",
            " 'Loss/localization_loss': 0.0028591384,\n",
            " 'Loss/regularization_loss': 0.08005691,\n",
            " 'Loss/total_loss': 0.2511227,\n",
            " 'learning_rate': 0.5918019}\n",
            "INFO:tensorflow:Step 17800 per-step time 0.432s\n",
            "I1112 16:07:44.939781 139621605971840 model_lib_v2.py:707] Step 17800 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15440136,\n",
            " 'Loss/localization_loss': 0.0029899257,\n",
            " 'Loss/regularization_loss': 0.07988741,\n",
            " 'Loss/total_loss': 0.2372787,\n",
            " 'learning_rate': 0.58954746}\n",
            "I1112 16:07:44.940118 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.15440136,\n",
            " 'Loss/localization_loss': 0.0029899257,\n",
            " 'Loss/regularization_loss': 0.07988741,\n",
            " 'Loss/total_loss': 0.2372787,\n",
            " 'learning_rate': 0.58954746}\n",
            "INFO:tensorflow:Step 17900 per-step time 0.430s\n",
            "I1112 16:08:27.901666 139621605971840 model_lib_v2.py:707] Step 17900 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10993882,\n",
            " 'Loss/localization_loss': 0.001998639,\n",
            " 'Loss/regularization_loss': 0.08006825,\n",
            " 'Loss/total_loss': 0.19200572,\n",
            " 'learning_rate': 0.5872852}\n",
            "I1112 16:08:27.901993 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.10993882,\n",
            " 'Loss/localization_loss': 0.001998639,\n",
            " 'Loss/regularization_loss': 0.08006825,\n",
            " 'Loss/total_loss': 0.19200572,\n",
            " 'learning_rate': 0.5872852}\n",
            "INFO:tensorflow:Step 18000 per-step time 0.430s\n",
            "I1112 16:09:10.904176 139621605971840 model_lib_v2.py:707] Step 18000 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14881049,\n",
            " 'Loss/localization_loss': 0.0016285287,\n",
            " 'Loss/regularization_loss': 0.079816364,\n",
            " 'Loss/total_loss': 0.2302554,\n",
            " 'learning_rate': 0.5850153}\n",
            "I1112 16:09:10.904511 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.14881049,\n",
            " 'Loss/localization_loss': 0.0016285287,\n",
            " 'Loss/regularization_loss': 0.079816364,\n",
            " 'Loss/total_loss': 0.2302554,\n",
            " 'learning_rate': 0.5850153}\n",
            "INFO:tensorflow:Step 18100 per-step time 0.452s\n",
            "I1112 16:09:56.117078 139621605971840 model_lib_v2.py:707] Step 18100 per-step time 0.452s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15449096,\n",
            " 'Loss/localization_loss': 0.0018346584,\n",
            " 'Loss/regularization_loss': 0.07977492,\n",
            " 'Loss/total_loss': 0.23610055,\n",
            " 'learning_rate': 0.5827378}\n",
            "I1112 16:09:56.117435 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.15449096,\n",
            " 'Loss/localization_loss': 0.0018346584,\n",
            " 'Loss/regularization_loss': 0.07977492,\n",
            " 'Loss/total_loss': 0.23610055,\n",
            " 'learning_rate': 0.5827378}\n",
            "INFO:tensorflow:Step 18200 per-step time 0.430s\n",
            "I1112 16:10:39.120534 139621605971840 model_lib_v2.py:707] Step 18200 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2424216,\n",
            " 'Loss/localization_loss': 0.0032589813,\n",
            " 'Loss/regularization_loss': 0.08016129,\n",
            " 'Loss/total_loss': 0.32584187,\n",
            " 'learning_rate': 0.58045274}\n",
            "I1112 16:10:39.120864 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.2424216,\n",
            " 'Loss/localization_loss': 0.0032589813,\n",
            " 'Loss/regularization_loss': 0.08016129,\n",
            " 'Loss/total_loss': 0.32584187,\n",
            " 'learning_rate': 0.58045274}\n",
            "INFO:tensorflow:Step 18300 per-step time 0.427s\n",
            "I1112 16:11:21.805228 139621605971840 model_lib_v2.py:707] Step 18300 per-step time 0.427s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14949805,\n",
            " 'Loss/localization_loss': 0.0022617793,\n",
            " 'Loss/regularization_loss': 0.08018199,\n",
            " 'Loss/total_loss': 0.23194182,\n",
            " 'learning_rate': 0.5781603}\n",
            "I1112 16:11:21.805563 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.14949805,\n",
            " 'Loss/localization_loss': 0.0022617793,\n",
            " 'Loss/regularization_loss': 0.08018199,\n",
            " 'Loss/total_loss': 0.23194182,\n",
            " 'learning_rate': 0.5781603}\n",
            "INFO:tensorflow:Step 18400 per-step time 0.431s\n",
            "I1112 16:12:04.868093 139621605971840 model_lib_v2.py:707] Step 18400 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18266875,\n",
            " 'Loss/localization_loss': 0.0027586962,\n",
            " 'Loss/regularization_loss': 0.08016514,\n",
            " 'Loss/total_loss': 0.26559258,\n",
            " 'learning_rate': 0.5758605}\n",
            "I1112 16:12:04.868461 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.18266875,\n",
            " 'Loss/localization_loss': 0.0027586962,\n",
            " 'Loss/regularization_loss': 0.08016514,\n",
            " 'Loss/total_loss': 0.26559258,\n",
            " 'learning_rate': 0.5758605}\n",
            "INFO:tensorflow:Step 18500 per-step time 0.430s\n",
            "I1112 16:12:47.826777 139621605971840 model_lib_v2.py:707] Step 18500 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23713745,\n",
            " 'Loss/localization_loss': 0.0042942986,\n",
            " 'Loss/regularization_loss': 0.0806133,\n",
            " 'Loss/total_loss': 0.32204503,\n",
            " 'learning_rate': 0.5735535}\n",
            "I1112 16:12:47.827100 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.23713745,\n",
            " 'Loss/localization_loss': 0.0042942986,\n",
            " 'Loss/regularization_loss': 0.0806133,\n",
            " 'Loss/total_loss': 0.32204503,\n",
            " 'learning_rate': 0.5735535}\n",
            "INFO:tensorflow:Step 18600 per-step time 0.430s\n",
            "I1112 16:13:30.849145 139621605971840 model_lib_v2.py:707] Step 18600 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16037372,\n",
            " 'Loss/localization_loss': 0.0033669488,\n",
            " 'Loss/regularization_loss': 0.080451585,\n",
            " 'Loss/total_loss': 0.24419224,\n",
            " 'learning_rate': 0.5712394}\n",
            "I1112 16:13:30.849481 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16037372,\n",
            " 'Loss/localization_loss': 0.0033669488,\n",
            " 'Loss/regularization_loss': 0.080451585,\n",
            " 'Loss/total_loss': 0.24419224,\n",
            " 'learning_rate': 0.5712394}\n",
            "INFO:tensorflow:Step 18700 per-step time 0.428s\n",
            "I1112 16:14:13.693952 139621605971840 model_lib_v2.py:707] Step 18700 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16399638,\n",
            " 'Loss/localization_loss': 0.0020000564,\n",
            " 'Loss/regularization_loss': 0.08029838,\n",
            " 'Loss/total_loss': 0.24629483,\n",
            " 'learning_rate': 0.56891817}\n",
            "I1112 16:14:13.694285 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16399638,\n",
            " 'Loss/localization_loss': 0.0020000564,\n",
            " 'Loss/regularization_loss': 0.08029838,\n",
            " 'Loss/total_loss': 0.24629483,\n",
            " 'learning_rate': 0.56891817}\n",
            "INFO:tensorflow:Step 18800 per-step time 0.431s\n",
            "I1112 16:14:56.770091 139621605971840 model_lib_v2.py:707] Step 18800 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12761326,\n",
            " 'Loss/localization_loss': 0.0015118462,\n",
            " 'Loss/regularization_loss': 0.08000112,\n",
            " 'Loss/total_loss': 0.20912623,\n",
            " 'learning_rate': 0.56659}\n",
            "I1112 16:14:56.770475 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.12761326,\n",
            " 'Loss/localization_loss': 0.0015118462,\n",
            " 'Loss/regularization_loss': 0.08000112,\n",
            " 'Loss/total_loss': 0.20912623,\n",
            " 'learning_rate': 0.56659}\n",
            "INFO:tensorflow:Step 18900 per-step time 0.431s\n",
            "I1112 16:15:39.882340 139621605971840 model_lib_v2.py:707] Step 18900 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17788,\n",
            " 'Loss/localization_loss': 0.0031428412,\n",
            " 'Loss/regularization_loss': 0.08060324,\n",
            " 'Loss/total_loss': 0.2616261,\n",
            " 'learning_rate': 0.56425506}\n",
            "I1112 16:15:39.882696 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.17788,\n",
            " 'Loss/localization_loss': 0.0031428412,\n",
            " 'Loss/regularization_loss': 0.08060324,\n",
            " 'Loss/total_loss': 0.2616261,\n",
            " 'learning_rate': 0.56425506}\n",
            "INFO:tensorflow:Step 19000 per-step time 0.430s\n",
            "I1112 16:16:22.888609 139621605971840 model_lib_v2.py:707] Step 19000 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1729696,\n",
            " 'Loss/localization_loss': 0.0024315475,\n",
            " 'Loss/regularization_loss': 0.080742106,\n",
            " 'Loss/total_loss': 0.25614324,\n",
            " 'learning_rate': 0.5619134}\n",
            "I1112 16:16:22.888945 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1729696,\n",
            " 'Loss/localization_loss': 0.0024315475,\n",
            " 'Loss/regularization_loss': 0.080742106,\n",
            " 'Loss/total_loss': 0.25614324,\n",
            " 'learning_rate': 0.5619134}\n",
            "INFO:tensorflow:Step 19100 per-step time 0.451s\n",
            "I1112 16:17:07.981496 139621605971840 model_lib_v2.py:707] Step 19100 per-step time 0.451s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1528187,\n",
            " 'Loss/localization_loss': 0.0021308525,\n",
            " 'Loss/regularization_loss': 0.08045864,\n",
            " 'Loss/total_loss': 0.23540819,\n",
            " 'learning_rate': 0.559565}\n",
            "I1112 16:17:07.981832 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.1528187,\n",
            " 'Loss/localization_loss': 0.0021308525,\n",
            " 'Loss/regularization_loss': 0.08045864,\n",
            " 'Loss/total_loss': 0.23540819,\n",
            " 'learning_rate': 0.559565}\n",
            "INFO:tensorflow:Step 19200 per-step time 0.431s\n",
            "I1112 16:17:51.104421 139621605971840 model_lib_v2.py:707] Step 19200 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16209815,\n",
            " 'Loss/localization_loss': 0.0020369804,\n",
            " 'Loss/regularization_loss': 0.08062151,\n",
            " 'Loss/total_loss': 0.24475664,\n",
            " 'learning_rate': 0.55721}\n",
            "I1112 16:17:51.104741 139621605971840 model_lib_v2.py:708] {'Loss/classification_loss': 0.16209815,\n",
            " 'Loss/localization_loss': 0.0020369804,\n",
            " 'Loss/regularization_loss': 0.08062151,\n",
            " 'Loss/total_loss': 0.24475664,\n",
            " 'learning_rate': 0.55721}\n"
          ]
        }
      ],
      "source": [
        "#Starten eines Trainingsvorgangs.\n",
        "\n",
        "# mit regulären Metrics\n",
        "\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={config_path} \\\n",
        "    --model_dir={training_folder} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps} \\\n",
        "    --checkpoint_every_n=1000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kZptl6Zgmvd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901b267a-e2b8-49de-fd06-2cdd29118072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-12 16:44:08.633154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 16:44:08.790052: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2022-11-12 16:44:08.819658: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-12 16:44:09.640204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-12 16:44:09.640307: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-12 16:44:09.640324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1112 16:44:11.998644 140145410238336 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I1112 16:44:11.998885 140145410238336 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1112 16:44:11.998979 140145410238336 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1112 16:44:11.999072 140145410238336 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1112 16:44:11.999213 140145410238336 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2022-11-12 16:44:12.003117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 16:44:12.831293: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-11-12 16:44:12.831376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38354 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "I1112 16:44:12.851376 140145410238336 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1112 16:44:12.851556 140145410238336 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1112 16:44:12.851634 140145410238336 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1112 16:44:12.855584 140145410238336 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 16:44:12.897137 140145410238336 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 16:44:12.897325 140145410238336 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 16:44:13.066565 140145410238336 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 16:44:13.066745 140145410238336 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 16:44:13.360873 140145410238336 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 16:44:13.361051 140145410238336 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 16:44:13.651342 140145410238336 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 16:44:13.651523 140145410238336 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 16:44:14.035423 140145410238336 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 16:44:14.035595 140145410238336 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 16:44:14.417952 140145410238336 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 16:44:14.418121 140145410238336 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 16:44:14.890389 140145410238336 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 16:44:14.890568 140145410238336 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1112 16:44:15.091024 140145410238336 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1112 16:44:15.136055 140145410238336 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/validation.record']\n",
            "I1112 16:44:15.208323 140145410238336 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/validation.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/validation.record']\n",
            "I1112 16:44:15.208712 140145410238336 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/validation.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1112 16:44:15.208801 140145410238336 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1112 16:44:15.208857 140145410238336 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1112 16:44:15.213521 140145410238336 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1112 16:44:15.230245 140145410238336 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1112 16:44:19.405875 140145410238336 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1112 16:44:20.890479 140145410238336 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100\n",
            "I1112 16:44:23.572520 140145410238336 checkpoint_utils.py:142] Waiting for new checkpoint at /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100\n",
            "INFO:tensorflow:Found new checkpoint at /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/ckpt-21\n",
            "I1112 16:44:23.574997 140145410238336 checkpoint_utils.py:151] Found new checkpoint at /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/ckpt-21\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
            "2022-11-12 16:44:57.801098: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
            "2022-11-12 16:44:59.484068: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1112 16:44:59.872071 140145410238336 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I1112 16:45:00.013376 140145410238336 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1112 16:45:00.184127 140145410238336 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "tcmalloc: large alloc 1073741824 bytes == 0xdaf52000 @  0x7f76251fbb6b 0x7f762521b379 0x7f76026e99bc 0x7f75f1452e20 0x7f75f146d859 0x7f75f146e63a 0x7f75f146eb19 0x7f75f146eff1 0x7f75f1464b83 0x7f75ec2694dc 0x7f75ec059f4d 0x7f75ebe75a4a 0x7f75ebe7663c 0x7f75ebe76885 0x7f75f54c2a96 0x7f75ec26ab8b 0x7f75ec1d9cfc 0x7f75ec1dab98 0x7f76015d1301 0x7f76026e5585 0x7f76026e32b3 0x7f75ec0324ab 0x7f7624bdd6db 0x7f7624f1661f\n",
            "INFO:tensorflow:Performing evaluation on 93 images.\n",
            "I1112 16:45:10.345730 140145410238336 coco_evaluation.py:293] Performing evaluation on 93 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1112 16:45:10.346258 140145410238336 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1112 16:45:10.350583 140145410238336 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.44s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.863\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.599\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628\n",
            "INFO:tensorflow:Eval metrics at step 20000\n",
            "I1112 16:45:10.867657 140145410238336 model_lib_v2.py:1015] Eval metrics at step 20000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.504724\n",
            "I1112 16:45:10.945410 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.504724\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.862565\n",
            "I1112 16:45:10.947341 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.862565\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.548556\n",
            "I1112 16:45:10.948750 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.548556\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I1112 16:45:10.950049 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.400047\n",
            "I1112 16:45:10.951337 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.400047\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.512488\n",
            "I1112 16:45:10.952614 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.512488\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.461983\n",
            "I1112 16:45:10.953969 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.461983\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.599174\n",
            "I1112 16:45:10.955265 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.599174\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.620661\n",
            "I1112 16:45:10.956546 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.620661\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I1112 16:45:10.957659 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.512500\n",
            "I1112 16:45:10.958948 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.512500\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.628319\n",
            "I1112 16:45:10.960441 140145410238336 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.628319\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.005204\n",
            "I1112 16:45:10.961453 140145410238336 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.005204\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.305715\n",
            "I1112 16:45:10.962479 140145410238336 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.305715\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.080575\n",
            "I1112 16:45:10.963538 140145410238336 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.080575\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.391494\n",
            "I1112 16:45:10.964546 140145410238336 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.391494\n",
            "INFO:tensorflow:Exiting evaluation at step 20000\n",
            "I1112 16:45:11.151871 140145410238336 model_lib_v2.py:1168] Exiting evaluation at step 20000\n"
          ]
        }
      ],
      "source": [
        "# Erzeugt final Evaluation metrics z.B. mAP / iou precisions -> auch unabhängig von Training anwendbar\n",
        "\n",
        "!python /content/models/research/object_detection/model_main_tf2.py --model_dir={training_folder} --pipeline_config_path={config_path} --checkpoint_dir={training_folder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3GNLS4ywstA"
      },
      "source": [
        "## Export model inference graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WcvbNjcZw2er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570c4eb3-6497-4cf1-b278-19de0d6158e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-12 16:45:12.969377: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 16:45:13.120608: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2022-11-12 16:45:13.149495: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-12 16:45:13.972539: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-12 16:45:13.972635: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-12 16:45:13.972669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-12 16:45:15.991537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-12 16:45:16.822943: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-11-12 16:45:16.823014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38354 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "I1112 16:45:16.844123 140062982952832 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1112 16:45:16.844328 140062982952832 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1112 16:45:16.844395 140062982952832 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1112 16:45:16.848108 140062982952832 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 16:45:16.891823 140062982952832 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1112 16:45:16.891990 140062982952832 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 16:45:17.065631 140062982952832 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1112 16:45:17.065807 140062982952832 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 16:45:17.499657 140062982952832 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1112 16:45:17.499844 140062982952832 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 16:45:17.800704 140062982952832 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1112 16:45:17.800889 140062982952832 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 16:45:18.201454 140062982952832 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1112 16:45:18.201628 140062982952832 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 16:45:18.597295 140062982952832 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1112 16:45:18.597466 140062982952832 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 16:45:19.083404 140062982952832 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1112 16:45:19.083573 140062982952832 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1112 16:45:19.287069 140062982952832 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1112 16:45:19.335513 140062982952832 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W1112 16:45:23.149299 140062982952832 deprecation.py:628] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f61f00dfd90>, because it is not built.\n",
            "W1112 16:45:49.886651 140062982952832 save_impl.py:68] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f61f00dfd90>, because it is not built.\n",
            "W1112 16:46:50.783543 140062982952832 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 535). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/inference_graph/saved_model/assets\n",
            "I1112 16:47:26.511654 140062982952832 builder_impl.py:780] Assets written to: /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/inference_graph/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/inference_graph/pipeline.config\n",
            "I1112 16:47:29.239134 140062982952832 config_util.py:254] Writing pipeline config file to /content/drive/MyDrive/training2_effdetd1_ds2_8_20000_100/inference_graph/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "output_directory = training_folder+'/inference_graph'\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {training_folder} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {config_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tGVwzpLxvSv"
      },
      "source": [
        "## Anwendung des trainierten Model\n",
        "\n",
        "Dieser Schritt im Inferenz-Notebook unabhängig vom Training ausführbar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp4wlWrhxyJL"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import six\n",
        "import time\n",
        "import glob\n",
        "from IPython.display import display\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEaYWo8WyLS2"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path (this can be local or on colossus)\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxWU7K_oyVwq"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkMddTneyesG"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(f'{output_directory}/saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxAf3XJBzLHq"
      },
      "outputs": [],
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cmiblvFxDgM"
      },
      "outputs": [],
      "source": [
        "#model_dir = '/content/drive/MyDrive/training_effDet_d0_4_3000_100/'\n",
        "#print (model_dir)\n",
        "#speicherPfadEvalBilder = model_dir + \"angewendeteBilder\"\n",
        "\n",
        "#%mkdir {speicherPfadEvalBilder}\n",
        "print(training_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EEX-m3P1yp4y"
      },
      "outputs": [],
      "source": [
        "#model_dir = '/content/drive/MyDrive/training_effDet_d0_4_3000_100/'\n",
        "print (training_folder)\n",
        "speicherPfadEvalBilder = training_folder + \"/angewendeteBilder\"\n",
        "\n",
        "%mkdir {speicherPfadEvalBilder}\n",
        "\n",
        "for image_path in glob.glob('/content/drive/MyDrive/Child_Dataset/testEval/*g'):\n",
        "\n",
        "  image_name = os.path.basename(image_path).replace(\".jpg\", \"\")\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  outImg = vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.5,\n",
        "      max_boxes_to_draw=20,\n",
        "      line_thickness=3)\n",
        "  \n",
        "  im = Image.fromarray(outImg)\n",
        "  display(Image.fromarray(image_np))\n",
        "  print ('Versuche hier zu speichern:' + speicherPfadEvalBilder + \"/\" + image_name + \"_boxed.jpg\")\n",
        "  im.save(speicherPfadEvalBilder + \"/\" + image_name + \"_boxed.jpg\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5tGVwzpLxvSv"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}